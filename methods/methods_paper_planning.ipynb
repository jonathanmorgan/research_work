{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**methods paper planning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Setup---Imports\" data-toc-modified-id=\"Setup---Imports-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Setup - Imports</a></span></li><li><span><a href=\"#Setup---virtualenv-jupyter-kernel\" data-toc-modified-id=\"Setup---virtualenv-jupyter-kernel-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Setup - virtualenv jupyter kernel</a></span></li><li><span><a href=\"#Setup---Initialize-Django\" data-toc-modified-id=\"Setup---Initialize-Django-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Setup - Initialize Django</a></span></li></ul></li><li><span><a href=\"#Analysis-steps\" data-toc-modified-id=\"Analysis-steps-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Analysis steps</a></span></li><li><span><a href=\"#Data-Creation\" data-toc-modified-id=\"Data-Creation-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Creation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Creation---local-GRP-articles\" data-toc-modified-id=\"Data-Creation---local-GRP-articles-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Data Creation - local GRP articles</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Creation---GRP---prelim-month\" data-toc-modified-id=\"Data-Creation---GRP---prelim-month-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Data Creation - GRP - prelim month</a></span></li></ul></li><li><span><a href=\"#Data-Creation---local-TDN-articles\" data-toc-modified-id=\"Data-Creation---local-TDN-articles-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Data Creation - local TDN articles</a></span></li></ul></li><li><span><a href=\"#Reliability\" data-toc-modified-id=\"Reliability-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Reliability</a></span><ul class=\"toc-item\"><li><span><a href=\"#Coding-protocol-testing\" data-toc-modified-id=\"Coding-protocol-testing-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Coding protocol testing</a></span></li><li><span><a href=\"#Reliability-Data\" data-toc-modified-id=\"Reliability-Data-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Reliability Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#prelim_month-reliability-sample-size\" data-toc-modified-id=\"prelim_month-reliability-sample-size-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>prelim_month reliability sample size</a></span></li><li><span><a href=\"#original-design-reliability-sample-size\" data-toc-modified-id=\"original-design-reliability-sample-size-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>original design reliability sample size</a></span></li><li><span><a href=\"#Creating-Reliability_Names-data\" data-toc-modified-id=\"Creating-Reliability_Names-data-4.2.3\"><span class=\"toc-item-num\">4.2.3&nbsp;&nbsp;</span>Creating Reliability_Names data</a></span></li></ul></li><li><span><a href=\"#Reliability-Analysis\" data-toc-modified-id=\"Reliability-Analysis-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Reliability Analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Code-to-calculate-reliability-numbers\" data-toc-modified-id=\"Code-to-calculate-reliability-numbers-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>Code to calculate reliability numbers</a></span></li><li><span><a href=\"#Original-notebooks-to-calculate-reliability\" data-toc-modified-id=\"Original-notebooks-to-calculate-reliability-4.3.2\"><span class=\"toc-item-num\">4.3.2&nbsp;&nbsp;</span>Original notebooks to calculate reliability</a></span></li></ul></li><li><span><a href=\"#prelim_reliability_combined_human_final-results\" data-toc-modified-id=\"prelim_reliability_combined_human_final-results-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>prelim_reliability_combined_human_final results</a></span><ul class=\"toc-item\"><li><span><a href=\"#Author-reliability\" data-toc-modified-id=\"Author-reliability-4.4.1\"><span class=\"toc-item-num\">4.4.1&nbsp;&nbsp;</span>Author reliability</a></span></li><li><span><a href=\"#Subject-reliability\" data-toc-modified-id=\"Subject-reliability-4.4.2\"><span class=\"toc-item-num\">4.4.2&nbsp;&nbsp;</span>Subject reliability</a></span></li></ul></li><li><span><a href=\"#prelim_reliability_combined_human-results\" data-toc-modified-id=\"prelim_reliability_combined_human-results-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>prelim_reliability_combined_human results</a></span><ul class=\"toc-item\"><li><span><a href=\"#Author-reliability\" data-toc-modified-id=\"Author-reliability-4.5.1\"><span class=\"toc-item-num\">4.5.1&nbsp;&nbsp;</span>Author reliability</a></span></li><li><span><a href=\"#Subject-reliability\" data-toc-modified-id=\"Subject-reliability-4.5.2\"><span class=\"toc-item-num\">4.5.2&nbsp;&nbsp;</span>Subject reliability</a></span></li></ul></li></ul></li><li><span><a href=\"#Preparation-for-automated-assessment\" data-toc-modified-id=\"Preparation-for-automated-assessment-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Preparation for automated assessment</a></span><ul class=\"toc-item\"><li><span><a href=\"#Single-name-removal\" data-toc-modified-id=\"Single-name-removal-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Single name removal</a></span><ul class=\"toc-item\"><li><span><a href=\"#Notes\" data-toc-modified-id=\"Notes-5.1.1\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>Notes</a></span></li><li><span><a href=\"#Error-detail\" data-toc-modified-id=\"Error-detail-5.1.2\"><span class=\"toc-item-num\">5.1.2&nbsp;&nbsp;</span>Error detail</a></span></li></ul></li><li><span><a href=\"#Evaluating-disagreements\" data-toc-modified-id=\"Evaluating-disagreements-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Evaluating disagreements</a></span></li></ul></li><li><span><a href=\"#Automated-coder-evaluation\" data-toc-modified-id=\"Automated-coder-evaluation-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Automated coder evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#prelim_month-vs.-prelim_month_human\" data-toc-modified-id=\"prelim_month-vs.-prelim_month_human-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span><code>prelim_month</code> vs. <code>prelim_month_human</code></a></span></li><li><span><a href=\"#Precision-and-Recall---prelim_month\" data-toc-modified-id=\"Precision-and-Recall---prelim_month-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Precision and Recall - <code>prelim_month</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#Automated-Confusion-Matrix-and-Scores\" data-toc-modified-id=\"Automated-Confusion-Matrix-and-Scores-6.2.1\"><span class=\"toc-item-num\">6.2.1&nbsp;&nbsp;</span>Automated Confusion Matrix and Scores</a></span></li></ul></li><li><span><a href=\"#Human-Precision-and-Recall---prelim_month_human\" data-toc-modified-id=\"Human-Precision-and-Recall---prelim_month_human-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Human Precision and Recall - <code>prelim_month_human</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#Human-Confusion-Matrix-and-Scores\" data-toc-modified-id=\"Human-Confusion-Matrix-and-Scores-6.3.1\"><span class=\"toc-item-num\">6.3.1&nbsp;&nbsp;</span>Human Confusion Matrix and Scores</a></span></li></ul></li><li><span><a href=\"#Calculate-reliability-numbers-for-prelim_month...\" data-toc-modified-id=\"Calculate-reliability-numbers-for-prelim_month...-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Calculate reliability numbers for <code>prelim_month</code>...</a></span><ul class=\"toc-item\"><li><span><a href=\"#prelim_month-Automated-Author-reliability\" data-toc-modified-id=\"prelim_month-Automated-Author-reliability-6.4.1\"><span class=\"toc-item-num\">6.4.1&nbsp;&nbsp;</span>prelim_month Automated Author reliability</a></span></li><li><span><a href=\"#prelim_month-Automated-Subject-reliability\" data-toc-modified-id=\"prelim_month-Automated-Subject-reliability-6.4.2\"><span class=\"toc-item-num\">6.4.2&nbsp;&nbsp;</span>prelim_month Automated Subject reliability</a></span></li></ul></li><li><span><a href=\"#...-and-calculate-reliability-numbers-for-prelim_month_human\" data-toc-modified-id=\"...-and-calculate-reliability-numbers-for-prelim_month_human-6.5\"><span class=\"toc-item-num\">6.5&nbsp;&nbsp;</span>... and calculate reliability numbers for <code>prelim_month_human</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#prelim_month_human---Author-reliability\" data-toc-modified-id=\"prelim_month_human---Author-reliability-6.5.1\"><span class=\"toc-item-num\">6.5.1&nbsp;&nbsp;</span>prelim_month_human - Author reliability</a></span></li><li><span><a href=\"#prelim_month_human---Subject-reliability\" data-toc-modified-id=\"prelim_month_human---Subject-reliability-6.5.2\"><span class=\"toc-item-num\">6.5.2&nbsp;&nbsp;</span>prelim_month_human - Subject reliability</a></span></li></ul></li></ul></li><li><span><a href=\"#Network-Analysis\" data-toc-modified-id=\"Network-Analysis-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Network Analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Basic-Plan-for-getting-back-up-to-speed:\" data-toc-modified-id=\"Basic-Plan-for-getting-back-up-to-speed:-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Basic Plan for getting back up to speed:</a></span></li><li><span><a href=\"#New-analysis-steps\" data-toc-modified-id=\"New-analysis-steps-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>New analysis steps</a></span></li><li><span><a href=\"#SNA-Notebooks\" data-toc-modified-id=\"SNA-Notebooks-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>SNA Notebooks</a></span><ul class=\"toc-item\"><li><span><a href=\"#notebooks---create-data\" data-toc-modified-id=\"notebooks---create-data-7.3.1\"><span class=\"toc-item-num\">7.3.1&nbsp;&nbsp;</span>notebooks - create data</a></span></li><li><span><a href=\"#notebooks---network-analysis---igraph\" data-toc-modified-id=\"notebooks---network-analysis---igraph-7.3.2\"><span class=\"toc-item-num\">7.3.2&nbsp;&nbsp;</span>notebooks - network analysis - igraph</a></span></li><li><span><a href=\"#notebooks---network-creation,-descriptives-and-QAP---statnet\" data-toc-modified-id=\"notebooks---network-creation,-descriptives-and-QAP---statnet-7.3.3\"><span class=\"toc-item-num\">7.3.3&nbsp;&nbsp;</span>notebooks - network creation, descriptives and QAP - statnet</a></span><ul class=\"toc-item\"><li><span><a href=\"#ANALYSIS---network-creation,-descriptives-and-QAP---statnet\" data-toc-modified-id=\"ANALYSIS---network-creation,-descriptives-and-QAP---statnet-7.3.3.1\"><span class=\"toc-item-num\">7.3.3.1&nbsp;&nbsp;</span>ANALYSIS - network creation, descriptives and QAP - statnet</a></span></li></ul></li><li><span><a href=\"#notebooks---author-info\" data-toc-modified-id=\"notebooks---author-info-7.3.4\"><span class=\"toc-item-num\">7.3.4&nbsp;&nbsp;</span>notebooks - author info</a></span></li></ul></li><li><span><a href=\"#network-analysis-TODO\" data-toc-modified-id=\"network-analysis-TODO-7.4\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>network analysis TODO</a></span><ul class=\"toc-item\"><li><span><a href=\"#network-analysis-TODO---DEFERRED\" data-toc-modified-id=\"network-analysis-TODO---DEFERRED-7.4.1\"><span class=\"toc-item-num\">7.4.1&nbsp;&nbsp;</span>network analysis TODO - DEFERRED</a></span></li><li><span><a href=\"#network-analysis-TODO---DONE\" data-toc-modified-id=\"network-analysis-TODO---DONE-7.4.2\"><span class=\"toc-item-num\">7.4.2&nbsp;&nbsp;</span>network analysis TODO - DONE</a></span></li></ul></li></ul></li><li><span><a href=\"#Combine-results-into-spreadsheet\" data-toc-modified-id=\"Combine-results-into-spreadsheet-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Combine results into spreadsheet</a></span></li><li><span><a href=\"#NEXT\" data-toc-modified-id=\"NEXT-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>NEXT</a></span></li><li><span><a href=\"#Paper-Edits\" data-toc-modified-id=\"Paper-Edits-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Paper Edits</a></span></li><li><span><a href=\"#TODO\" data-toc-modified-id=\"TODO-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>TODO</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Imports\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T01:42:07.555038Z",
     "start_time": "2019-04-24T01:42:07.548530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packages imported at 2019-04-24 01:42:07.550142\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import six\n",
    "\n",
    "print( \"packages imported at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - virtualenv jupyter kernel\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "If you are using a virtualenv, make sure that you:\n",
    "\n",
    "- have installed your virtualenv as a kernel.\n",
    "- choose the kernel for your virtualenv as the kernel for your notebook (Kernel --> Change kernel).\n",
    "\n",
    "Since I use a virtualenv, need to get that activated somehow inside this notebook.  One option is to run `../dev/wsgi.py` in this notebook, to configure the python environment manually as if you had activated the `sourcenet` virtualenv.  To do this, you'd make a code cell that contains:\n",
    "\n",
    "    %run ../dev/wsgi.py\n",
    "    \n",
    "This is sketchy, however, because of the changes it makes to your Python environment within the context of whatever your current kernel is.  I'd worry about collisions with the actual Python 3 kernel.  Better, one can install their virtualenv as a separate kernel.  Steps:\n",
    "\n",
    "- activate your virtualenv:\n",
    "\n",
    "        workon sourcenet\n",
    "\n",
    "- in your virtualenv, install the package `ipykernel`.\n",
    "\n",
    "        pip install ipykernel\n",
    "\n",
    "- use the ipykernel python program to install the current environment as a kernel:\n",
    "\n",
    "        python -m ipykernel install --user --name <env_name> --display-name \"<display_name>\"\n",
    "        \n",
    "    `sourcenet` example:\n",
    "    \n",
    "        python -m ipykernel install --user --name sourcenet --display-name \"sourcenet (Python 3)\"\n",
    "        \n",
    "More details: [http://ipython.readthedocs.io/en/stable/install/kernel_install.html](http://ipython.readthedocs.io/en/stable/install/kernel_install.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T01:42:09.931951Z",
     "start_time": "2019-04-24T01:42:09.919388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jonathanmorgan/work/django/research/work/phd_work/methods'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Initialize Django\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "First, initialize my dev django project, so I can run code in this notebook that references my django models and can talk to the database using my project's settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T01:42:15.035161Z",
     "start_time": "2019-04-24T01:42:12.299552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "django initialized at 2019-04-24 01:42:15.032662\n"
     ]
    }
   ],
   "source": [
    "%run django_init.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T01:42:24.688127Z",
     "start_time": "2019-04-24T01:42:24.684518Z"
    }
   },
   "outputs": [],
   "source": [
    "# django imports\n",
    "from context_analysis.models import Reliability_Names_Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis steps\n",
    "\n",
    "In the methods folder, here is the order the code was run for analysis:\n",
    "\n",
    "- 1) `data_creation` (results in `data` folder)\n",
    "- 2) `reliability` - for human reliability.\n",
    "- 3) `evaluate_disagreements` - correct human coding when they are wrong in a disagreement, to create \"ground truth\".\n",
    "- 4) `precision_recall`\n",
    "- 5) `reliability` - for comparing human and computer coding to baseline.\n",
    "- 6) `network_analysis`\n",
    "- 7) `results`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Creation\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Below are the criteria used for each paper to filter down to just locally-implemented hard news articles.\n",
    "\n",
    "For actual code, see [./data_creation/data_creation-filter_locally_implemented_hard_news.ipynb](./data_creation/data_creation-filter_locally_implemented_hard_news.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Creation - local GRP articles\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Definition of local hard news and in-house implementor:\n",
    "\n",
    "- Grand Rapids Press\n",
    "\n",
    "    - `context_text/examples/articles/articles-GRP-local_news.py`\n",
    "    - local hard news sections (stored in `Article.GRP_NEWS_SECTION_NAME_LIST`):\n",
    "   \n",
    "        - \"Business\"\n",
    "        - \"City and Region\"\n",
    "        - \"Front Page\"\n",
    "        - \"Lakeshore\"\n",
    "        - \"Religion\"\n",
    "        - \"Special\"\n",
    "        - \"State\"\n",
    "\n",
    "    - excluding any publications with index term of \"Column\".\n",
    "    - in-house implementor (based on byline patterns, stored in `sourcenet.models.Article.Q_GRP_IN_HOUSE_AUTHOR`):\n",
    "    \n",
    "        - Byline ends in \"/ THE GRAND RAPIDS PRESS\", ignore case.\n",
    "        \n",
    "            - `Q( author_varchar__iregex = r'.* */ *THE GRAND RAPIDS PRESS$'`\n",
    "\n",
    "        - Byline ends in \"/ PRESS * EDITOR\", ignore case.\n",
    "     \n",
    "            - `Q( author_varchar__iregex = r'.* */ *PRESS .* EDITOR$' )`\n",
    "        \n",
    "        - Byline ends in \"/ GRAND RAPIDS PRESS * BUREAU\", ignore case.\n",
    "        \n",
    "            - `Q( author_varchar__iregex = r'.* */ *GRAND RAPIDS PRESS .* BUREAU$' )`\n",
    "            \n",
    "        - Byline ends in \"/ SPECIAL TO THE PRESS\", ignore case.\n",
    "        \n",
    "            - `Q( author_varchar__iregex = r'.* */ *SPECIAL TO THE PRESS$' )`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Creation - GRP - prelim month\n",
    "\n",
    "Description of month of GRP articles from December, 2009, for paper.\n",
    "\n",
    "- grp_month article count = 441\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T01:42:30.600014Z",
     "start_time": "2019-04-24T01:42:30.594787Z"
    }
   },
   "outputs": [],
   "source": [
    "from context_text.models import Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many articles in \"grp_month\"?\n",
    "article_qs = Article.objects.filter( tags__name__in = [ \"grp_month\" ] )\n",
    "grp_month_count = article_qs.count()\n",
    "\n",
    "print( \"grp_month count = {}\".format( grp_month_count ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Creation - local TDN articles\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Definition of local hard news and in-house implementor:\n",
    "\n",
    "- Detroit News\n",
    "\n",
    "    - `context_text/examples/articles/articles-TDN-local_news.py`\n",
    "    - local hard news sections (stored in `from context_text.collectors.newsbank.newspapers.DTNB import DTNB` - `DTNB.NEWS_SECTION_NAME_LIST`):\n",
    "   \n",
    "        - \"Business\"\n",
    "        - \"Metro\"\n",
    "        - \"Nation\" - because of auto industry stories\n",
    "\n",
    "    - in-house implementor (based on byline patterns, stored in `DTNB.Q_IN_HOUSE_AUTHOR`):\n",
    "    \n",
    "        - Byline ends in \"/ The Detroit News\", ignore case.\n",
    "        \n",
    "            - `Q( author_varchar__iregex = r'.*\\s*/\\s*the\\s*detroit\\s*news$' )`\n",
    "\n",
    "        - Byline ends in \"Special to The Detroit News\", ignore case.\n",
    "        \n",
    "            - `Q( author_varchar__iregex = r'.*\\s*/\\s*special\\s*to\\s*the\\s*detroit\\s*news$' )`\n",
    "        \n",
    "        - Byline ends in \"Detroit News * Bureau\", ignore case.\n",
    "        \n",
    "            - `Q( author_varchar__iregex = r'.*\\s*/\\s*detroit\\s*news\\s*.*\\s*bureau$' )`    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reliability\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "TODO:\n",
    "\n",
    "- Characterize data used in reliability test (# articles, from both Detroit News and Grand Rapids Press, etc.).\n",
    "- describe reliability results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding protocol testing\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Outline in voodoopad - \"`Dropbox/academia/MSU/program_stuff/voodoopad/phd.vpdoc`\", note \"Prelim - Notes\".\n",
    "\n",
    "Trained on 7 samples of 10 articles each. For each training set, users coded, I reviewed coding and updated protocol, then we reviewed problems and changes to protocol.  After 7 sets, did formal reliability test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reliability Data\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Article traits:\n",
    "\n",
    "- 87 total local news articles implemented by a staff writer (either full-time or contractor), published in a local news section (outline criteria for GRP and TDN), and across two different papers, to just confirm that sourcing is standard across publications.\n",
    "- Sample size:\n",
    "\n",
    "    - minimum required sample size was 47 articles (46.79)\n",
    "    - Equation: $$n = \\frac {(N-1)(SE)^2 + PQN}{(N-1)(SE)^2 + PQ}$$\n",
    "    \n",
    "        - WHERE:\n",
    "        \n",
    "            - N = total number of items to be coded\n",
    "            - SE = standard error at desired confidence level ( $$SE = \\frac{confidence interval}{Z-score}$$\n",
    "            - P = population level of agreement\n",
    "            - Q = 1 - P\n",
    "    \n",
    "    - from:\n",
    "\n",
    "        - Lacy, S., and D. Riffe. “Sampling Error and Selecting Intercoder Reliability Samples for Nominal Content Categories.” JOURNALISM AND MASS COMMUNICATION QUARTERLY, no. 4 (Winter 1996): 963. https://doi.org/10.1177/107769909607300414.\n",
    "        - Riffe, Daniel, Stephen Lacy, and Frederick G. Fico. Analyzing Media Messages: Using Quantitative Content Analysis in Research, Second Edition. 2nd ed. LEA Communications Series. Mahwah, New Jersey: Lawrence Erlbaum Associates, Inc., 2005.\n",
    "\n",
    "- Articles in the reliability test sample:\n",
    "\n",
    "    - need a minimum of 47 articles given math above (calculated in detail below).  Ended up including 87 articles in reliability sample to make sure we would be OK if we needed to code many more by hand if automated coder was no good. \n",
    "    - 27 articles from the Detroit News (tags \"minnesota1-20160409\", \"minnesota2-20160409\", and \"minnesota3-20160409\" each reference these same 27 articles)\n",
    "    - 60 Grand Rapids Press articles are tagged \"prelim_reliability_test\".\n",
    "    \n",
    "- number of people detected?\n",
    "- anything else?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$n = \\frac {(N-1)(SE)^2 + PQN}{(N-1)(SE)^2 + PQ}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prelim_month reliability sample size\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-17T03:24:50.357838Z",
     "start_time": "2018-08-17T03:24:50.351963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prelim_month reliability minimum sample size: 46.78486279032644\n"
     ]
    }
   ],
   "source": [
    "# ==> prelim_month\n",
    "\n",
    "# init variables\n",
    "n = 441\n",
    "p = 0.95\n",
    "ci = 0.05\n",
    "z = 1.64\n",
    "se = ci / z\n",
    "q = 1 - p\n",
    "sample_size = None\n",
    "\n",
    "# calculate sample_size\n",
    "n_minus_1 = n - 1\n",
    "se_squared = se ** 2\n",
    "p_times_q = p * q\n",
    "n_minus_1_times_se_squared = n_minus_1 * se_squared\n",
    "numerator = n_minus_1_times_se_squared + ( p_times_q * n )\n",
    "denominator = n_minus_1_times_se_squared + p_times_q\n",
    "sample_size = numerator / denominator\n",
    "\n",
    "print( \"prelim_month reliability minimum sample size: {}\".format( sample_size ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for \"`grp_month`\":\n",
    "\n",
    "    - P = 95% agreement in the population\n",
    "    - seeking a 95% confidence level (confidence interval p = 0.05)\n",
    "    - Z-Score for p = 0.05: 1.64\n",
    "    - N = content universe = 1 month of local news articles by staff writers in Grand Rapids Press = 441 articles.\n",
    "    - SE = 0.05 / 1.64 = 0.0304878\n",
    "    - so:\n",
    "\n",
    "$$n = \\frac {(441-1)(0.0304878)^2 + (0.95 * 0.05 * 441)}{(441-1)(0.0304878)^2 + (0.95 * 0.05)}$$\n",
    "\n",
    "$$n = \\frac {(440)(0.0304878)^2 + (0.95 * 0.05 * 441)}{(440)(0.0304878)^2 + (0.95 * 0.05)}$$\n",
    "\n",
    "$$n = \\frac {(440)(0.0009295059) + (0.95 * 0.05 * 441)}{(440)(0.0009295059) + (0.95 * 0.05)}$$\n",
    "\n",
    "$$n = \\frac {0.4089826 + (0.95 * 0.05 * 441)}{0.4089826 + (0.95 * 0.05)}$$\n",
    "\n",
    "$$n = \\frac {0.4089826 + (0.0475 * 441)}{0.4089826 + 0.0475}$$\n",
    "\n",
    "$$n = \\frac {0.4089826 + 20.9475}{0.4089826 + 0.0475}$$\n",
    "\n",
    "$$n = \\frac {21.35648}{0.4564826}$$\n",
    "\n",
    "$$n = 46.78487$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-17T03:33:09.168976Z",
     "start_time": "2018-08-17T03:33:09.162915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prelim_month reliability minimum sample size: 52.10239738854489\n"
     ]
    }
   ],
   "source": [
    "# ==> prelim_month\n",
    "\n",
    "# init variables\n",
    "n = 1000000000\n",
    "p = 0.95\n",
    "ci = 0.05\n",
    "z = 1.64\n",
    "se = ci / z\n",
    "q = 1 - p\n",
    "sample_size = None\n",
    "\n",
    "# calculate sample_size\n",
    "n_minus_1 = n - 1\n",
    "se_squared = se ** 2\n",
    "p_times_q = p * q\n",
    "n_minus_1_times_se_squared = n_minus_1 * se_squared\n",
    "numerator = n_minus_1_times_se_squared + ( p_times_q * n )\n",
    "denominator = n_minus_1_times_se_squared + p_times_q\n",
    "sample_size = numerator / denominator\n",
    "\n",
    "print( \"prelim_month reliability minimum sample size: {}\".format( sample_size ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### original design reliability sample size\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-17T03:24:32.060576Z",
     "start_time": "2018-08-17T03:24:32.054487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original sample reliability minimum sample size: 46.9929438797392\n"
     ]
    }
   ],
   "source": [
    "# ==> original sample\n",
    "\n",
    "# init variables\n",
    "n = 461\n",
    "p = 0.95\n",
    "ci = 0.05\n",
    "z = 1.64\n",
    "se = ci / z\n",
    "q = 1 - p\n",
    "sample_size = None\n",
    "\n",
    "# calculate sample_size\n",
    "n_minus_1 = n - 1\n",
    "se_squared = se ** 2\n",
    "p_times_q = p * q\n",
    "n_minus_1_times_se_squared = n_minus_1 * se_squared\n",
    "numerator = n_minus_1_times_se_squared + ( p_times_q * n )\n",
    "denominator = n_minus_1_times_se_squared + p_times_q\n",
    "sample_size = numerator / denominator\n",
    "\n",
    "print( \"original sample reliability minimum sample size: {}\".format( sample_size ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for original sample:\n",
    "\n",
    "    - P = 95% agreement in the population\n",
    "    - seeking a 95% confidence level (confidence interval p = 0.05)\n",
    "    - Z-Score for p = 0.05: 1.64\n",
    "    - N = content universe = 2 weeks of local news articles by staff writers in each of the Grand Rapids Press and Detroit News = 461 articles.\n",
    "    - SE = 0.05 / 1.64 = 0.0304878\n",
    "    - so:\n",
    "\n",
    "$$n = \\frac {(461-1)(0.0304878)^2 + (0.95 * 0.05 * 461)}{(461-1)(0.0304878)^2 + (0.95 * 0.05)}$$\n",
    "\n",
    "$$n = \\frac {(460)(0.0304878)^2 + (0.95 * 0.05 * 461)}{(460)(0.0304878)^2 + (0.95 * 0.05)}$$\n",
    "\n",
    "$$n = \\frac {(460)(0.0009295059) + (0.95 * 0.05 * 461)}{(460)(0.0009295059) + (0.95 * 0.05)}$$\n",
    "\n",
    "$$n = \\frac {0.4275727 + (0.95 * 0.05 * 461)}{0.4275727 + (0.95 * 0.05)}$$\n",
    "\n",
    "$$n = \\frac {0.4275727 + (0.0475 * 461)}{0.4275727 + 0.0475}$$\n",
    "\n",
    "$$n = \\frac {0.4275727 + 21.8975}{0.4275727 + 0.0475}$$\n",
    "\n",
    "$$n = \\frac {22.32507}{0.4750727}$$\n",
    "\n",
    "$$n = 46.99295$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T18:21:39.830948Z",
     "start_time": "2018-11-07T18:21:39.827345Z"
    }
   },
   "source": [
    "### Creating Reliability_Names data\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "A little exploration to see what the tags below contain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T20:08:04.052116Z",
     "start_time": "2018-11-07T20:08:04.047777Z"
    }
   },
   "outputs": [],
   "source": [
    "from context_text.models import Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T20:08:05.090019Z",
     "start_time": "2018-11-07T20:08:04.998363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prelim_reliability_test count = 60\n"
     ]
    }
   ],
   "source": [
    "# how many articles in \"prelim_reliability_test\"?\n",
    "article_qs = Article.objects.filter( tags__name__in = [ \"prelim_reliability_test\" ] )\n",
    "reliability_sample_count = article_qs.count()\n",
    "\n",
    "print( \"prelim_reliability_test count = {}\".format( reliability_sample_count ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T20:08:30.008840Z",
     "start_time": "2018-11-07T20:08:29.995032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prelim_reliability_combined count = 87\n"
     ]
    }
   ],
   "source": [
    "# how many articles in \"prelim_reliability_combined\"?\n",
    "article_qs = Article.objects.filter( tags__name__in = [ \"prelim_reliability_combined\" ] )\n",
    "reliability_sample_count = article_qs.count()\n",
    "\n",
    "print( \"prelim_reliability_combined count = {}\".format( reliability_sample_count ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So:\n",
    "\n",
    "- `prelim_reliability_test` is just Grand Rapids Press, not what I'm reporting for the paper.\n",
    "- `prelim_reliability_combined` is GRP plus The Detroit News, is what I'm reporting in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original code to generate data is in [context_analysis/examples/reliability/reliability-build_name_data.py](https://research.local:8000/user/jonathanmorgan/edit/work/django/research/context_analysis/examples/reliability/reliability-build_name_data.py).  It was used to create all the Reliability_Names data for the formal reliability test, including the initial run that only contained GRP articles, and some runs that included the automated coding alongside (no need).\n",
    "\n",
    "The main label for reliability is `prelim_reliability_combined_human`, which would not have included the index 4 with automated coder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "\n",
    "# django imports\n",
    "from django.contrib.auth.models import User\n",
    "\n",
    "# sourcenet imports\n",
    "from context_text.shared.context_text_base import ContextTextBase\n",
    "\n",
    "# context_analysis imports\n",
    "from context_analysis.reliability.reliability_names_builder import ReliabilityNamesBuilder\n",
    "\n",
    "# declare variables\n",
    "my_reliability_instance = None\n",
    "tag_list = None\n",
    "label = \"\"\n",
    "\n",
    "# declare variables - user setup\n",
    "current_coder = None\n",
    "current_coder_id = -1\n",
    "current_index = -1\n",
    "\n",
    "# declare variables - Article_Data filtering.\n",
    "coder_type = \"\"\n",
    "\n",
    "# make reliability instance\n",
    "my_reliability_instance = ReliabilityNamesBuilder()\n",
    "\n",
    "#===============================================================================\n",
    "# configure\n",
    "#===============================================================================\n",
    "\n",
    "# list of tags of articles we want to process.\n",
    "tag_list = [ \"prelim_reliability_combined\", ]\n",
    "\n",
    "# label to associate with results, for subsequent lookup.\n",
    "label = \"prelim_reliability_combined_human\"\n",
    "\n",
    "# ! ====> map coder user IDs to indices within the reliability names table.\n",
    "\n",
    "# set it up so that...\n",
    "\n",
    "# ...coder ID 8 is index 1...\n",
    "current_coder_id = 8\n",
    "current_index = 1\n",
    "my_reliability_instance.add_coder_at_index( current_coder_id, current_index )\n",
    "\n",
    "# ...coder ID 9 is index 2...\n",
    "current_coder_id = 9\n",
    "current_index = 2\n",
    "my_reliability_instance.add_coder_at_index( current_coder_id, current_index )\n",
    "\n",
    "# ...coder ID 10 is index 3...\n",
    "current_coder_id = 10\n",
    "current_index = 3\n",
    "my_reliability_instance.add_coder_at_index( current_coder_id, current_index )\n",
    "\n",
    "# output debug JSON to file\n",
    "#my_reliability_instance.debug_output_json_file_path = \"/home/jonathanmorgan/\" + label + \".json\"\n",
    "\n",
    "#===============================================================================\n",
    "# process\n",
    "#===============================================================================\n",
    "\n",
    "# process articles\n",
    "my_reliability_instance.process_articles( tag_list )\n",
    "\n",
    "# output to database.\n",
    "my_reliability_instance.output_reliability_data( label )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reliability Analysis\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Path to Dropbox folder that holds PDF and Excel file output of reliability numbers:\n",
    "\n",
    "- Dropbox/academia/MSU/program_stuff/prelim_paper/analysis/reliability/2016-data\n",
    "\n",
    "To view results: [https://research.local/research/context/analysis/reliability/names/results/view](https://research.local/research/context/analysis/reliability/names/results/view)\n",
    "\n",
    "The human-only results (the ones I will write about) are results with labels:\n",
    "\n",
    "- \"`prelim_reliability_combined_human_final`\"\n",
    "\n",
    "    - this is latest code, regenerated recently.  Is identical to the results from the old code (numbers from 2016.08.27):\n",
    "    \n",
    "        - `Dropbox/academia/MSU/program_stuff/prelim_paper/analysis/reliability/2016-data/2016.08.27-reliability-prelim_reliability_combined_human.pdf`\n",
    "        - `Dropbox/academia/MSU/program_stuff/prelim_paper/analysis/reliability/2016-data/2016.08.27-reliability-prelim_reliability_combined_human.xlsx`\n",
    "\n",
    "- and \"`prelim_reliability_combined_human`\"\n",
    "\n",
    "    - this is old code results stored in the database.\n",
    "    - compare to \"final\" calculated with rewritten code - numbers should be identical.\n",
    "    - results in database for \"`prelim_reliability_combined_human`\", shown below, are not identical - but,  the results stored in Dropbox (see above) are identical to those for \"`prelim_reliability_combined_human_final`\".  Very strange.\n",
    "    \n",
    "Since they match original numbers, and since they are lower, I'll just use \"`prelim_reliability_combined_human_final`\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to calculate reliability numbers\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "This is the code invoked by the page [https://research.local/research/context/analysis/reliability/names/results/view](https://research.local/research/context/analysis/reliability/names/results/view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start to support python 3:\n",
    "from __future__ import unicode_literals\n",
    "from __future__ import division\n",
    "\n",
    "#==============================================================================#\n",
    "# ! imports\n",
    "#==============================================================================#\n",
    "\n",
    "# grouped by functional area, then alphabetical order by package, then\n",
    "#     alphabetical order by name of thing being imported.\n",
    "\n",
    "# context_analysis imports\n",
    "from context_analysis.reliability.reliability_names_analyzer import ReliabilityNamesAnalyzer\n",
    "\n",
    "#==============================================================================#\n",
    "# ! logic\n",
    "#==============================================================================#\n",
    "\n",
    "# declare variables\n",
    "my_analysis_instance = None\n",
    "label = \"\"\n",
    "indices_to_process = -1\n",
    "result_status = \"\"\n",
    "\n",
    "# make reliability instance\n",
    "my_analysis_instance = ReliabilityNamesAnalyzer()\n",
    "\n",
    "# database connection information - 2 options...  Enter it here:\n",
    "#my_analysis_instance.db_username = \"\"\n",
    "#my_analysis_instance.db_password = \"\"\n",
    "#my_analysis_instance.db_host = \"localhost\"\n",
    "#my_analysis_instance.db_name = \"sourcenet\"\n",
    "\n",
    "# Or set up the following properties in Django_Config, inside the django admins.\n",
    "#     All have application of: \"sourcenet-db-admin\":\n",
    "#     - db_username\n",
    "#     - db_password\n",
    "#     - db_host\n",
    "#     - db_port\n",
    "#     - db_name\n",
    "\n",
    "# run the analyze method, see what happens.\n",
    "#label = \"prelim_reliability_test\"\n",
    "#indices_to_process = 3\n",
    "#label = \"prelim_reliability_combined_human\"\n",
    "#indices_to_process = 3\n",
    "#label = \"name_data_test_combined_human\"\n",
    "#indices_to_process = 3\n",
    "#label = \"prelim_reliability_combined_human_final\"\n",
    "#indices_to_process = 3\n",
    "#label = \"prelim_reliability_combined_all\"\n",
    "#indices_to_process = 4\n",
    "#label = \"prelim_reliability_combined_all_final\"\n",
    "#indices_to_process = 4\n",
    "#label = \"prelim_reliability_test_human\"\n",
    "#indices_to_process = 3\n",
    "#label = \"prelim_reliability_test_all\"\n",
    "#indices_to_process = 4\n",
    "label = \"prelim_month\"\n",
    "indices_to_process = 2\n",
    "result_status = my_analysis_instance.analyze_reliability_names( label, indices_to_process )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original notebooks to calculate reliability\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Notebooks with the original, pre-web-page code to calculate reliability:\n",
    "\n",
    "- [phd_work/methods/reliability/prelim_month-reliability.ipynb](https://research.local:8000/user/jonathanmorgan/notebooks/work/django/research/work/phd_work/methods/reliability/prelim_month-reliability.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prelim_reliability_combined_human_final results\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Go to: [https://research.local/research/context/analysis/reliability/names/results/view](https://research.local/research/context/analysis/reliability/names/results/view)\n",
    "\n",
    "Label: `prelim_reliability_combined_human_final`\n",
    "\n",
    "Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"reliability_names_instance_view\" name=\"reliability_names_instance_view\">\n",
    "    <h3>Author reliability</h3>\n",
    "    <table class=\"gridtable\">\n",
    "        <tr>\n",
    "            <th>label</th>\n",
    "            <th>results ID</th>\n",
    "            <th>coder1 index</th>\n",
    "            <th>coder2 index</th>\n",
    "            <th>coder1 ID</th>\n",
    "            <th>coder2 ID</th>\n",
    "            <th>count</th>\n",
    "            <th>detect %</th>\n",
    "            <th>detect A</th>\n",
    "            <th>detect pi</th>\n",
    "            <th>lookup %</th>\n",
    "            <th>lookup A</th>\n",
    "            <th>lookup-NZ %</th>\n",
    "            <th>lookup-NZ A</th>\n",
    "            <th>lookup-NZ N</th>\n",
    "            <th>type %</th>\n",
    "            <th>type A</th>\n",
    "            <th>type pi</th>\n",
    "            <th>type-NZ %</th>\n",
    "            <th>type-NZ A</th>\n",
    "            <th>type-NZ pi</th>\n",
    "            <th>type-NZ N</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>prelim_reliability_combined_human_final</td>\n",
    "            <td>10</td>\n",
    "            <td>1</td>\n",
    "            <td>2</td>\n",
    "            <td></td>\n",
    "            <td></td>\n",
    "            <td>98</td>\n",
    "            <td>0.9795918367</td>\n",
    "            <td>-0.0051546392</td>\n",
    "            <td>0.9727891156</td>\n",
    "            <!-- Lookup -->\n",
    "            <td>0.9795918367</td>\n",
    "            <td>0.9791722296</td>\n",
    "            <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>96</td>\n",
    "            <td>0.9795918367</td>\n",
    "            <td>-0.0051546392</td>\n",
    "            <td>0.9782312925</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>96</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>prelim_reliability_combined_human_final</td>\n",
    "            <td>11</td>\n",
    "            <td>1</td>\n",
    "            <td>3</td>\n",
    "            <td></td>\n",
    "            <td>10</td>\n",
    "            <td>98</td>\n",
    "            <td>0.9897959184</td>\n",
    "            <td>0.0000000000</td>\n",
    "            <td>0.9863945578</td>\n",
    "            <!-- Lookup -->\n",
    "            <td>0.9897959184</td>\n",
    "            <td>0.9895861148</td>\n",
    "            <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>97</td>\n",
    "            <td>0.9897959184</td>\n",
    "            <td>0.0000000000</td>\n",
    "            <td>0.9891156463</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>97</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>prelim_reliability_combined_human_final</td>\n",
    "            <td>12</td>\n",
    "            <td>2</td>\n",
    "            <td>3</td>\n",
    "            <td></td>\n",
    "            <td>10</td>\n",
    "            <td>98</td>\n",
    "            <td>0.9897959184</td>\n",
    "            <td>0.0000000000</td>\n",
    "            <td>0.9863945578</td>\n",
    "            <!-- Lookup -->\n",
    "            <td>0.9897959184</td>\n",
    "            <td>0.9895816637</td>\n",
    "            <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>97</td>\n",
    "            <td>0.9897959184</td>\n",
    "            <td>0.0000000000</td>\n",
    "            <td>0.9891156463</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>97</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><strong>Averages:</strong></td>\n",
    "            <td></td> <!-- results_instance.id -->\n",
    "            <td></td> <!-- results_instance.coder1_coder_index -->\n",
    "            <td></td> <!-- results_instance.coder2_coder_index -->\n",
    "            <td></td> <!-- results_instance.coder1.id -->\n",
    "            <td></td> <!-- results_instance.coder2.id -->\n",
    "            <td>98</td>\n",
    "            <td>0.9863945578333333333333333333</td>\n",
    "            <td>-0.001718213066666666666666666667</td>\n",
    "            <td>0.9818594104</td>\n",
    "            <!-- Lookup -->\n",
    "            <td>0.9863945578333333333333333333</td>\n",
    "            <td>0.9861133360333333333333333333</td>\n",
    "            <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>96.66666666666666666666666667</td>\n",
    "            <td>0.9863945578333333333333333333</td>\n",
    "            <td>-0.001718213066666666666666666667</td>\n",
    "            <td>0.9854875283666666666666666667</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>96.66666666666666666666666667</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "    <hr />\n",
    "    <h3>Subject reliability</h3>\n",
    "    <table class=\"gridtable\">\n",
    "        <tr>\n",
    "            <th>label</th>\n",
    "            <th>results ID</th>\n",
    "            <th>coder1 index</th>\n",
    "            <th>coder2 index</th>\n",
    "            <th>coder1 ID</th>\n",
    "            <th>coder2 ID</th>\n",
    "            <th>count</th>\n",
    "            <th>detect %</th>\n",
    "            <th>detect A</th>\n",
    "            <th>detect pi</th>\n",
    "            <th>lookup %</th>\n",
    "            <th>lookup A</th>\n",
    "            <th>lookup-NZ %</th>\n",
    "            <th>lookup-NZ A</th>\n",
    "            <th>lookup-NZ N</th>\n",
    "            <th>type %</th>\n",
    "            <th>type A</th>\n",
    "            <th>type pi</th>\n",
    "            <th>type-NZ %</th>\n",
    "            <th>type-NZ A</th>\n",
    "            <th>type-NZ pi</th>\n",
    "            <th>type-NZ N</th>\n",
    "            <th>1st graf %</th>\n",
    "            <th>1st graf A</th>\n",
    "            <th>1st index %</th>\n",
    "            <th>1st index A</th>\n",
    "            <th>org hash %</th>\n",
    "            <th>org hash A</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>prelim_reliability_combined_human_final</td>\n",
    "            <td>10</td>\n",
    "            <td>1</td>\n",
    "            <td>2</td>\n",
    "            <td></td>\n",
    "            <td></td>\n",
    "            <td>399</td>\n",
    "            <td>0.9122807018</td>\n",
    "            <td>0.1407669798</td>\n",
    "            <td>0.8830409357</td>\n",
    "            <!-- Lookup -->\n",
    "            <td>0.9122807018</td>\n",
    "            <td>0.9118944818</td>\n",
    "            <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>360</td>\n",
    "            <td>0.8922305764</td>\n",
    "            <td>0.7955934892</td>\n",
    "            <td>0.8850459482</td>\n",
    "            <td>0.9777777778</td>\n",
    "            <td>0.9523699116</td>\n",
    "            <td>0.9750000000</td>\n",
    "            <td>360</td>\n",
    "            <td>0.5363408521</td>\n",
    "            <td>0.9573273382</td>\n",
    "            <td>0.5087719298</td>\n",
    "            <td>0.9101064582</td>\n",
    "            <td>0.5839598997</td>\n",
    "            <td>0.5626481371</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>prelim_reliability_combined_human_final</td>\n",
    "            <td>11</td>\n",
    "            <td>1</td>\n",
    "            <td>3</td>\n",
    "            <td></td>\n",
    "            <td>10</td>\n",
    "            <td>399</td>\n",
    "            <td>0.8972431078</td>\n",
    "            <td>0.2505447123</td>\n",
    "            <td>0.8629908104</td>\n",
    "            <!-- Lookup -->\n",
    "            <td>0.8972431078</td>\n",
    "            <td>0.8965318523</td>\n",
    "            <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>349</td>\n",
    "            <td>0.8746867168</td>\n",
    "            <td>0.7694145966</td>\n",
    "            <td>0.8663324979</td>\n",
    "            <td>0.9742120344</td>\n",
    "            <td>0.9446517907</td>\n",
    "            <td>0.9709885387</td>\n",
    "            <td>349</td>\n",
    "            <td>0.4962406015</td>\n",
    "            <td>0.9117737368</td>\n",
    "            <td>0.4736842105</td>\n",
    "            <td>0.8747093023</td>\n",
    "            <td>0.5664160401</td>\n",
    "            <td>0.5380809123</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>prelim_reliability_combined_human_final</td>\n",
    "            <td>12</td>\n",
    "            <td>2</td>\n",
    "            <td>3</td>\n",
    "            <td></td>\n",
    "            <td>10</td>\n",
    "            <td>399</td>\n",
    "            <td>0.9147869674</td>\n",
    "            <td>0.1062664908</td>\n",
    "            <td>0.8863826232</td>\n",
    "            <!-- Lookup -->\n",
    "            <td>0.9147869674</td>\n",
    "            <td>0.9144471807</td>\n",
    "            <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>362</td>\n",
    "            <td>0.8972431078</td>\n",
    "            <td>0.8055310893</td>\n",
    "            <td>0.8903926483</td>\n",
    "            <td>0.9806629834</td>\n",
    "            <td>0.9591258208</td>\n",
    "            <td>0.9782458564</td>\n",
    "            <td>362</td>\n",
    "            <td>0.5037593985</td>\n",
    "            <td>0.9086158161</td>\n",
    "            <td>0.4812030075</td>\n",
    "            <td>0.8724327241</td>\n",
    "            <td>0.5664160401</td>\n",
    "            <td>0.5514299936</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><strong>Averages:</strong></td>\n",
    "            <td></td> <!-- results_instance.id -->\n",
    "            <td></td> <!-- results_instance.coder1_coder_index -->\n",
    "            <td></td> <!-- results_instance.coder2_coder_index -->\n",
    "            <td></td> <!-- results_instance.coder1.id -->\n",
    "            <td></td> <!-- results_instance.coder2.id -->\n",
    "            <td>399</td>\n",
    "            <td>0.9081035923333333333333333333</td>\n",
    "            <td>0.1658593943</td>\n",
    "            <td>0.8774714564333333333333333333</td>\n",
    "            <!-- Lookup -->\n",
    "            <td>0.9081035923333333333333333333</td>\n",
    "            <td>0.9076245049333333333333333333</td>\n",
    "            <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>357</td>\n",
    "            <td>0.8880534670</td>\n",
    "            <td>0.7901797250333333333333333333</td>\n",
    "            <td>0.8805903648</td>\n",
    "            <td>0.9775509318666666666666666667</td>\n",
    "            <td>0.9520491743666666666666666667</td>\n",
    "            <td>0.9747447983666666666666666667</td>\n",
    "            <td>357</td>\n",
    "            <td>0.5121136173666666666666666667</td>\n",
    "            <td>0.9259056303666666666666666667</td>\n",
    "            <td>0.4878863826</td>\n",
    "            <td>0.8857494948666666666666666667</td>\n",
    "            <td>0.5722639933</td>\n",
    "            <td>0.5507196810</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prelim_reliability_combined_human results\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "This is not the latest code, and so not reporting it, but including it here for reference.\n",
    "\n",
    "Go to: [https://research.local/research/context/analysis/reliability/names/results/view](https://research.local/research/context/analysis/reliability/names/results/view)\n",
    "\n",
    "Label: `prelim_reliability_combined_human`\n",
    "\n",
    "Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"reliability_names_instance_view\" name=\"reliability_names_instance_view\">\n",
    "    <h3>Author reliability</h3>\n",
    "    <table class=\"gridtable\">\n",
    "        <tr>\n",
    "            <th>label</th>\n",
    "            <th>results ID</th>\n",
    "            <th>coder1 index</th>\n",
    "            <th>coder2 index</th>\n",
    "            <th>coder1 ID</th>\n",
    "            <th>coder2 ID</th>\n",
    "            <th>count</th>\n",
    "            <th>detect %</th>\n",
    "            <th>detect A</th>\n",
    "            <th>detect pi</th>\n",
    "            <th>lookup %</th>\n",
    "            <th>lookup A</th>\n",
    "            <th>lookup-NZ %</th>\n",
    "            <th>lookup-NZ A</th>\n",
    "            <th>lookup-NZ N</th>\n",
    "            <th>type %</th>\n",
    "            <th>type A</th>\n",
    "            <th>type pi</th>\n",
    "            <th>type-NZ %</th>\n",
    "            <th>type-NZ A</th>\n",
    "            <th>type-NZ pi</th>\n",
    "            <th>type-NZ N</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>prelim_reliability_combined_human</td>\n",
    "            <td>37</td>\n",
    "            <td>1</td>\n",
    "            <td>2</td>\n",
    "            <td></td>\n",
    "            <td>9</td>\n",
    "            <td>98</td>\n",
    "            <td>0.9795918367</td>\n",
    "            <td>-0.0051546392</td>\n",
    "            <td>0.9727891156</td>\n",
    "            <!-- Lookup -->\n",
    "            <td>0.9795918367</td>\n",
    "            <td>0.9791722296</td>\n",
    "            <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>96</td>\n",
    "            <td>0.9795918367</td>\n",
    "            <td>-0.0051546392</td>\n",
    "            <td>0.9782312925</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>96</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>prelim_reliability_combined_human</td>\n",
    "            <td>38</td>\n",
    "            <td>1</td>\n",
    "            <td>3</td>\n",
    "            <td></td>\n",
    "            <td></td>\n",
    "            <td>98</td>\n",
    "            <td>0.9897959184</td>\n",
    "            <td>0.0000000000</td>\n",
    "            <td>0.9863945578</td>\n",
    "            <!-- Lookup -->\n",
    "            <td>0.9897959184</td>\n",
    "            <td>0.9895861148</td>\n",
    "            <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>97</td>\n",
    "            <td>0.9897959184</td>\n",
    "            <td>0.0000000000</td>\n",
    "            <td>0.9891156463</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>97</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>prelim_reliability_combined_human</td>\n",
    "            <td>39</td>\n",
    "            <td>2</td>\n",
    "            <td>3</td>\n",
    "            <td>9</td>\n",
    "            <td></td>\n",
    "            <td>98</td>\n",
    "            <td>0.9897959184</td>\n",
    "            <td>0.0000000000</td>\n",
    "            <td>0.9863945578</td>\n",
    "            <!-- Lookup -->\n",
    "            <td>0.9897959184</td>\n",
    "            <td>0.9895816637</td>\n",
    "            <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>97</td>\n",
    "            <td>0.9897959184</td>\n",
    "            <td>0.0000000000</td>\n",
    "            <td>0.9891156463</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>97</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><strong>Averages:</strong></td>\n",
    "            <td></td> <!-- results_instance.id -->\n",
    "            <td></td> <!-- results_instance.coder1_coder_index -->\n",
    "            <td></td> <!-- results_instance.coder2_coder_index -->\n",
    "            <td></td> <!-- results_instance.coder1.id -->\n",
    "            <td></td> <!-- results_instance.coder2.id -->\n",
    "            <td>98</td>\n",
    "            <td>0.9863945578333333333333333333</td>\n",
    "            <td>-0.001718213066666666666666666667</td>\n",
    "            <td>0.9818594104</td>\n",
    "            <!-- Lookup -->\n",
    "            <td>0.9863945578333333333333333333</td>\n",
    "            <td>0.9861133360333333333333333333</td>\n",
    "            <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>96.66666666666666666666666667</td>\n",
    "            <td>0.9863945578333333333333333333</td>\n",
    "            <td>-0.001718213066666666666666666667</td>\n",
    "            <td>0.9854875283666666666666666667</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>96.66666666666666666666666667</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "    <hr />\n",
    "    <h3>Subject reliability</h3>\n",
    "    <table class=\"gridtable\">\n",
    "        <tr>\n",
    "            <th>label</th>\n",
    "            <th>results ID</th>\n",
    "            <th>coder1 index</th>\n",
    "            <th>coder2 index</th>\n",
    "            <th>coder1 ID</th>\n",
    "            <th>coder2 ID</th>\n",
    "            <th>count</th>\n",
    "            <th>detect %</th>\n",
    "            <th>detect A</th>\n",
    "            <th>detect pi</th>\n",
    "            <th>lookup %</th>\n",
    "            <th>lookup A</th>\n",
    "            <th>lookup-NZ %</th>\n",
    "            <th>lookup-NZ A</th>\n",
    "            <th>lookup-NZ N</th>\n",
    "            <th>type %</th>\n",
    "            <th>type A</th>\n",
    "            <th>type pi</th>\n",
    "            <th>type-NZ %</th>\n",
    "            <th>type-NZ A</th>\n",
    "            <th>type-NZ pi</th>\n",
    "            <th>type-NZ N</th>\n",
    "            <th>1st graf %</th>\n",
    "            <th>1st graf A</th>\n",
    "            <th>1st index %</th>\n",
    "            <th>1st index A</th>\n",
    "            <th>org hash %</th>\n",
    "            <th>org hash A</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>prelim_reliability_combined_human</td>\n",
    "            <td>37</td>\n",
    "            <td>1</td>\n",
    "            <td>2</td>\n",
    "            <td></td>\n",
    "            <td>9</td>\n",
    "            <td>398</td>\n",
    "            <td>0.9170854271</td>\n",
    "            <td>0.1524794056</td>\n",
    "            <td>0.8894472362</td>\n",
    "            <!-- Lookup -->\n",
    "            <td>0.9145728643</td>\n",
    "            <td>0.9142174364</td>\n",
    "            <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "            <td>0.9972299169</td>\n",
    "            <td>0.9972247563</td>\n",
    "            <td>361</td>\n",
    "            <td>0.8969849246</td>\n",
    "            <td>0.8038230285</td>\n",
    "            <td>0.8901172529</td>\n",
    "            <td>0.9778393352</td>\n",
    "            <td>0.9524469067</td>\n",
    "            <td>0.9750692521</td>\n",
    "            <td>361</td>\n",
    "            <td>0.5402010050</td>\n",
    "            <td>0.9575247587</td>\n",
    "            <td>0.5125628141</td>\n",
    "            <td>0.9105087189</td>\n",
    "            <td>0.5854271357</td>\n",
    "            <td>0.5645628699</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>prelim_reliability_combined_human</td>\n",
    "            <td>38</td>\n",
    "            <td>1</td>\n",
    "            <td>3</td>\n",
    "            <td></td>\n",
    "            <td></td>\n",
    "            <td>398</td>\n",
    "            <td>0.9020100503</td>\n",
    "            <td>0.2639413147</td>\n",
    "            <td>0.8693467337</td>\n",
    "            <!-- Lookup -->\n",
    "            <td>0.8994974874</td>\n",
    "            <td>0.8988353338</td>\n",
    "            <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "            <td>0.9971428571</td>\n",
    "            <td>0.9971374163</td>\n",
    "            <td>350</td>\n",
    "            <td>0.8793969849</td>\n",
    "            <td>0.7772888300</td>\n",
    "            <td>0.8713567839</td>\n",
    "            <td>0.9742857143</td>\n",
    "            <td>0.9447435683</td>\n",
    "            <td>0.9710714286</td>\n",
    "            <td>350</td>\n",
    "            <td>0.5000000000</td>\n",
    "            <td>0.9121951220</td>\n",
    "            <td>0.4773869347</td>\n",
    "            <td>0.8752880184</td>\n",
    "            <td>0.5703517588</td>\n",
    "            <td>0.5427100012</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>prelim_reliability_combined_human</td>\n",
    "            <td>39</td>\n",
    "            <td>2</td>\n",
    "            <td>3</td>\n",
    "            <td>9</td>\n",
    "            <td></td>\n",
    "            <td>398</td>\n",
    "            <td>0.9145728643</td>\n",
    "            <td>0.0615886682</td>\n",
    "            <td>0.8860971524</td>\n",
    "            <!-- Lookup -->\n",
    "            <td>0.9145728643</td>\n",
    "            <td>0.9142514529</td>\n",
    "            <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>362</td>\n",
    "            <td>0.8969849246</td>\n",
    "            <td>0.8042530448</td>\n",
    "            <td>0.8901172529</td>\n",
    "            <td>0.9806629834</td>\n",
    "            <td>0.9591258208</td>\n",
    "            <td>0.9782458564</td>\n",
    "            <td>362</td>\n",
    "            <td>0.5050251256</td>\n",
    "            <td>0.9086158161</td>\n",
    "            <td>0.4824120603</td>\n",
    "            <td>0.8724327241</td>\n",
    "            <td>0.5653266332</td>\n",
    "            <td>0.5506229232</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><strong>Averages:</strong></td>\n",
    "            <td></td> <!-- results_instance.id -->\n",
    "            <td></td> <!-- results_instance.coder1_coder_index -->\n",
    "            <td></td> <!-- results_instance.coder2_coder_index -->\n",
    "            <td></td> <!-- results_instance.coder1.id -->\n",
    "            <td></td> <!-- results_instance.coder2.id -->\n",
    "            <td>398</td>\n",
    "            <td>0.9112227805666666666666666667</td>\n",
    "            <td>0.1593364628333333333333333333</td>\n",
    "            <td>0.8816303741</td>\n",
    "            <!-- Lookup -->\n",
    "            <td>0.9095477386666666666666666667</td>\n",
    "            <td>0.9091014077</td>\n",
    "            <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "            <td>0.9981242580</td>\n",
    "            <td>0.9981207242</td>\n",
    "            <td>357.6666666666666666666666667</td>\n",
    "            <td>0.8911222780333333333333333333</td>\n",
    "            <td>0.7951216344333333333333333333</td>\n",
    "            <td>0.8838637632333333333333333333</td>\n",
    "            <td>0.9775960109666666666666666667</td>\n",
    "            <td>0.9521054319333333333333333333</td>\n",
    "            <td>0.9747955123666666666666666667</td>\n",
    "            <td>357.6666666666666666666666667</td>\n",
    "            <td>0.5150753768666666666666666667</td>\n",
    "            <td>0.9261118989333333333333333333</td>\n",
    "            <td>0.4907872697</td>\n",
    "            <td>0.8860764871333333333333333333</td>\n",
    "            <td>0.5737018425666666666666666667</td>\n",
    "            <td>0.5526319314333333333333333333</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation for automated assessment\n",
    "\n",
    "- Bacl to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "In preparation for using the human coding as a standard against which data created with automated tool is assessed, I performed a couple of cleaning steps:\n",
    "\n",
    "- **[Single name removal](#Single-name-removal)** - In CA protocol, we ignored people who were referred to only with a single name part, to avoid potential for ambiguity when assigning a last name.  When preparing for assessment, I first went through and removed all people who were captured with only a single name by the automated tool.\n",
    "- **[Evaluating disagreements](#Evaluating-disagreements)** - In order to make the human-created data as good a reflection of correct data as possible, I then reviewed each disagreement between the human and computer manually.  I assessed the disagreement based on the content analysis protocol and on having been a news writer and editor.  If the human coding was in error, I fixed the human coding (and the content analysis protocol, if it turned out to have been a problem with the protocol)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single name removal\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "In CA protocol, we ignored people who were referred to only with a single name part, to avoid potential for ambiguity when assigning a last name.  Removed all instances where person was only ever referenced using a single-word (really single-part - only first name, mostly) name, to remove potential source of ambiguity.  \n",
    "\n",
    "Example:  \"Joe Smith's wife Sandy\" - could assume her name is Sandy Smith, but it could be something else.  For this study, removing that potential ambiguity by discarding instances where a given person's full name is never used.\n",
    "\n",
    "- Notebook with aggregated information on what was removed, and notes: [2017.06.01-work_log-prelim_month-remove_single_names.ipynb](https://research.local:8000/user/jonathanmorgan/notebooks/work/django/research/work/phd_work/methods/2017.06.01-work_log-prelim_month-remove_single_names.ipynb)\n",
    "- Exceptions:\n",
    "\n",
    "    - If the single-name was an error on the part of either computer or human, where one party detected the full name but the other incorrectly detected just a single name, the Reliability_Names records for the two were merged so the same person being detected was captured, and then the error is subsumed in the agreement and precision-recall analysis.\n",
    "    - Since, post-reliability, the human coding is being used as the standard against which the quality of the automated coding is compared, if the human made an error, the coding was corrected to prepare for assessing the automated coding (see non-destructive method for correcting erroneous human coding below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "- removed single names because of potential for ambiguity\n",
    "- Usually means you lose spouses and children of subjects who are not subjects themselves.\n",
    "- 143 instances of single name references removed from coding data.\n",
    "- 3 instances were automated errors that needed to be merged with a more accurate human-coded record.\n",
    "- 1 instance was human error, and was corrected.\n",
    "- Types of single-named entities:\n",
    "\n",
    "    - most were family members of subjects not relevant to the story (spouses, children, parents, grandparents, etc.).\n",
    "    - biblical characters (Mary, Jesus)\n",
    "    - famous people (Obama)\n",
    "    - one homeless man who wouldn't give last name (article [23982](http://research.local/research/context/text/article/article_data/view_with_text/?article_id=23982)).\n",
    "    - a few were misspellings (so a wrong spelling of a last name only used once, without first name).\n",
    "    - pets\n",
    "    - out and out automated errors - place name (Example: Saigon - Article [23921](http://research.local/research/context/text/article/article_data/view_with_text/?article_id=23921)), parts of song titles (\"Twinkle\" - Article [23491](http://research.local/research/context/text/article/article_data/view_with_text/?article_id=23491)), planet names (\"Saturn\" -  Article [23559](http://research.local/research/context/text/article/article_data/view_with_text/?article_id=23559)), or a part of a business name were detected as a person name.\n",
    "\n",
    "- Of 143 single names removed from analysis data, 15 instances were out-and-out errors (89.5% correct):\n",
    "\n",
    "    - 3 partial-name detects that had to be merged.\n",
    "    - 3 references to named pet chickens (Article [23065](http://research.local/research/context/text/article/article_data/view_with_text/?article_id=23065) - Betty, Mabel, and Violet).\n",
    "    - 9 errors where a place name (Example: Saigon - Article [23921](http://research.local/research/context/text/article/article_data/view_with_text/?article_id=23921)), parts of song titles (\"Twinkle\" - Article [23491](http://research.local/research/context/text/article/article_data/view_with_text/?article_id=23491)), planet names (\"Saturn\" -  Article [23559](http://research.local/research/context/text/article/article_data/view_with_text/?article_id=23559)), or a part of a business name were detected as a person name.\n",
    "\n",
    "- Only noted one instance where the single-name person was quoted (\"Linda\") - Article [23223](http://research.local/research/context/text/article/article_data/view_with_text/?article_id=23223) | Article_Data 3212 | 12096 (AS) - Linda ( id = 2911; capture_method = OpenCalais_REST_API_v2 ) (quoted; individual) ==> name: Linda |\n",
    "\n",
    "    - Actually was quoted, but just a one-word name, no explicit mention of last name. Need to keep track of relationship to others in story (\"wife of X\").\n",
    "\n",
    "- Assessment - OpenCalais is actually quite good at identifying single name-part references to people, for the most part.  It even sometimes tacked on a last name based on the context in the article.  But, most of the time it did not.  Appears to be built to know of this potential, but tuned to only take action when it is certain.  Not built to assume name relationships implied by things like \"survived by\" or \"Smith's children X, Y, and Z\".  This is something that could be leveraged in a post-processing step if single names were left in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error detail\n",
    "\n",
    "Errors:\n",
    "\n",
    "- Article 21116\n",
    "\n",
    "    - RANDOM - \"More...\"\n",
    "    - Paragraph 12: More than 600 works of art were added to the museum's collection under her leadership, most notably Ellsworth Kelly's \"Blue White,\" a 25-foot- tall wall sculpture that was commissioned in 2006 for the museum's entry pavilion.\n",
    "    - User: 2 - automated (OpenCalais_REST_API_v2)\n",
    "    - Article [21116](http://research.local/research/context/text/article/article_data/view_with_text/?article_id=21116) | 11288 (AS) - More ( id = 2817; capture_method = OpenCalais_REST_API_v2 ) (mentioned; individual) ==> name: More\n",
    "    \n",
    "- Article 22765\n",
    "\n",
    "    - PLACE NAME\n",
    "    - Paragraph 8: Gavin Orchards has started selling farm-direct apples to Grand Rapids and Fruitport schools. The biggest challenge is the time it takes to deliver low-volume orders, said Mike Gavin, who runs the 240-acre farm near Coopersville with his brother, Dave. \n",
    "    - User: 2 - automated (OpenCalais_REST_API_v2)\n",
    "    - Article [22765](http://research.local/research/context/text/article/article_data/view_with_text/?article_id=22765) | 11806 (AS) - Coopersville ( id = 2869; capture_method = OpenCalais_REST_API_v2 ) (mentioned; individual) ==> name: Coopersville\n",
    "    \n",
    "- Article 23055\n",
    "\n",
    "    - PLACE NAME\n",
    "    - Paragraph 2: While they are not disputing the state DHS' recent decision to reassign longtime Kent County DHS Director Andy Zylstra from Grand Rapids to Lansing, legislators are asking state officials to improve their communications with local workers, state Rep. Robert Dean said.\n",
    "    - User: 2 - automated (OpenCalais_REST_API_v2)\n",
    "    - Article [23055](http://research.local/research/context/text/article/article_data/view_with_text/?article_id=23055) | 12014 (AS) - Lansing ( id = 2902; capture_method = OpenCalais_REST_API_v2 ) (mentioned; individual) ==> name: Lansing\n",
    "    \n",
    "- Article 23491\n",
    "\n",
    "    - SONG LYRIC\n",
    "    - Paragraph 39: \"As the program was wrapping up and the kids were leaving the stage, one of the 2-year-olds ran up to the microphone and started singing 'Twinkle, twinkle Christmas star ...' to the tune of 'Twinkle, Twinkle Little Star.' It was so funny and cute.\"\n",
    "    - User: 2 - automated (OpenCalais_REST_API_v2)\n",
    "    - Portion of Song title: | 10448 | Article [23491](http://research.local/research/context/text/article/article_data/view_with_text/?article_id=23491) | Article_Data [3249](http://research.local/research/context/text/article/article_data/view/?article_id=23491&article_data_id_select=3249) | 12299 (AS) - Twinkle ( id = 2938; capture_method = OpenCalais_REST_API_v2 ) (mentioned; individual) ==> name: Twinkle |\n",
    "    \n",
    "- Article 23559\n",
    "\n",
    "    - PLANET NAME\n",
    "    - Paragraph 10: \"Three appear: Saturn joins Mars and Venus in March so, through spring and most of summer, there will be three naked eye planets in the evening sky. They will be joined briefly by elusive Mercury in April.\"\n",
    "    - User: 2 - automated (OpenCalais_REST_API_v2)\n",
    "    - \"Saturn joins...\" - | 7961 | Article [23559](http://research.local/research/context/text/article/article_data/view_with_text/?article_id=23559) | Article_Data [3254](http://research.local/research/context/text/article/article_data/view/?article_id=23559&article_data_id_select=3254) | 12315 (AS) - Saturn ( id = 2940; capture_method = OpenCalais_REST_API_v2 ) (mentioned; individual) ==> name: Saturn |\n",
    "\n",
    "- Article 23631\n",
    "\n",
    "    - SCHOOL NAME - \"Madonna\"\n",
    "    - Paragraph 6: \"The school is planning a tribute during halftime of the first night's Hope game Tuesday against Madonna. There will also be other activities open to former players and family members connected to DeVette.\"\n",
    "    - User: 2 - automated (OpenCalais_REST_API_v2)\n",
    "    - | 8120 | Article [23631](http://research.local/research/context/text/article/article_data/view_with_text/?article_id=23631) | Article_Data [3274](http://research.local/research/context/text/article/article_data/view/?article_id=23631&article_data_id_select=3274) | 12404 (AS) - Madonna ( id = 2946; capture_method = OpenCalais_REST_API_v2 ) (mentioned; individual) ==> name: Madonna |\n",
    "\n",
    "- Article 23631\n",
    "\n",
    "    - SCHOOL NAME\n",
    "    - Paragraph 7: \"We have a dinner scheduled in his honor and memory during the first game of the tournament (between Davenport and Grace Bible),\" Van Wieren said. \"We had people that had a hard time getting to the funeral, so this will be a way that people attending can share memories of Russ.\" \n",
    "    - User: 2 - automated (OpenCalais_REST_API_v2)\n",
    "    - | 8119 | Article [23631](http://research.local/research/context/text/article/article_data/view_with_text/?article_id=23631) | Article_Data [3274](http://research.local/research/context/text/article/article_data/view/?article_id=23631&article_data_id_select=3274) | 12405 (AS) - Davenport ( id = 2947; capture_method = OpenCalais_REST_API_v2 ) (mentioned; individual) ==> name: Davenport |\n",
    "\n",
    "- Article 23921\n",
    "\n",
    "    - PLACE\n",
    "    - Paragraph 6: It was 1975 when he fled his native Saigon as it fell to the North Vietnamese Army.\n",
    "    - User: 2 - automated (OpenCalais_REST_API_v2)\n",
    "    - | 8981 | Article [23921](http://research.local/research/context/text/article/article_data/view_with_text/?article_id=23921) | Article_Data [3283](http://research.local/research/context/text/article/article_data/view/?article_id=23921&article_data_id_select=3283) | 12444 (AS) - Saigon ( id = 2952; capture_method = OpenCalais_REST_API_v2 ) (mentioned; individual) ==> name: Saigon |\n",
    "    \n",
    "- Article 23974\n",
    "\n",
    "    - BUSINESS NAME - Detected part of business name as person.\n",
    "    - Paragraph 14: Trevor Ditmar, a two-year employee at Smitty's Specialty Beverage, 1489 Lake Drive SE, said customers are vowing to quit in increasing numbers due to the product change.\n",
    "    - User: 2 - automated (OpenCalais_REST_API_v2)\n",
    "    - | 8185 | Article [23974](http://research.local/research/context/text/article/article_data/view_with_text/?article_id=23974) | Article_Data [3292](http://research.local/research/context/text/article/article_data/view/?article_id=23974&article_data_id_select=3292) | 12492 (AS) - Smitty ( id = 2789; capture_method = OpenCalais_REST_API_v2 ) (mentioned; individual) ==> name: Smitty |\n",
    "    \n",
    "- Article 21080\n",
    "\n",
    "    - MISSPELLING\n",
    "    - Paragraph 21: \"Ben was in middle school when his father was in Desert Storm, and we'd watch the developments on TV,\" Patti Vab Syzkle said. \"He'd say, 'It's OK, Mom. It's just a skirmish.'\"\n",
    "    - User: 2 - automated (OpenCalais_REST_API_v2)\n",
    "    - Made new person: 11246 (AS) - Syzkle, Patti ( id = 2813; capture_method = OpenCalais_REST_API_v2 ) (quoted; individual) ==> name: Patti Vab Syzkle\n",
    "    - Should have mapped to: 11248 (AS) - Van Syzkle, Patti ( id = 1750; capture_method = OpenCalais_REST_API_v2 ) (mentioned; individual) ==> name: Patti Van Syzkle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating disagreements\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Moved to [2018.02.09-prelim-disagreement_analysis.ipynb](/user/jonathanmorgan/notebooks/work/django/research/work/phd_work/methods/evaluate_disagreements/2018.02.09-prelim-disagreement_analysis.ipynb).\n",
    "\n",
    "Details:\n",
    "\n",
    "- For numbers used in results, see: `2018.02.09-prelim-disagreement_analysis.ipynb` --> [Deleted `Reliability_Names` records](https://research.local:8000/user/jonathanmorgan/notebooks/work/django/research/work/phd_work/methods/evaluate_disagreements/2018.02.09-prelim-disagreement_analysis.ipynb#Deleted-Reliability_Names-records)\n",
    "- For discussion, see disagreement reason summary: `2018.02.09-prelim-disagreement_analysis.ipynb` --> [disagreement reason summary](https://research.local:8000/user/jonathanmorgan/notebooks/work/django/research/work/phd_work/methods/evaluate_disagreements/2018.02.09-prelim-disagreement_analysis.ipynb#disagreement-reason-summary)\n",
    "- There is also a tag summary, but I switched to updating fields halfway through, so the reason summary linked above is more complete.  Tag summary: `2018.02.09-prelim-disagreement_analysis.ipynb` --> [review tags](https://research.local:8000/user/jonathanmorgan/notebooks/work/django/research/work/phd_work/methods/evaluate_disagreements/2018.02.09-prelim-disagreement_analysis.ipynb#review-tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated coder evaluation\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `prelim_month` vs. `prelim_month_human`\n",
    "\n",
    "- `prelim_month` - Reliability_Names data with label `prelim_month` where coder 1 is \"ground truth\" (corrected human coding) and coder 2 is data created by OpenCalais.\n",
    "- `prelim_month_human` - Reliability_Names data with label `prelim_month_human` where coder 1 is \"ground truth\" (corrected human coding) and coder 2 is uncorrected human coding (for comparison)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision and Recall - `prelim_month`\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Calculate precision and recall for automated versus baseline - set it up so that coder 1 is human coding with ground_truth user having precedence, set up coder 2 so it is the automated coding output.\n",
    "\n",
    "- Jupyter notebooks:\n",
    "\n",
    "    - Create Reliability_Names data where coder 1 is ground truth, and coder 2 is automated coder: [https://research.local:8000/user/jonathanmorgan/notebooks/work/django/research/work/phd_work/methods/data_creation/prelim_month-create_Reliability_Names_data.ipynb](https://research.local:8000/user/jonathanmorgan/notebooks/work/django/research/work/phd_work/methods/data_creation/prelim_month-create_Reliability_Names_data.ipynb)\n",
    "        \n",
    "        - configuration: [https://research.local:8000/user/jonathanmorgan/edit/work/django/research/work/phd_work/methods/config-coder_index-prelim_month.py](https://research.local:8000/user/jonathanmorgan/edit/work/django/research/work/phd_work/methods/config-coder_index-prelim_month.py)\n",
    "        \n",
    "    - Calculate confusion matrices and precision/recall/F1: [https://research.local:8000/user/jonathanmorgan/notebooks/work/django/research/work/phd_work/methods/precision_recall/prelim_month-confusion_matrix.ipynb](https://research.local:8000/user/jonathanmorgan/notebooks/work/django/research/work/phd_work/methods/precision_recall/prelim_month-confusion_matrix.ipynb)\n",
    "\n",
    "- results are in `Dropbox/academia/MSU/program_stuff/prelim_paper/analysis/precision_and_recall/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"reliability_names_instance_view\" name=\"reliability_names_instance_view\">\n",
    "    <h3>Automated Confusion Matrix and Scores</h3>\n",
    "    <table class=\"gridtable\">\n",
    "        <tr>\n",
    "            <th>score</th>\n",
    "            <th>detect</th>\n",
    "            <th>type \"author\"</th>\n",
    "            <th>type \"subject\"</th>\n",
    "            <th>type \"source\"</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>TP</td>\n",
    "            <td>2315</td>\n",
    "            <td>454</td>\n",
    "            <td>631</td>\n",
    "            <td>1080</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>TN</td>\n",
    "            <td>0</td>\n",
    "            <td>1990</td>\n",
    "            <td>1580</td>\n",
    "            <td>1172</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>FP</td>\n",
    "            <td>68</td>\n",
    "            <td>0</td>\n",
    "            <td>152</td>\n",
    "            <td>66</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>FN</td>\n",
    "            <td>63</td>\n",
    "            <td>2</td>\n",
    "            <td>83</td>\n",
    "            <td>128</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>precision</td>\n",
    "            <td>0.97146</td>\n",
    "            <td>1</td>\n",
    "            <td>0.80587</td>\n",
    "            <td>0.94241</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>recall</td>\n",
    "            <td>0.97351</td>\n",
    "            <td>0.99561</td>\n",
    "            <td>0.88375</td>\n",
    "            <td>0.89404</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>F1</td>\n",
    "            <td>0.97248</td>\n",
    "            <td>0.9978</td>\n",
    "            <td>0.84302</td>\n",
    "            <td>0.91759</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Precision and Recall - `prelim_month_human`\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Calculate precision and recall for humans versus ground truth - set it up so that coder 1 is as it was for computer (ground_truth having precedence) and then set up coder 2 up the same way, but without ground_truth...\n",
    "\n",
    "- Jupyter notebooks:\n",
    "\n",
    "    - Create Reliability_Names data where coder 1 is ground truth, coder 2 is human coding without corrections for ground truth: [https://research.local:8000/user/jonathanmorgan/notebooks/work/django/research/work/phd_work/methods/precision_recall/prelim_month-create_Reliability_Names-ground_truth_vs_human.ipynb](https://research.local:8000/user/jonathanmorgan/notebooks/work/django/research/work/phd_work/methods/precision_recall/prelim_month-create_Reliability_Names-ground_truth_vs_human.ipynb)\n",
    "    - Calculate confusion matrices and precision/recall/F1: [https://research.local:8000/user/jonathanmorgan/notebooks/work/django/research/work/phd_work/methods/precision_recall/prelim_month_human-confusion_matrix.ipynb](https://research.local:8000/user/jonathanmorgan/notebooks/work/django/research/work/phd_work/methods/precision_recall/prelim_month_human-confusion_matrix.ipynb)\n",
    "\n",
    "- results are in `Dropbox/academia/MSU/program_stuff/prelim_paper/analysis/precision_and_recall/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"reliability_names_instance_view\" name=\"reliability_names_instance_view\">\n",
    "    <h3>Human Confusion Matrix and Scores</h3>\n",
    "    <table class=\"gridtable\">\n",
    "        <tr>\n",
    "            <th>score</th>\n",
    "            <th>detect</th>\n",
    "            <th>type \"author\"</th>\n",
    "            <th>type \"subject\"</th>\n",
    "            <th>type \"source\"</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>TP</td>\n",
    "            <td>2309</td>\n",
    "            <td>453</td>\n",
    "            <td>646</td>\n",
    "            <td>1188</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>TN</td>\n",
    "            <td>0</td>\n",
    "            <td>1962</td>\n",
    "            <td>1669</td>\n",
    "            <td>1189</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>FP</td>\n",
    "            <td>19</td>\n",
    "            <td>1</td>\n",
    "            <td>24</td>\n",
    "            <td>16</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>FN</td>\n",
    "            <td>93</td>\n",
    "            <td>5</td>\n",
    "            <td>82</td>\n",
    "            <td>28</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>precision</td>\n",
    "            <td>0.99184</td>\n",
    "            <td>0.9978</td>\n",
    "            <td>0.96418</td>\n",
    "            <td>0.98671</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>recall</td>\n",
    "            <td>0.96128</td>\n",
    "            <td>0.98908</td>\n",
    "            <td>0.88736</td>\n",
    "            <td>0.97697</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>F1</td>\n",
    "            <td>0.97632</td>\n",
    "            <td>0.99342</td>\n",
    "            <td>0.92418</td>\n",
    "            <td>0.98182</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate reliability numbers for `prelim_month`...\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Run the reliability calculations for prelim_month just to get lookup assessment (since it is not classification, precision and recall make no sense).\n",
    "\n",
    "- Jupyter notebook: [https://research.local:8000/user/jonathanmorgan/notebooks/work/django/research/work/phd_work/methods/reliability/prelim_month-reliability.ipynb](https://research.local:8000/user/jonathanmorgan/notebooks/work/django/research/work/phd_work/methods/reliability/prelim_month-reliability.ipynb)\n",
    "- results:\n",
    "\n",
    "    - Go to: [https://research.local/research/context/analysis/reliability/names/results/view](https://research.local/research/context/analysis/reliability/names/results/view)\n",
    "    - Label: `prelim_month`\n",
    "    - also stored in PDF form in `Dropbox/academia/MSU/program_stuff/prelim_paper/analysis/reliability/2016-data/prelim_month-reliability_results.pdf`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"reliability_names_instance_view\" name=\"reliability_names_instance_view\">\n",
    "    <h3>prelim_month Automated Author reliability</h3>\n",
    "    <table class=\"gridtable\">\n",
    "        <tr>\n",
    "            <th>label</th>\n",
    "            <th>results ID</th>\n",
    "            <th>coder1 index</th>\n",
    "            <th>coder2 index</th>\n",
    "            <th>coder1 ID</th>\n",
    "            <th>coder2 ID</th>\n",
    "            <th>count</th>\n",
    "            <th>detect %</th>\n",
    "            <th>detect A</th>\n",
    "            <th>detect pi</th>\n",
    "            <th>lookup %</th>\n",
    "            <th>lookup A</th>\n",
    "            <th>lookup-NZ %</th>\n",
    "            <th>lookup-NZ A</th>\n",
    "            <th>lookup-NZ N</th>\n",
    "            <th>type %</th>\n",
    "            <th>type A</th>\n",
    "            <th>type pi</th>\n",
    "            <th>type-NZ %</th>\n",
    "            <th>type-NZ A</th>\n",
    "            <th>type-NZ pi</th>\n",
    "            <th>type-NZ N</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>prelim_month</td>\n",
    "            <td>41</td>\n",
    "            <td>1</td>\n",
    "            <td>2</td>\n",
    "            <td>9</td>\n",
    "            <td>2</td>\n",
    "            <td>456</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <!-- Lookup -->\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>456</td>\n",
    "            <td>0.9956140351</td>\n",
    "            <td>-0.0010989011</td>\n",
    "            <td>0.9941520468</td>\n",
    "            <td>0.9956140351</td>\n",
    "            <td>-0.0010989011</td>\n",
    "            <td>0.9934210526</td>\n",
    "            <td>456</td>\n",
    "        </tr>                        \n",
    "        <tr>\n",
    "            <td><strong>Averages:</strong></td>\n",
    "            <td></td> <!-- results_instance.id -->\n",
    "            <td></td> <!-- results_instance.coder1_coder_index -->\n",
    "            <td></td> <!-- results_instance.coder2_coder_index -->\n",
    "            <td></td> <!-- results_instance.coder1.id -->\n",
    "            <td></td> <!-- results_instance.coder2.id -->\n",
    "            <td>456</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <!-- Lookup -->\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>456</td>\n",
    "            <td>0.9956140351</td>\n",
    "            <td>-0.0010989011</td>\n",
    "            <td>0.9941520468</td>\n",
    "            <td>0.9956140351</td>\n",
    "            <td>-0.0010989011</td>\n",
    "            <td>0.9934210526</td>\n",
    "            <td>456</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "    <hr />\n",
    "    <h3>prelim_month Automated Subject reliability</h3>\n",
    "    <table class=\"gridtable\">\n",
    "        <tr>\n",
    "            <th>label</th>\n",
    "            <th>results ID</th>\n",
    "            <th>coder1 index</th>\n",
    "            <th>coder2 index</th>\n",
    "            <th>coder1 ID</th>\n",
    "            <th>coder2 ID</th>\n",
    "            <th>count</th>\n",
    "            <th>detect %</th>\n",
    "            <th>detect A</th>\n",
    "            <th>detect pi</th>\n",
    "            <th>lookup %</th>\n",
    "            <th>lookup A</th>\n",
    "            <th>lookup-NZ %</th>\n",
    "            <th>lookup-NZ A</th>\n",
    "            <th>lookup-NZ N</th>\n",
    "            <th>type %</th>\n",
    "            <th>type A</th>\n",
    "            <th>type pi</th>\n",
    "            <th>type-NZ %</th>\n",
    "            <th>type-NZ A</th>\n",
    "            <th>type-NZ pi</th>\n",
    "            <th>type-NZ N</th>\n",
    "            <th>1st graf %</th>\n",
    "            <th>1st graf A</th>\n",
    "            <th>1st index %</th>\n",
    "            <th>1st index A</th>\n",
    "            <th>org hash %</th>\n",
    "            <th>org hash A</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>prelim_month</td>\n",
    "            <td>41</td>\n",
    "            <td>1</td>\n",
    "            <td>2</td>\n",
    "            <td>9</td>\n",
    "            <td>2</td>\n",
    "            <td>1990</td>\n",
    "            <td>0.9341708543</td>\n",
    "            <td>-0.0337750065</td>\n",
    "            <td>0.8683417085</td>\n",
    "            <!-- Lookup -->\n",
    "            <td>0.9271356784</td>\n",
    "            <td>0.9270088091</td>\n",
    "            <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "            <td>0.9924690694</td>\n",
    "            <td>0.9924634556</td>\n",
    "            <td>1859</td>\n",
    "            <td>0.8597989950</td>\n",
    "            <td>0.7240822488</td>\n",
    "            <td>0.8130653266</td>\n",
    "            <td>0.9203873050</td>\n",
    "            <td>0.8309561562</td>\n",
    "            <td>0.8805809575</td>\n",
    "            <td>1859</td>\n",
    "            <td>0.3437185930</td>\n",
    "            <td>0.6123922212</td>\n",
    "            <td>0.3366834171</td>\n",
    "            <td>0.6206739538</td>\n",
    "            <td>0.2412060302</td>\n",
    "            <td>-0.2349657677</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><strong>Averages:</strong></td>\n",
    "            <td></td> <!-- results_instance.id -->\n",
    "            <td></td> <!-- results_instance.coder1_coder_index -->\n",
    "            <td></td> <!-- results_instance.coder2_coder_index -->\n",
    "            <td></td> <!-- results_instance.coder1.id -->\n",
    "            <td></td> <!-- results_instance.coder2.id -->\n",
    "            <td>1990</td>\n",
    "            <td>0.9341708543</td>\n",
    "            <td>-0.0337750065</td>\n",
    "            <td>0.8683417085</td>\n",
    "            <!-- Lookup -->\n",
    "            <td>0.9271356784</td>\n",
    "            <td>0.9270088091</td>\n",
    "            <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "            <td>0.9924690694</td>\n",
    "            <td>0.9924634556</td>\n",
    "            <td>1859</td>\n",
    "            <td>0.8597989950</td>\n",
    "            <td>0.7240822488</td>\n",
    "            <td>0.8130653266</td>\n",
    "            <td>0.9203873050</td>\n",
    "            <td>0.8309561562</td>\n",
    "            <td>0.8805809575</td>\n",
    "            <td>1859</td>\n",
    "            <td>0.3437185930</td>\n",
    "            <td>0.6123922212</td>\n",
    "            <td>0.3366834171</td>\n",
    "            <td>0.6206739538</td>\n",
    "            <td>0.2412060302</td>\n",
    "            <td>-0.2349657677</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ... and calculate reliability numbers for `prelim_month_human`\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Run the reliability calculations for prelim_month_human just to get lookup assessment (since it is not classification, precision and recall make no sense).\n",
    "\n",
    "- Jupyter notebook of agreement between corrected and uncorrected human coding: [https://research.local:8000/user/jonathanmorgan/notebooks/work/django/research/work/phd_work/methods/reliability/prelim_month_human-reliability.ipynb](https://research.local:8000/user/jonathanmorgan/notebooks/work/django/research/work/phd_work/methods/reliability/prelim_month_human-reliability.ipynb)\n",
    "\n",
    "- results are in `Dropbox/academia/MSU/program_stuff/prelim_paper/analysis/reliability/2016-data/prelim_month_human-reliability_results.pdf`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"reliability_names_instance_view\" name=\"reliability_names_instance_view\">\n",
    "    <h3>prelim_month_human - Author reliability</h3>\n",
    "    <table class=\"gridtable\">\n",
    "        <tr>\n",
    "            <th>label</th>\n",
    "            <th>results ID</th>\n",
    "            <th>coder1 index</th>\n",
    "            <th>coder2 index</th>\n",
    "            <th>coder1 ID</th>\n",
    "            <th>coder2 ID</th>\n",
    "            <th>count</th>\n",
    "            <th>detect %</th>\n",
    "            <th>detect A</th>\n",
    "            <th>detect pi</th>\n",
    "            <th>lookup %</th>\n",
    "            <th>lookup A</th>\n",
    "            <th>lookup-NZ %</th>\n",
    "            <th>lookup-NZ A</th>\n",
    "            <th>lookup-NZ N</th>\n",
    "            <th>type %</th>\n",
    "            <th>type A</th>\n",
    "            <th>type pi</th>\n",
    "            <th>type-NZ %</th>\n",
    "            <th>type-NZ A</th>\n",
    "            <th>type-NZ pi</th>\n",
    "            <th>type-NZ N</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>prelim_month_human</td>\n",
    "            <td>42</td>\n",
    "            <td>1</td>\n",
    "            <td>2</td>\n",
    "            <td>9</td>\n",
    "            <td>9</td>\n",
    "            <td>459</td>\n",
    "            <td>0.9869281046</td>\n",
    "            <td>-0.0054824561</td>\n",
    "            <td>0.9738562092</td>\n",
    "            <!-- Lookup -->\n",
    "            <td>0.9869281046</td>\n",
    "            <td>0.9864845280</td>\n",
    "            <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>453</td>\n",
    "            <td>0.9869281046</td>\n",
    "            <td>-0.0054824561</td>\n",
    "            <td>0.9825708061</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>453</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><strong>Averages:</strong></td>\n",
    "            <td></td> <!-- results_instance.id -->\n",
    "            <td></td> <!-- results_instance.coder1_coder_index -->\n",
    "            <td></td> <!-- results_instance.coder2_coder_index -->\n",
    "            <td></td> <!-- results_instance.coder1.id -->\n",
    "            <td></td> <!-- results_instance.coder2.id -->\n",
    "            <td>459</td>\n",
    "            <td>0.9869281046</td>\n",
    "            <td>-0.0054824561</td>\n",
    "            <td>0.9738562092</td>\n",
    "            <!-- Lookup -->\n",
    "            <td>0.9869281046</td>\n",
    "            <td>0.9864845280</td>\n",
    "            <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>453</td>\n",
    "            <td>0.9869281046</td>\n",
    "            <td>-0.0054824561</td>\n",
    "            <td>0.9825708061</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>453</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "    <hr />\n",
    "    <h3>prelim_month_human - Subject reliability</h3>\n",
    "    <table class=\"gridtable\">       \n",
    "        <tr>\n",
    "            <th>label</th>\n",
    "            <th>results ID</th>\n",
    "            <th>coder1 index</th>\n",
    "            <th>coder2 index</th>\n",
    "            <th>coder1 ID</th>\n",
    "            <th>coder2 ID</th>\n",
    "            <th>count</th>\n",
    "            <th>detect %</th>\n",
    "            <th>detect A</th>\n",
    "            <th>detect pi</th>\n",
    "            <th>lookup %</th>\n",
    "            <th>lookup A</th>\n",
    "            <th>lookup-NZ %</th>\n",
    "            <th>lookup-NZ A</th>\n",
    "            <th>lookup-NZ N</th>\n",
    "            <th>type %</th>\n",
    "            <th>type A</th>\n",
    "            <th>type pi</th>\n",
    "            <th>type-NZ %</th>\n",
    "            <th>type-NZ A</th>\n",
    "            <th>type-NZ pi</th>\n",
    "            <th>type-NZ N</th>\n",
    "            <th>1st graf %</th>\n",
    "            <th>1st graf A</th>\n",
    "            <th>1st index %</th>\n",
    "            <th>1st index A</th>\n",
    "            <th>org hash %</th>\n",
    "            <th>org hash A</th>            \n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>prelim_month_human</td>\n",
    "            <td>42</td>\n",
    "            <td>1</td>\n",
    "            <td>2</td>\n",
    "            <td>9</td>\n",
    "            <td>9</td>\n",
    "            <td>1962</td>\n",
    "            <td>0.9459734964</td>\n",
    "            <td>-0.0275013096</td>\n",
    "            <td>0.8919469929</td>\n",
    "            <!-- Lookup -->\n",
    "            <td>0.9454638124</td>\n",
    "            <td>0.9453873170</td>\n",
    "            <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "            <td>0.9994612069</td>\n",
    "            <td>0.9994608121</td>\n",
    "            <td>1856</td>\n",
    "            <td>0.9347604485</td>\n",
    "            <td>0.8674336065</td>\n",
    "            <td>0.9130139314</td>\n",
    "            <td>0.9881465517</td>\n",
    "            <td>0.9740898999</td>\n",
    "            <td>0.9822198276</td>\n",
    "            <td>1856</td>\n",
    "            <td>0.6121304791</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>0.6116207951</td>\n",
    "            <td>0.9991667040</td>\n",
    "            <td>0.9576962283</td>\n",
    "            <td>0.9550945519</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><strong>Averages:</strong></td>\n",
    "            <td></td> <!-- results_instance.id -->\n",
    "            <td></td> <!-- results_instance.coder1_coder_index -->\n",
    "            <td></td> <!-- results_instance.coder2_coder_index -->\n",
    "            <td></td> <!-- results_instance.coder1.id -->\n",
    "            <td></td> <!-- results_instance.coder2.id -->\n",
    "            <td>1962</td>\n",
    "            <td>0.9459734964</td>\n",
    "            <td>-0.0275013096</td>\n",
    "            <td>0.8919469929</td>\n",
    "            <!-- Lookup -->\n",
    "            <td>0.9454638124</td>\n",
    "            <td>0.9453873170</td>\n",
    "            <!-- Lookup Limited to Non-Zero (both detect) -->\n",
    "            <td>0.9994612069</td>\n",
    "            <td>0.9994608121</td>\n",
    "            <td>1856</td>\n",
    "            <td>0.9347604485</td>\n",
    "            <td>0.8674336065</td>\n",
    "            <td>0.9130139314</td>\n",
    "            <td>0.9881465517</td>\n",
    "            <td>0.9740898999</td>\n",
    "            <td>0.9822198276</td>\n",
    "            <td>1856</td>\n",
    "            <td>0.6121304791</td>\n",
    "            <td>1.0000000000</td>\n",
    "            <td>0.6116207951</td>\n",
    "            <td>0.9991667040</td>\n",
    "            <td>0.9576962283</td>\n",
    "            <td>0.9550945519</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Analysis\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Generate some basic network statistics from the ground truth and automated attribution data, characterize and compare using QAP (including explaining substantial limitations of this given sparseness of networks).\n",
    "\n",
    "- **This notebook, [methods_paper_planning.ipynb](methods_paper_planning.ipynb), is the master network analysis planning notebook now, not [network_analysis/methods-network_analysis-create_network_data.ipynb](network_analysis/methods-network_analysis-create_network_data.ipynb).**\n",
    "\n",
    "- ARCHIVE - Original master network analysis notebook: [network_analysis/methods-network_analysis-create_network_data.ipynb](network_analysis/methods-network_analysis-create_network_data.ipynb) (previously named `2017.11.14-work_log-prelim-network_analysis.ipynb`).\n",
    "\n",
    "    - contains all original notebooks and additional explanation of what each contains (now consolidated into this notebook, below, and expanded to include latest code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Plan for getting back up to speed:\n",
    "\n",
    "- original plan was to derive descriptives on human and machine coded networks, compare them, and then do a QAP graph correlaton comparison just between the two graphs to assess quality of automated coding.  This is superceded in current plan by precision, recall, F1.  But, will use the original graph analysis code and plan to compare different time slices, so need to know how it works.\n",
    "- find code used to derive network information last time. - Evernote Network Analysis Notes: [https://www.evernote.com/shard/s101/nl/11379781/ef9db83f-5fd3-4bd2-bdd7-1407e2c01f9c/](https://www.evernote.com/shard/s101/nl/11379781/ef9db83f-5fd3-4bd2-bdd7-1407e2c01f9c/)\n",
    "- run it again on full month of data, rather than just a week.\n",
    "- examine traits of ground_truth and automated networks\n",
    "\n",
    "    - compare with QAP.\n",
    "    - look at average degree of reporters\n",
    "    - look at average degree, density, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New analysis steps\n",
    "\n",
    "- 1) create network data for each time period - [network_analysis/methods-network_analysis-create_network_data.ipynb](network_analysis/methods-network_analysis-create_network_data.ipynb)\n",
    "    \n",
    "    - resulting network matrix plus some node-level traits stored in tab-delimited files that are then loaded by R programs that do the actual analysis in igraph and statnet.\n",
    "    \n",
    "- 2) network descriptives, for comparison across network slices.\n",
    "\n",
    "    - igraph - see Notebooks section on [notebooks - network analysis - igraph](#notebooks---network-analysis---igraph) below.\n",
    "    - statnet - see Notebooks section on [notebooks - network creation, descriptives and QAP - statnet](#notebooks---network-creation,-descriptives-and-QAP---statnet) below.\n",
    "\n",
    "- 3) QAP comparison of networks.\n",
    "\n",
    "    - see Notebooks section on [notebooks - network creation, descriptives and QAP - statnet](#notebooks---network-creation,-descriptives-and-QAP---statnet) below.\n",
    "\n",
    "- 4) Question: do we care about author-info?\n",
    "\n",
    "    - see Notebooks section on [notebooks - author info](#notebooks---author-info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNA Notebooks\n",
    "\n",
    "Details on notebooks that:\n",
    "\n",
    "- 1) are used to implement steps above and...\n",
    "- 2) contain the results, for reference when writing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notebooks - create data\n",
    "\n",
    "- [network_analysis/methods-network_analysis-create_network_data.ipynb](network_analysis/methods-network_analysis-create_network_data.ipynb)\n",
    "\n",
    "    - Overview:\n",
    "    \n",
    "        - data creation for original Python network analysis and for current analysis.\n",
    "        - original Python network analysis, run for original coders, then week and month of new data - per-author source, shared, and article counts; and means of each across all authors.\n",
    "        - for \"human\", this is the baseline - \"ground_truth\" user takes precedence over all others.\n",
    "\n",
    "    - Section 2 (2.1-2.3): Deriving network data - for all network analysis, contains the exact settings used to create the network data for each time period.\n",
    "\n",
    "        - 2.1 - for original week (12/06/2009-12/12/2009), original coders, networks output include:\n",
    "        \n",
    "            - combined human\n",
    "            - automated.\n",
    "        \n",
    "        - 2.2 - original week (12/06/2009-12/12/2009), new coders, networks output include:\n",
    "        \n",
    "            - ground_truth (combined human plus corrected, corrected first, then human)\n",
    "            - automated.\n",
    "            \n",
    "        - 2.3 - entire month (12/01/2009-12/31/2009).\n",
    "        \n",
    "            - includes all people for the entire month, networks for:\n",
    "            \n",
    "                - 2.3.1  nodes - full month; ties - full month\n",
    "                - 2.3.2  nodes - full month; ties - week 1 (2009-12-06 to 2009-12-12)\n",
    "                - 2.3.3  nodes - full month; ties - week 2 (2009-12-13 to 2009-12-19)\n",
    "                - 2.3.4  nodes - full month; ties - week 3 (2009-12-20 to 2009-12-26)\n",
    "                \n",
    "    - Section 3 - output from here is basis for all the R author info stuff below:\n",
    "    \n",
    "        - 3.1 - reproduce original analysis, but with the new data.  Success.  Modest.\n",
    "        - 3.2 - OBSOLETE - Overview of the rest of the notebooks, consolidated below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notebooks - network analysis - igraph\n",
    "\n",
    "- [network_analysis/igraph](network_analysis/igraph) - R igraph analysis\n",
    "\n",
    "    - new notebooks: Broke out into one file per time period, and separate R data files:\n",
    "\n",
    "        - [network_analysis/igraph/R-igraph-grp_month-full_month.ipynb](network_analysis/igraph/R-igraph-grp_month-full_month.ipynb) - full month of data, and data file `igraph-grp_month-full_month.RData`.\n",
    "        - [network_analysis/igraph/R-igraph-grp_month-week_1.ipynb](network_analysis/igraph/R-igraph-grp_month-week_1.ipynb) - full week 1 of three (2009-12-06 to 2009-12-12), and data file `igraph-grp_month-week_1.RData`.\n",
    "        - [network_analysis/igraph/R-igraph-grp_month-week_2.ipynb](network_analysis/igraph/R-igraph-grp_month-week_2.ipynb) - full week 2 of three (2009-12-13 to 2009-12-19), and data file `igraph-grp_month-week_2.RData`.\n",
    "        - [network_analysis/igraph/R-igraph-grp_month-week_3.ipynb](network_analysis/igraph/R-igraph-grp_month-week_3.ipynb) - full week 3 of three (2009-12-20 to 2009-12-26), and data file `igraph-grp_month-week_3.RData`.\n",
    "        \n",
    "    - original notebook: [network_analysis/igraph/2017.12.02-work_log-prelim-R-igraph-grp_month.ipynb](network_analysis/igraph/2017.12.02-work_log-prelim-R-igraph-grp_month.ipynb) - basic network analysis of new month and week (nodes for all people from entire month, ties for whole month, then just first week) using igraph.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notebooks - network creation, descriptives and QAP - statnet\n",
    "\n",
    "- [network_analysis/statnet](network_analysis/statnet) - R statnet analysis\n",
    "\n",
    "    - All data still stored in a single RData file (`statnet-grp_month.RData`)\n",
    "    - statnet function library: context_analysis git repo, `context_analysis/r/sna/statnet/functions-statnet.r`\n",
    "    - network creation, descriptives, and QAP notebooks:\n",
    "\n",
    "        - the below notebooks each create network data for a single time period, then analyze each period separately.  Each includes:\n",
    "    \n",
    "            - creating the data for the notebook's time period using automated data and generating basic network metrics to describe the network.\n",
    "            - creating the data for the notebook's time period using the baseline data and generating basic network metrics to describe the network.\n",
    "            - comparing the baseline matrix to the automated matrix using matrix correlation and QAP.\n",
    "    \n",
    "        - notebooks:\n",
    "        \n",
    "            - [network_analysis/statnet/R-statnet-grp_month-full_month.ipynb](network_analysis/statnet/R-statnet-grp_month-full_month.ipynb) - full month of data.\n",
    "            \n",
    "                - correlation between human and automated: 0.914011398376571\n",
    "            \n",
    "            - [network_analysis/statnet/R-statnet-grp_month-week_1.ipynb](network_analysis/statnet/R-statnet-grp_month-week_1.ipynb) - full week 1 of three (2009-12-06 to 2009-12-12).\n",
    "            \n",
    "                - correlation between human and automated: 0.90223000784894\n",
    "            \n",
    "            - [network_analysis/statnet/R-statnet-grp_month-week_2.ipynb](network_analysis/statnet/R-statnet-grp_month-week_2.ipynb) - full week 2 of three (2009-12-13 to 2009-12-19).\n",
    "            \n",
    "                - correlation between human and automated: 0.908007732272713\n",
    "            \n",
    "            - [network_analysis/statnet/R-statnet-grp_month-week_3.ipynb](network_analysis/statnet/R-statnet-grp_month-week_3.ipynb) - full week 3 of three (2009-12-20 to 2009-12-26).\n",
    "            \n",
    "                - correlation between human and automated: 0.898065381427003\n",
    "            \n",
    "    - network comparison - then, the networks created above are compared week-to-week and each week to the month as a whole to start to look at what constitutes a network snapshot.\n",
    "\n",
    "        - [network_analysis/statnet/R-statnet-grp_month-compare_graphs.ipynb](network_analysis/statnet/R-statnet-grp_month-compare_graphs.ipynb) - QAP comparisons, both automated-to-automated and human-to-human, of:\n",
    "        \n",
    "            - week 1 to week 2\n",
    "            - week 1 to week 3\n",
    "            - week 2 to week 3\n",
    "            - full month to week 1\n",
    "            - full month to week 2\n",
    "            - full month to week 3\n",
    "            \n",
    "        - [network_analysis/statnet/R-statnet-grp_month-compare_graphs_cross_source.ipynb](network_analysis/statnet/R-statnet-grp_month-compare_graphs_cross_source.ipynb) - To look at difference mixing and matching human and automated makes for analysis, includes QAP comparisons, baseline-to-automated (b2a) and automated-to-baseline (a2b), of:\n",
    "\n",
    "            - week 1 to week 2\n",
    "            - week 1 to week 3\n",
    "            - week 2 to week 3\n",
    "            - full month to week 1\n",
    "            - full month to week 2\n",
    "            - full month to week 3\n",
    "\n",
    "    - **ARCHIVE:** original notebook: [network_analysis/statnet/2017.12.02-work_log-prelim-R-statnet-grp_month.ipynb](network_analysis/statnet/2017.12.02-work_log-prelim-R-statnet-grp_month.ipynb) - basic network analysis of new month and week (nodes for all people from entire month, ties for whole month, then just first week) using statnet.  Broke out into one notebook per time period, and one notebook for comparisons across time periods.  All data still stored in a single RData file (`statnet-grp_month.RData`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANALYSIS - network creation, descriptives and QAP - statnet\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Anaylsis of these descriptives and QAP correlations:\n",
    "\n",
    "- Comparison between automated and baseline networks (month, week1, week2, week3): `Dropbox/academia/MSU/program_stuff/prelim_paper/paper/latest/network_snapshots-compare_automated_to_baseline.xlsx`\n",
    "\n",
    "    - includes comparisons from `network_analysis/statnet/R-statnet-grp_month-compare_graphs.ipynb` and `network_analysis/statnet/R-statnet-grp_month-compare_graphs_cross_source.ipynb` above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notebooks - author info\n",
    "\n",
    "- [network_analysis/author_info](network_analysis/author_info) - Information on the authors in the data set and their network characteristics.\n",
    "\n",
    "    - **NOTE: Still looks to be dependent on the python author info code run in [network_analysis/methods-network_analysis-create_network_data.ipynb](network_analysis/methods-network_analysis-create_network_data.ipynb), section 3.1 (vectors of person IDs, counts hard-coded in the R code)**\n",
    "    \n",
    "        - _in new notebooks, the weeks 2 and 3 result in different numbers, but look to be based on the same 1-week vectors... would need to understand what is going on here again before I'd use these numbers.  I'd expect you'd need to run python author info 4 times, once for month, once for each week, not just for month and 1 week._\n",
    "\n",
    "    - new notebooks:\n",
    "    \n",
    "        - [network_analysis/author_info/R-grp_month-sna-author_info-full_month.r.ipynb](network_analysis/author_info/R-grp_month-sna-author_info-full_month.r.ipynb)\n",
    "        - [network_analysis/author_info/R-grp_month-sna-author_info-week_1.r.ipynb](network_analysis/author_info/R-grp_month-sna-author_info-week_1.r.ipynb)\n",
    "        - [network_analysis/author_info/R-grp_month-sna-author_info-week_2.r.ipynb](network_analysis/author_info/R-grp_month-sna-author_info-week_2.r.ipynb)\n",
    "        - [network_analysis/author_info/R-grp_month-sna-author_info-week_3.r.ipynb](network_analysis/author_info/R-grp_month-sna-author_info-week_3.r.ipynb)\n",
    "\n",
    "    - original notebooks:\n",
    "\n",
    "        - [network_analysis/author_info/2017.12.07-work_log-prelim-R-grp_month-sna-author_info.r.ipynb](network_analysis/author_info/2017.12.07-work_log-prelim-R-grp_month-sna-author_info.r.ipynb) - R-based author info (similar to Python-based above) for full month of data.\n",
    "        - [network_analysis/author_info/2017.12.09-work_log-prelim-R-grp_week-sna-author_info.r.ipynb](network_analysis/author_info/2017.12.09-work_log-prelim-R-grp_week-sna-author_info.r.ipynb) - R-based author info (similar to Python-based above) for single week of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## network analysis TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### network analysis TODO - DEFERRED\n",
    "\n",
    "TODO: update all below so they include the two additional weeks.\n",
    "\n",
    "- [network_analysis/statnet/2017.12.07-work_log-prelim-R-statnet-grp_month-01.ipynb](network_analysis/statnet/2017.12.07-work_log-prelim-R-statnet-grp_month-01.ipynb) - statnet analysis when network is converted to either be 0 or 1 weight, where all weights greater than 1 are converted to 1.  No real difference here, so ignoring in paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-31T05:07:59.731310Z",
     "start_time": "2017-10-31T05:07:59.720302Z"
    }
   },
   "source": [
    "### network analysis TODO - DONE\n",
    "\n",
    "DONE:\n",
    "\n",
    "- updated forms `ArticleSelectForm` and `PersonSelectForm` to include field for \"`coder_id_priority_list`\"/\"`person_coder_id_priority_list`\".\n",
    "- created method NetworkOutput.get_coder_id_list() that:\n",
    "\n",
    "    - knows about the two places where coder IDs can be set.\n",
    "    - if prioritzed list is present:\n",
    "    \n",
    "        - starts with the priotized list\n",
    "        - appends coders from other field who aren't already in the list to the end of it.\n",
    "        - stores the list in an instance variable inside the object so it can be retrieved easily.\n",
    "        \n",
    "- updated NetworkOutput.create_query_set() to use get_coder_id_list() method.\n",
    "- need to update NetworkOutput.remove_duplicate_article_data() - it is where we choose which Article_Data to omit per article where there are duplicates.  Need to go with order of list.  Might already do this...  Nope.\n",
    "\n",
    "    - get prioritized list.\n",
    "    - for first instance of Article_Data for article, store it (related by id, or unique_identifier?)\n",
    "    - on subsequent Article_Data for article, get index of coder for existing and new.\n",
    "    - Whichever has lower index you keep.\n",
    "    - **_Need to test_**\n",
    "\n",
    "        - person-coded articles:\n",
    "        \n",
    "            - 1) output networks from initial prelim (12/6/2009-12/13/2009).  Make sure they are the same now as they were then.\n",
    "            - 2) keep article specs the same, but change person lookup to use ordered ID list.  See if this is the same as the files in 1 (might not be).  If not, count rows, find and compare rows for some users to see how different they are.  Hopefully same contents, different order...?\n",
    "            - 3) then, switch the article specs to use ordered list and put person specs back to old way, see how this file compares to the others.\n",
    "            - look for differences in:\n",
    "            \n",
    "                - number of rows\n",
    "                - contents of rows\n",
    "                - IDs of those included\n",
    "            \n",
    "        - automated coder:\n",
    "\n",
    "            - 1) output networks from initial prelim (12/6/2009-12/13/2009).  Make sure they are the same now as they were then.\n",
    "            - 2) keep article specs the same, but change person lookup to use ordered ID list.  See if this is the same as the files in 1 (might not be).  If not, count rows, find and compare rows for some users to see how different they are.  Hopefully same contents, different order.\n",
    "            - 3) then, switch the article specs to use ordered list, see how this file compares to the others.\n",
    "\n",
    "        - as long as the tests above check out, then try out the whole month, with prioritized coder list.\n",
    "\n",
    "- need to update NetworkDataOutput and children?  Looks like no - all comes down to the remove_duplicate_article_data().\n",
    "- figure out how to run `context_text/R/sna/sna_author_info.r`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine results into spreadsheet\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Next step is to pull analysis together in an Excel spreadsheet like I did last time.\n",
    "\n",
    "For old results and more detailed notes on implementation and interpretation, see `Dropbox/academia/MSU/program_stuff/prelim_paper/analysis/archive/prelim_v1-2015/analysis_summary.xlsx`.\n",
    "\n",
    "New analysis file: `Dropbox/academia/MSU/program_stuff/prelim_paper/analysis/analysis_summary-2017.12.24.xlsx`\n",
    "\n",
    "Analysis charts for paper (should take all tables, convert to markdown, and add to this notebook): `Dropbox/academia/MSU/program_stuff/prelim_paper/paper/latest/methods-charts.xlsx`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "- In general, revised procedure:\n",
    "\n",
    "    - content analysis protocol to create testing data.\n",
    "    \n",
    "        - create and test protocol.\n",
    "        - report reliability.\n",
    "        - use protocol to create testing data.\n",
    "\n",
    "    - have automated tool code same articles.\n",
    "    - for all disagreements, evaluate manually, correct the testing data when it has an error.\n",
    "    - derive confusion matrix data by comparing automated coding to testing data, assess quality of automated coding using precision and recall (etc.).\n",
    "    \n",
    "- so, won't look as much at comparing humans to computer in terms of agreement for content analysis:\n",
    "\n",
    "    - describe protocol development and reliability assessment\n",
    "    - describe process of turning the resulting data into testing data (don't use \"ground truth\").  Some discussion here of ratio of human error to machine error, proportion of human to machine errors, overall number of errors compared to all decisions, etc.\n",
    "    - outline precision and recall and evaluate.\n",
    "\n",
    "- Removed tabs:\n",
    "\n",
    "    - `agree-prelim_reliability` - old reliability coding between 2 human coders.\n",
    "    - `agree-prelim_network-mentions` - agreement between traits of network data derived from human and computer code - tie weights.\n",
    "    - `values-detect_names` - survey of name detection descriptives - counts across all names of how many were detected and not per coder.  Will see if we need to derive this again for new coders.  Probably won't.\n",
    "    - `values-count_ties` - descriptives and comparison of ties weights between human and computer, to look at something like precision and recall (confusion matrix), but just comparing human and computer, not treating human as ground truth.  No need for this with precision and recall stats.\n",
    "    - `counts_per_person` - not sure what this is...\n",
    "    - `disagreements` - similar to `values-count_ties`, but higher-level analysis.  Will have to create new disagreement information from results of disagreement analysis in creating evaluation data.\n",
    "\n",
    "Updated spreadsheet:\n",
    "\n",
    "- New analysis file: `Dropbox/academia/MSU/program_stuff/prelim_paper/analysis/analysis_summary-2017.12.24.xlsx`\n",
    "- Agreement results:\n",
    "\n",
    "    - tabs \"`CA-reliability-author`\" and \"`CA-reliability-subject`\" are derived from work labeled \"`prelim_reliability_combined`\" = articles from both Grand Rapids Press and Detroit News, to minimally test cross-paper use of protocol.\n",
    "    \n",
    "        - pulled from spreadsheet: `Dropbox/academia/MSU/program_stuff/prelim_paper/analysis/reliability/2016-data/2016.08.27-reliability-prelim_reliability_combined_human.xlsx`\n",
    "    \n",
    "    - old results have \"mentions\".  Mentions are weights from network data back when I derived it and stored it in a table of my own design (\"`context_analysis_reliability_ties`\"), rather than outputting in formats readable by SNA packages.  Omitting this in favor of precision and recall and network statistics.\n",
    "\n",
    "- Network results:\n",
    "\n",
    "    - Main sources:\n",
    "    \n",
    "        - [2017.12.02-work_log-prelim-R-statnet-grp_month.ipynb](2017.12.02-work_log-prelim-R-statnet-grp_month.ipynb) - basic network analysis of new month and week using statnet.\n",
    "        - [2017.12.07-work_log-prelim-R-grp_month-sna-author_info.r.ipynb](2017.12.07-work_log-prelim-R-grp_month-sna-author_info.r.ipynb) - R-based author info (similar to Python-based above) for full month of data.\n",
    "        - [2017.12.09-work_log-prelim-R-grp_week-sna-author_info.r.ipynb](2017.12.09-work_log-prelim-R-grp_week-sna-author_info.r.ipynb) - R-based author info (similar to Python-based above) for single week of data.\n",
    "        - [2017.12.02-work_log-prelim-R-igraph-grp_month.ipynb](2017.12.02-work_log-prelim-R-igraph-grp_month.ipynb) - basic network analysis of new month and week using igraph.\n",
    "            \n",
    "            - for mean transitivity of nodes, look at igraph notebook.\n",
    "\n",
    "    - Other:\n",
    "    \n",
    "        - [2017.11.14-work_log-prelim-network_analysis.ipynb](2017.11.14-work_log-prelim-network_analysis.ipynb) - original Python network analysis, run for original coders, then week and month of new data - per-author source, shared, and article counts; and means of each across all authors.\n",
    "        - [2017.12.07-work_log-prelim-R-statnet-grp_month-01.ipynb](2017.12.07-work_log-prelim-R-statnet-grp_month-01.ipynb) - statnet analysis when network is converted to either be 0 or 1 weight, where all weights greater than 1 are converted to 1.  No real difference here, so ignoring in paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Edits\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "**Path to paper:** `Dropbox/academia/MSU/program_stuff/prelim_paper/paper/latest/Morgan-Prelim.docx`\n",
    "\n",
    "TODO:\n",
    "\n",
    "- cut the shit out of lit. review.\n",
    "- update discussion\n",
    "\n",
    "DONE:\n",
    "\n",
    "- update methods\n",
    "\n",
    "    - generate content analysis data.\n",
    "    - assess reliability.\n",
    "    - generate attribution data using OpenCalais API.\n",
    "    - evaluate disagreements to establish ground truth (fix human errors).\n",
    "    - calculate precision and recall.\n",
    "    - examine resulting networks.\n",
    "\n",
    "- update results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "- brief lit. review of hybrid content analysis coding, so I can mention a few in lit. review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DONE:\n",
    "\n",
    "- make sure the network code can deal with multiple coders, and can prioritize in an order I specify."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_virtualenv",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "689px",
    "left": "0px",
    "right": "1118px",
    "top": "111px",
    "width": "322px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
