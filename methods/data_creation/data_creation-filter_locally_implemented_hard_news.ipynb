{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**data creation - filter locally implemented hard news**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Setup---Imports\" data-toc-modified-id=\"Setup---Imports-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Setup - Imports</a></span></li><li><span><a href=\"#Setup---virtualenv-jupyter-kernel\" data-toc-modified-id=\"Setup---virtualenv-jupyter-kernel-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Setup - virtualenv jupyter kernel</a></span></li><li><span><a href=\"#Setup---Initialize-Django\" data-toc-modified-id=\"Setup---Initialize-Django-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Setup - Initialize Django</a></span></li></ul></li><li><span><a href=\"#Analysis-steps\" data-toc-modified-id=\"Analysis-steps-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Analysis steps</a></span></li><li><span><a href=\"#Data-Creation\" data-toc-modified-id=\"Data-Creation-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Creation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Creation---local-GRP-articles\" data-toc-modified-id=\"Data-Creation---local-GRP-articles-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Data Creation - local GRP articles</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Creation---GRP---examples\" data-toc-modified-id=\"Data-Creation---GRP---examples-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Data Creation - GRP - examples</a></span></li><li><span><a href=\"#Data-Creation---GRP---prelim-month\" data-toc-modified-id=\"Data-Creation---GRP---prelim-month-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Data Creation - GRP - prelim month</a></span></li></ul></li><li><span><a href=\"#Data-Creation---local-TDN-articles\" data-toc-modified-id=\"Data-Creation---local-TDN-articles-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Data Creation - local TDN articles</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Creation---TDN---local-bylines\" data-toc-modified-id=\"Data-Creation---TDN---local-bylines-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Data Creation - TDN - local bylines</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Imports\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T20:53:46.339280Z",
     "start_time": "2020-02-28T20:53:46.333696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packages imported at 2020-02-28 20:53:46.336181\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import six\n",
    "\n",
    "# Django query object for OR-ing selection criteria together.\n",
    "from django.db.models import Q\n",
    "\n",
    "# imports - python_utilities\n",
    "from python_utilities.logging.logging_helper import LoggingHelper\n",
    "\n",
    "print( \"packages imported at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - virtualenv jupyter kernel\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "If you are using a virtualenv, make sure that you:\n",
    "\n",
    "- have installed your virtualenv as a kernel.\n",
    "- choose the kernel for your virtualenv as the kernel for your notebook (Kernel --> Change kernel).\n",
    "\n",
    "Since I use a virtualenv, need to get that activated somehow inside this notebook.  One option is to run `../dev/wsgi.py` in this notebook, to configure the python environment manually as if you had activated the `sourcenet` virtualenv.  To do this, you'd make a code cell that contains:\n",
    "\n",
    "    %run ../dev/wsgi.py\n",
    "    \n",
    "This is sketchy, however, because of the changes it makes to your Python environment within the context of whatever your current kernel is.  I'd worry about collisions with the actual Python 3 kernel.  Better, one can install their virtualenv as a separate kernel.  Steps:\n",
    "\n",
    "- activate your virtualenv:\n",
    "\n",
    "        workon sourcenet\n",
    "\n",
    "- in your virtualenv, install the package `ipykernel`.\n",
    "\n",
    "        pip install ipykernel\n",
    "\n",
    "- use the ipykernel python program to install the current environment as a kernel:\n",
    "\n",
    "        python -m ipykernel install --user --name <env_name> --display-name \"<display_name>\"\n",
    "        \n",
    "    `sourcenet` example:\n",
    "    \n",
    "        python -m ipykernel install --user --name sourcenet --display-name \"sourcenet (Python 3)\"\n",
    "        \n",
    "More details: [http://ipython.readthedocs.io/en/stable/install/kernel_install.html](http://ipython.readthedocs.io/en/stable/install/kernel_install.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T20:29:13.776141Z",
     "start_time": "2020-02-28T20:29:13.766630Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jonathanmorgan/work/django/research/work/phd_work/methods/data_creation'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Initialize Django\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "First, initialize my dev django project, so I can run code in this notebook that references my django models and can talk to the database using my project's settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T20:30:32.019071Z",
     "start_time": "2020-02-28T20:30:32.015177Z"
    }
   },
   "outputs": [],
   "source": [
    "# init django\n",
    "django_init_folder = \"/home/jonathanmorgan/work/django/research/work/phd_work\"\n",
    "django_init_path = \"django_init.py\"\n",
    "if( ( django_init_folder is not None ) and ( django_init_folder != \"\" ) ):\n",
    "    \n",
    "    # add folder to front of path.\n",
    "    django_init_path = \"{}/{}\".format( django_init_folder, django_init_path )\n",
    "    \n",
    "#-- END check to see if django_init folder. --#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T20:30:34.478259Z",
     "start_time": "2020-02-28T20:30:33.146224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "django initialized at 2020-02-28 20:30:34.476100\n"
     ]
    }
   ],
   "source": [
    "%run $django_init_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T20:53:55.298838Z",
     "start_time": "2020-02-28T20:53:55.259705Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports - context_text\n",
    "from context_text.collectors.newsbank.newspapers.DTNB import DTNB\n",
    "from context_text.models import Article\n",
    "from context_text.models import Article_Text\n",
    "from context_text.models import Newspaper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis steps\n",
    "\n",
    "In the methods folder, here is the order the code was run for analysis:\n",
    "\n",
    "- 1) `data_creation` (results in `data` folder)\n",
    "- 2) `reliability` - for human reliability.\n",
    "- 3) `evaluate_disagreements` - correct human coding when they are wrong in a disagreement, to create \"ground truth\".\n",
    "- 4) `precision_recall`\n",
    "- 5) `reliability` - for comparing human and computer coding to baseline.\n",
    "- 6) `network_analysis`\n",
    "- 7) `results`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Creation\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Below are the criteria used for each paper to filter down to just locally-implemented hard news articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Creation - local GRP articles\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Definition of local hard news and in-house implementor:\n",
    "\n",
    "- Grand Rapids Press\n",
    "\n",
    "    - `context_text/examples/articles/articles-GRP-local_news.py`\n",
    "    - local hard news sections (stored in `Article.GRP_NEWS_SECTION_NAME_LIST`):\n",
    "   \n",
    "        - \"Business\"\n",
    "        - \"City and Region\"\n",
    "        - \"Front Page\"\n",
    "        - \"Lakeshore\"\n",
    "        - \"Religion\"\n",
    "        - \"Special\"\n",
    "        - \"State\"\n",
    "\n",
    "    - excluding any publications with index term of \"Column\".\n",
    "    - in-house implementor (based on byline patterns, stored in `sourcenet.models.Article.Q_GRP_IN_HOUSE_AUTHOR`):\n",
    "    \n",
    "        - Byline ends in \"/ THE GRAND RAPIDS PRESS\", ignore case.\n",
    "        \n",
    "            - `Q( author_varchar__iregex = r'.* */ *THE GRAND RAPIDS PRESS$'`\n",
    "\n",
    "        - Byline ends in \"/ PRESS * EDITOR\", ignore case.\n",
    "     \n",
    "            - `Q( author_varchar__iregex = r'.* */ *PRESS .* EDITOR$' )`\n",
    "        \n",
    "        - Byline ends in \"/ GRAND RAPIDS PRESS * BUREAU\", ignore case.\n",
    "        \n",
    "            - `Q( author_varchar__iregex = r'.* */ *GRAND RAPIDS PRESS .* BUREAU$' )`\n",
    "            \n",
    "        - Byline ends in \"/ SPECIAL TO THE PRESS\", ignore case.\n",
    "        \n",
    "            - `Q( author_varchar__iregex = r'.* */ *SPECIAL TO THE PRESS$' )`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-29T03:24:42.146951Z",
     "start_time": "2020-02-29T03:24:08.035533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter params:\n",
      "- date_range_start: None\n",
      "- date_range_end: None\n",
      "- newspaper: 1 - Grand Rapids Press, The ( GRPB )\n",
      "- local_news_sections: ['Business', 'City and Region', 'Front Page', 'Lakeshore', 'Religion', 'Special', 'State']\n",
      "- custom_article_q: (OR: ('author_varchar__iregex', '.* */ *THE GRAND RAPIDS PRESS$'), ('author_varchar__iregex', '.* */ *PRESS .* EDITOR$'), ('author_varchar__iregex', '.* */ *GRAND RAPIDS PRESS .* BUREAU$'), ('author_varchar__iregex', '.* */ *SPECIAL TO THE PRESS$'))\n",
      "\n",
      "Article count before filtering on Article IDs: 41107\n",
      "Article count before filtering on tags: 41107\n",
      "Article count after tag filtering: 41107\n"
     ]
    }
   ],
   "source": [
    "#==============================================================================#\n",
    "# ! declare variables\n",
    "#==============================================================================#\n",
    "\n",
    "# declare variables - Grand Rapids Press\n",
    "local_news_sections = []\n",
    "selected_newspaper = None\n",
    "article_qs = None\n",
    "date_range_start = None\n",
    "date_range_end = None\n",
    "custom_article_q = None\n",
    "article_count = None\n",
    "tags_in_list = []\n",
    "tags_not_in_list = []\n",
    "random_count = -1\n",
    "\n",
    "# declare variables - size of random sample we want\n",
    "random_count = 0\n",
    "\n",
    "# declare variables - process articles?\n",
    "do_process_articles = False\n",
    "do_apply_tag = False\n",
    "tag_to_apply = None\n",
    "tags_to_apply_list = None\n",
    "article_id_list = None\n",
    "article_counter = -1\n",
    "current_article = None\n",
    "\n",
    "#==============================================================================#\n",
    "# ! configure filters\n",
    "#==============================================================================#\n",
    "\n",
    "# ==> Article.filter_articles()\n",
    "# date range, newspaper, section list, and custom Q().\n",
    "date_range_start = None\n",
    "date_range_end = None\n",
    "selected_newspaper = None\n",
    "section_name_in_list = None\n",
    "custom_article_q = None\n",
    "\n",
    "# ==> date range\n",
    "\n",
    "# month of local news from Detroit News from 2009-12-01 to 2009-12-31\n",
    "#date_range_start = \"2009-12-01\"\n",
    "#date_range_end = \"2009-12-31\"\n",
    "\n",
    "# ==> newspaper\n",
    "selected_newspaper = Newspaper.objects.get( id = 1 ) # Grand Rapids Press\n",
    "\n",
    "# ==> limit to \"local, regional and state news\" sections.\n",
    "\n",
    "#local_news_sections.append( \"Lakeshore\" )\n",
    "#local_news_sections.append( \"Front Page\" )\n",
    "#local_news_sections.append( \"City and Region\" )\n",
    "#local_news_sections.append( \"Business\" )\n",
    "#local_news_sections.append( \"Religion\" )\n",
    "#local_news_sections.append( \"State\" )\n",
    "#local_news_sections.append( \"Special\" )\n",
    "local_news_sections = Article.GRP_NEWS_SECTION_NAME_LIST\n",
    "section_name_in_list = local_news_sections\n",
    "\n",
    "# ==> limit to staff reporters.\n",
    "\n",
    "# use custom Article Q to filter down to in-house authors.\n",
    "custom_article_q = Article.Q_GRP_IN_HOUSE_AUTHOR\n",
    "\n",
    "# ==> article IDs - include\n",
    "#article_id_in_list = None\n",
    "\n",
    "# ==> tags - exclude\n",
    "#tags_not_in_list = [ \"prelim_reliability\", \"prelim_network\" ]\n",
    "tags_not_in_list = None\n",
    "\n",
    "# ==> tags - include only those with certain tags.\n",
    "#tags_in_list = [ \"prelim_reliability\", \"prelim_network\" ]\n",
    "#tags_in_list = [ \"prelim_reliability\", ]\n",
    "tags_in_list = None\n",
    "\n",
    "# ==> filter out \"*prelim*\" tags?\n",
    "filter_out_prelim_tags = False\n",
    "\n",
    "# ==> ORDER BY - do we want a random sample?\n",
    "#random_count = 10\n",
    "random_count = -1\n",
    "\n",
    "#==============================================================================#\n",
    "# ! configure processing\n",
    "#==============================================================================#\n",
    "\n",
    "do_process_articles = False\n",
    "do_apply_tag = False\n",
    "tags_to_apply_list = []\n",
    "#tags_to_apply_list = [ \"locally_implemented_hard_news\" ]\n",
    "\n",
    "print( \"Filter params:\" )\n",
    "print( \"- date_range_start: {}\".format( date_range_start ) )\n",
    "print( \"- date_range_end: {}\".format( date_range_end ) )\n",
    "print( \"- newspaper: {}\".format( newspaper ) )\n",
    "print( \"- local_news_sections: {}\".format( local_news_sections ) )\n",
    "print( \"- custom_article_q: {}\".format( custom_article_q ) )\n",
    "print( \"\" )\n",
    "\n",
    "#==============================================================================#\n",
    "# ! Do it!\n",
    "#==============================================================================#\n",
    "\n",
    "# start with all articles\n",
    "article_qs = Article.objects.all()\n",
    "\n",
    "# filter to include date range, newspaper, section list, and in-house reporters.\n",
    "article_qs = Article.filter_articles( qs_IN = article_qs,\n",
    "                                      start_date = date_range_start,\n",
    "                                      end_date = date_range_end,\n",
    "                                      newspaper = selected_newspaper,\n",
    "                                      section_name_list = section_name_in_list,\n",
    "                                      custom_article_q = custom_article_q )\n",
    "# no columns\n",
    "article_qs = article_qs.exclude( index_terms__icontains = \"Column\" )\n",
    "\n",
    "# how many is that?\n",
    "article_count = article_qs.count()\n",
    "print( \"Article count before filtering on Article IDs: \" + str( article_count ) )\n",
    "\n",
    "# ! ==> article IDs in list\n",
    "if ( ( article_id_in_list is not None ) and ( len( article_id_in_list ) > 0 ) ):\n",
    "\n",
    "    # include those in a list\n",
    "    print( \"filtering articles to those with IDs: \" + str( article_id_in_list ) )\n",
    "    article_qs = article_qs.filter( id__in = article_id_in_list )\n",
    "\n",
    "#-- END check to see if we have a specific list of tags we want to exclude --#\n",
    "\n",
    "# how many is that?\n",
    "article_count = article_qs.count()\n",
    "print( \"Article count before filtering on tags: \" + str( article_count ) )\n",
    "\n",
    "# ==> tags\n",
    "\n",
    "# tags to exclude\n",
    "if ( ( tags_not_in_list is not None ) and ( len( tags_not_in_list ) > 0 ) ):\n",
    "\n",
    "    # exclude those in a list\n",
    "    print( \"exclude-ing articles with tags: \" + str( tags_not_in_list ) )\n",
    "    article_qs = article_qs.exclude( tags__name__in = tags_not_in_list )\n",
    "\n",
    "#-- END check to see if we have a specific list of tags we want to exclude --#\n",
    "\n",
    "# ! ==> tags - include only those with certain tags.\n",
    "if ( ( tags_in_list is not None ) and ( len( tags_in_list ) > 0 ) ):\n",
    "\n",
    "    # filter\n",
    "    print( \"filtering to just articles with tags: \" + str( tags_in_list ) )\n",
    "    article_qs = article_qs.filter( tags__name__in = tags_in_list )\n",
    "    \n",
    "#-- END check to see if we have a specific list of tags we want to include --#\n",
    "\n",
    "# how many is that?\n",
    "article_count = article_qs.count()\n",
    "\n",
    "print( \"Article count after tag filtering: \" + str( article_count ) )\n",
    "\n",
    "# do we want a random sample?\n",
    "random_count = 0\n",
    "if ( random_count > 0 ):\n",
    "\n",
    "    # to get random, order them by \"?\", then use slicing to retrieve requested\n",
    "    #     number.\n",
    "    article_qs = article_qs.order_by( \"?\" )[ : random_count ]\n",
    "    \n",
    "#-- END check to see if we want random sample --#\n",
    "\n",
    "# this is a nice algorithm, also:\n",
    "# - http://www.titov.net/2005/09/21/do-not-use-order-by-rand-or-how-to-get-random-rows-from-table/\n",
    "\n",
    "# process articles?\n",
    "if ( do_process_articles == True ):\n",
    "\n",
    "    # make list of article IDs.\n",
    "\n",
    "    article_id_list = []\n",
    "    article_counter = 0\n",
    "    for current_article in article_qs:\n",
    "\n",
    "        # increment article_counter\n",
    "        article_counter += 1\n",
    "\n",
    "        # add IDs to article_id_list\n",
    "        article_id_list.append( str( current_article.id ) )\n",
    "\n",
    "        # ! ==> apply tags\n",
    "        \n",
    "        # apply tag(s) while we are at it?\n",
    "        if ( ( do_apply_tag == True ) and ( tags_to_apply_list is not None ) and ( len( tags_to_apply_list ) > 0 ) ):\n",
    "        \n",
    "            print( \"- Applying tags \" + str( tags_to_apply_list ) + \" to article.\")\n",
    "\n",
    "            # yes, please.  Loop over tags list.\n",
    "            for tag_to_apply in tags_to_apply_list:\n",
    "            \n",
    "                # tag the article with each tag in the list.\n",
    "                current_article.tags.add( tag_to_apply )\n",
    "                \n",
    "                print( \"====> Applied tag \\\"\" + tag_to_apply + \"\\\".\" )\n",
    "                \n",
    "            #-- END loop over tag list. --#\n",
    "            \n",
    "            print( \"- Tags for article \" + str( current_article.id ) + \" : \" + str( current_article.tags.all() ) )\n",
    "            \n",
    "        #-- END check to see if we apply tag. --#\n",
    "\n",
    "        # output the tags.\n",
    "        print( \"- Tags for article \" + str( current_article.id ) + \" : \" + str( current_article.tags.all() ) )\n",
    "\n",
    "    #-- END loop over articles --#\n",
    "\n",
    "    # output the list.\n",
    "    print( \"Found \" + str( article_counter ) + \" articles ( \" + str( article_count ) + \" ).\" )\n",
    "    print( \"List of \" + str( len( article_id_list ) ) + \" local GRP staff article IDs: \" + \", \".join( article_id_list ) )\n",
    "    \n",
    "#-- END check to see if we process articles --#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Creation - GRP - examples\n",
    "\n",
    "just 2009-12-01 through 2009-12-31:\n",
    "\n",
    "    Filter params:\n",
    "    - date_range_start: 2009-12-01\n",
    "    - date_range_end: 2009-12-31\n",
    "    - newspaper: 1 - Grand Rapids Press, The ( GRPB )\n",
    "    - local_news_sections: ['Business', 'City and Region', 'Front Page', 'Lakeshore', 'Religion', 'Special', 'State']\n",
    "    - custom_article_q: (OR: ('author_varchar__iregex', '.* */ *THE GRAND RAPIDS PRESS$'), ('author_varchar__iregex', '.* */ *PRESS .* EDITOR$'), ('author_varchar__iregex', '.* */ *GRAND RAPIDS PRESS .* BUREAU$'), ('author_varchar__iregex', '.* */ *SPECIAL TO THE PRESS$'))\n",
    "\n",
    "    Article count before filtering on tags: 441\n",
    "    Article count after tag filtering: 441\n",
    "    \n",
    "All articles:\n",
    "\n",
    "    Filter params:\n",
    "    - date_range_start: None\n",
    "    - date_range_end: None\n",
    "    - newspaper: 1 - Grand Rapids Press, The ( GRPB )\n",
    "    - local_news_sections: ['Business', 'City and Region', 'Front Page', 'Lakeshore', 'Religion', 'Special', 'State']\n",
    "    - custom_article_q: (OR: ('author_varchar__iregex', '.* */ *THE GRAND RAPIDS PRESS$'), ('author_varchar__iregex', '.* */ *PRESS .* EDITOR$'), ('author_varchar__iregex', '.* */ *GRAND RAPIDS PRESS .* BUREAU$'), ('author_varchar__iregex', '.* */ *SPECIAL TO THE PRESS$'))\n",
    "\n",
    "    Article count before filtering on tags: 41107\n",
    "    Article count after tag filtering: 41107"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Creation - GRP - prelim month\n",
    "\n",
    "Description of month of GRP articles from December, 2009, for paper.\n",
    "\n",
    "- grp_month article count = 441\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T01:42:30.600014Z",
     "start_time": "2019-04-24T01:42:30.594787Z"
    }
   },
   "outputs": [],
   "source": [
    "from context_text.models import Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many articles in \"grp_month\"?\n",
    "article_qs = Article.objects.filter( tags__name__in = [ \"grp_month\" ] )\n",
    "grp_month_count = article_qs.count()\n",
    "\n",
    "print( \"grp_month count = {}\".format( grp_month_count ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Creation - local TDN articles\n",
    "\n",
    "- back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Definition of local hard news and in-house implementor:\n",
    "\n",
    "- Detroit News\n",
    "\n",
    "    - `context_text/examples/articles/articles-TDN-local_news.py`\n",
    "    - local hard news sections (stored in `from context_text.collectors.newsbank.newspapers.DTNB import DTNB` - `DTNB.NEWS_SECTION_NAME_LIST`):\n",
    "   \n",
    "        - \"Business\"\n",
    "        - \"Metro\"\n",
    "        - \"Nation\" - because of auto industry stories\n",
    "\n",
    "    - in-house implementor (based on byline patterns, stored in `DTNB.Q_IN_HOUSE_AUTHOR`):\n",
    "    \n",
    "        - Byline ends in \"/ The Detroit News\", ignore case.\n",
    "        \n",
    "            - `Q( author_varchar__iregex = r'.*\\s*/\\s*the\\s*detroit\\s*news$' )`\n",
    "\n",
    "        - Byline ends in \"Special to The Detroit News\", ignore case.\n",
    "        \n",
    "            - `Q( author_varchar__iregex = r'.*\\s*/\\s*special\\s*to\\s*the\\s*detroit\\s*news$' )`\n",
    "        \n",
    "        - Byline ends in \"Detroit News * Bureau\", ignore case.\n",
    "        \n",
    "            - `Q( author_varchar__iregex = r'.*\\s*/\\s*detroit\\s*news\\s*.*\\s*bureau$' )`    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T21:22:05.301192Z",
     "start_time": "2020-02-28T21:21:45.039449Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article count before filtering on Article IDs: 13070\n",
      "Article count before filtering on tags: 13070\n",
      "Article count after tag filtering: 13070\n",
      "Article count after filtering on cleanup_status - filter out any that have already been cleaned up: 13036\n",
      "Article count after ORDER-ing: 13036\n",
      "Article count after LIMIT-ing: 13036\n"
     ]
    }
   ],
   "source": [
    "#==============================================================================#\n",
    "# ! imports\n",
    "#==============================================================================#\n",
    "\n",
    "# Django query object for OR-ing selection criteria together.\n",
    "from django.db.models import Q\n",
    "\n",
    "# imports - python_utilities\n",
    "from python_utilities.logging.logging_helper import LoggingHelper\n",
    "\n",
    "# imports - context_text\n",
    "from context_text.collectors.newsbank.newspapers.DTNB import DTNB\n",
    "from context_text.models import Article\n",
    "from context_text.models import Article_Text\n",
    "from context_text.models import Newspaper\n",
    "\n",
    "#==============================================================================#\n",
    "# ! declare variables\n",
    "#==============================================================================#\n",
    "selected_newspaper = None\n",
    "article_qs = None\n",
    "article_count = -1\n",
    "article_counter = -1\n",
    "\n",
    "# declare variables - filtering\n",
    "start_date = \"\"\n",
    "end_date = \"\"\n",
    "local_news_sections = []\n",
    "section_name_in_list = []\n",
    "custom_article_q = None\n",
    "affiliation = \"\"\n",
    "article_id_list = []\n",
    "article_id_in_list = []\n",
    "tags_in_list = []\n",
    "tags_not_in_list = []\n",
    "filter_out_prelim_tags = False\n",
    "random_count = -1\n",
    "limit_count = -1\n",
    "article_counter = -1\n",
    "\n",
    "# declare variables - capturing author info.\n",
    "do_capture_author_info = False\n",
    "processing_counter = -1\n",
    "processing_id_list = []\n",
    "processing_section_list = []\n",
    "\n",
    "# declare variables - size of random sample we want\n",
    "#random_count = 60\n",
    "\n",
    "# declare variables - also, apply tag?\n",
    "do_apply_tag = False\n",
    "tags_to_apply_list = []\n",
    "\n",
    "# declare variables - details on author string anomalies\n",
    "anomaly_detail = {}\n",
    "author_anomaly_article_id = -1\n",
    "author_anomaly_author_string = \"\"\n",
    "author_anomaly_graf_1 = \"\"\n",
    "author_anomaly_graf_2 = \"\"\n",
    "anomaly_detail_string = \"\"\n",
    "\n",
    "#==============================================================================#\n",
    "# ! configure filters\n",
    "#==============================================================================#\n",
    "\n",
    "# ==> Article.filter_articles()\n",
    "# date range, newspaper, section list, and custom Q().\n",
    "start_date = None\n",
    "end_date = None\n",
    "selected_newspaper = None\n",
    "section_name_in_list = None\n",
    "custom_article_q = None\n",
    "\n",
    "# month of local news from Detroit News from 2009-12-01 to 2009-12-31\n",
    "#start_date = \"2009-12-01\"\n",
    "#end_date = \"2009-12-31\"\n",
    "selected_newspaper = Newspaper.objects.get( id = 2 ) # Detroit News\n",
    "\n",
    "# limit to \"local, regional and state news\" sections.\n",
    "section_name_in_list = DTNB.NEWS_SECTION_NAME_LIST\n",
    "\n",
    "# limit to staff reporters.\n",
    "custom_article_q = DTNB.Q_IN_HOUSE_AUTHOR\n",
    "\n",
    "# ==> article IDs - include\n",
    "#article_id_in_list = None\n",
    "\n",
    "# ==> tags - exclude\n",
    "#tags_not_in_list = [ \"prelim_reliability\", \"prelim_network\" ]\n",
    "tags_not_in_list = None\n",
    "\n",
    "# ==> tags - include only those with certain tags.\n",
    "#tags_in_list = [ \"prelim_reliability\", \"prelim_network\" ]\n",
    "#tags_in_list = [ \"prelim_reliability\", ]\n",
    "tags_in_list = None\n",
    "\n",
    "# ==> filter out \"*prelim*\" tags?\n",
    "filter_out_prelim_tags = False\n",
    "\n",
    "# ==> ORDER BY - do we want a random sample?\n",
    "#random_count = 10\n",
    "random_count = -1\n",
    "\n",
    "#==============================================================================#\n",
    "# ! configure processing\n",
    "#==============================================================================#\n",
    "\n",
    "do_capture_author_info = False\n",
    "do_apply_tag = False\n",
    "tags_to_apply_list = []\n",
    "#tags_to_apply_list = [ \"locally_implemented_hard_news\" ]\n",
    "\n",
    "print( \"Filter params:\" )\n",
    "print( \"- date_range_start: {}\".format( date_range_start ) )\n",
    "print( \"- date_range_end: {}\".format( date_range_end ) )\n",
    "print( \"- newspaper: {}\".format( newspaper ) )\n",
    "print( \"- local_news_sections: {}\".format( local_news_sections ) )\n",
    "print( \"- custom_article_q: {}\".format( custom_article_q ) )\n",
    "print( \"\" )\n",
    "\n",
    "#==============================================================================#\n",
    "# ! filtering\n",
    "#==============================================================================#\n",
    "\n",
    "# start with all articles\n",
    "article_qs = Article.objects.all()\n",
    "\n",
    "# ! ==> call Article.filter_articles()\n",
    "article_qs = Article.filter_articles( qs_IN = article_qs,\n",
    "                                      start_date = start_date,\n",
    "                                      end_date = end_date,\n",
    "                                      newspaper = selected_newspaper,\n",
    "                                      section_name_list = section_name_in_list,\n",
    "                                      custom_article_q = custom_article_q )\n",
    "\n",
    "# how many is that?\n",
    "article_count = article_qs.count()\n",
    "print( \"Article count before filtering on Article IDs: \" + str( article_count ) )\n",
    "\n",
    "# ! ==> article IDs in list\n",
    "if ( ( article_id_in_list is not None ) and ( len( article_id_in_list ) > 0 ) ):\n",
    "\n",
    "    # include those in a list\n",
    "    print( \"filtering articles to those with IDs: \" + str( article_id_in_list ) )\n",
    "    article_qs = article_qs.filter( id__in = article_id_in_list )\n",
    "\n",
    "#-- END check to see if we have a specific list of tags we want to exclude --#\n",
    "\n",
    "# how many is that?\n",
    "article_count = article_qs.count()\n",
    "print( \"Article count before filtering on tags: \" + str( article_count ) )\n",
    "\n",
    "# ! ==> tags - exclude\n",
    "\n",
    "# tags to exclude\n",
    "if ( ( tags_not_in_list is not None ) and ( len( tags_not_in_list ) > 0 ) ):\n",
    "\n",
    "    # exclude those in a list\n",
    "    print( \"exclude-ing articles with tags: \" + str( tags_not_in_list ) )\n",
    "    article_qs = article_qs.exclude( tags__name__in = tags_not_in_list )\n",
    "\n",
    "#-- END check to see if we have a specific list of tags we want to exclude --#\n",
    "\n",
    "# ! ==> tags - include only those with certain tags.\n",
    "if ( ( tags_in_list is not None ) and ( len( tags_in_list ) > 0 ) ):\n",
    "\n",
    "    # filter\n",
    "    print( \"filtering to just articles with tags: \" + str( tags_in_list ) )\n",
    "    article_qs = article_qs.filter( tags__name__in = tags_in_list )\n",
    "    \n",
    "#-- END check to see if we have a specific list of tags we want to include --#\n",
    "\n",
    "# ! ==> filter out \"*prelim*\" tags?\n",
    "if ( filter_out_prelim_tags == True ):\n",
    "\n",
    "    # ifilter out all articles with any tag whose name contains \"prelim\".\n",
    "    print( \"filtering out articles with tags that contain \\\"prelim\\\"\" )\n",
    "    article_qs = article_qs.exclude( tags__name__icontains = \"prelim\" )\n",
    "    \n",
    "#-- END check to see if we filter out \"prelim_*\" tags --#\n",
    "\n",
    "# how many is that?\n",
    "article_count = article_qs.count()\n",
    "\n",
    "print( \"Article count after tag filtering: \" + str( article_count ) )\n",
    "\n",
    "# just want un-cleaned-up:\n",
    "article_qs = article_qs.filter( Q( cleanup_status = Article.CLEANUP_STATUS_NEW ) | Q( cleanup_status__isnull = True ) )\n",
    "article_count = article_qs.count()\n",
    "\n",
    "print( \"Article count after filtering on cleanup_status - filter out any that have already been cleaned up: \" + str( article_count ) )\n",
    "\n",
    "# ! ==> ORDER BY - do we want a random sample?\n",
    "#random_count = 10\n",
    "if ( random_count > 0 ):\n",
    "\n",
    "    # to get random, order them by \"?\", then use slicing to retrieve requested\n",
    "    #     number.\n",
    "    article_qs = article_qs.order_by( \"?\" )[ : random_count ]\n",
    "\n",
    "else:\n",
    "\n",
    "    # order by ID (can't re-order once a slice is taken, so can't re-order if\n",
    "    #     random sample).\n",
    "    article_qs = article_qs.order_by( \"id\" )\n",
    "\n",
    "#-- END check to see if we want random sample --#\n",
    "\n",
    "# this is a nice algorithm, also:\n",
    "# - http://www.titov.net/2005/09/21/do-not-use-order-by-rand-or-how-to-get-random-rows-from-table/\n",
    "\n",
    "# how many is that?\n",
    "article_count = article_qs.count()\n",
    "print( \"Article count after ORDER-ing: \" + str( article_count ) )\n",
    "\n",
    "# ! ==> LIMIT\n",
    "# limit_count = 1\n",
    "if ( limit_count > 0 ):\n",
    "\n",
    "    article_qs = article_qs[ : limit_count ]\n",
    "    \n",
    "#-- END check to see if we limit. --#\n",
    "\n",
    "# how many is that?\n",
    "article_count = article_qs.count()\n",
    "print( \"Article count after LIMIT-ing: \" + str( article_count ) )\n",
    "\n",
    "#==============================================================================#\n",
    "# ! processing - apply tags, capture author info\n",
    "#==============================================================================#\n",
    "\n",
    "# loop over articles?\n",
    "if ( ( do_apply_tag == True ) or ( do_capture_author_info == True ) ):\n",
    "\n",
    "    # capture author information\n",
    "    processing_counter = 0\n",
    "    processing_id_list = []\n",
    "    processing_section_list = []\n",
    "    for current_article in article_qs:\n",
    "    \n",
    "        # increment counter\n",
    "        processing_counter += 1\n",
    "        \n",
    "        # update auditing information\n",
    "        processing_id_list.append( current_article.id )\n",
    "        if ( current_article.section not in processing_section_list ):\n",
    "\n",
    "            # add hitherto unseen section to list.\n",
    "            processing_section_list.append( current_article.section )\n",
    "            \n",
    "        #-- END check to see if we've already captured this section. --#\n",
    "        \n",
    "        print( \"\\nArticle \" + str( processing_counter ) + \" of \" + str( article_count ) + \": \" + str( current_article ) )\n",
    "\n",
    "        # ! ==> capture_author_info()\n",
    "        \n",
    "        # are we capturing author info?\n",
    "        if ( do_capture_author_info ):\n",
    "    \n",
    "            print( \"- Attempting to capture author information from body of article.\")\n",
    "    \n",
    "            # call capture_author_info()\n",
    "            capture_status = tdn.capture_author_info( current_article )\n",
    "            capture_status_list = capture_status.get_message_list()\n",
    "            \n",
    "            # output status list\n",
    "            print( \"====> \" + str( processing_counter ) + \" - Article ID: \" + str( current_article.id ) + \"; capture_status = \" + str( capture_status ) )\n",
    "            \n",
    "        #-- END check to see if we try to capture author info --#\n",
    "        \n",
    "        # ! ==> apply tags\n",
    "        \n",
    "        # apply tag(s) while we are at it?\n",
    "        if ( ( do_apply_tag == True ) and ( tags_to_apply_list is not None ) and ( len( tags_to_apply_list ) > 0 ) ):\n",
    "        \n",
    "            print( \"- Applying tags \" + str( tags_to_apply_list ) + \" to article.\")\n",
    "\n",
    "            # yes, please.  Loop over tags list.\n",
    "            for tag_to_apply in tags_to_apply_list:\n",
    "            \n",
    "                # tag the article with each tag in the list.\n",
    "                current_article.tags.add( tag_to_apply )\n",
    "                \n",
    "                print( \"====> Applied tag \\\"\" + tag_to_apply + \"\\\".\" )\n",
    "                \n",
    "            #-- END loop over tag list. --#\n",
    "            \n",
    "            print( \"- Tags for article \" + str( current_article.id ) + \" : \" + str( current_article.tags.all() ) )\n",
    "            \n",
    "        #-- END check to see if we apply tag. --#\n",
    "        \n",
    "    #-- END loop over articles to capture author info. --#\n",
    "    \n",
    "    print( \"\\n\" )\n",
    "    print( \"Processed \" + str( processing_counter ) + \" filtered article IDs: \" + str( sorted( processing_id_list ) ) + \" in the following sections of the paper: \" + str( processing_section_list ) )\n",
    "\n",
    "#-- END check to see if there is work to do. --#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Creation - TDN - local bylines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================#\n",
    "# ! imports\n",
    "#==============================================================================#\n",
    "\n",
    "# Django query object for OR-ing selection criteria together.\n",
    "from django.db.models import Q\n",
    "\n",
    "# imports - python_utilities\n",
    "from python_utilities.logging.logging_helper import LoggingHelper\n",
    "\n",
    "# imports - context_text\n",
    "from context_text.collectors.newsbank.newspapers.DTNB import DTNB\n",
    "from context_text.models import Article\n",
    "from context_text.models import Article_Text\n",
    "from context_text.models import Newspaper\n",
    "\n",
    "#==============================================================================#\n",
    "# ! declare variables\n",
    "#==============================================================================#\n",
    "selected_newspaper = None\n",
    "article_qs = None\n",
    "article_count = -1\n",
    "article_counter = -1\n",
    "\n",
    "# declare variables - filtering\n",
    "start_date = \"\"\n",
    "end_date = \"\"\n",
    "local_news_sections = []\n",
    "section_name_in_list = []\n",
    "custom_article_q = None\n",
    "affiliation = \"\"\n",
    "article_id_list = []\n",
    "article_id_in_list = []\n",
    "tags_in_list = []\n",
    "tags_not_in_list = []\n",
    "filter_out_prelim_tags = False\n",
    "random_count = -1\n",
    "limit_count = -1\n",
    "article_counter = -1\n",
    "\n",
    "# declare variables - capturing author info.\n",
    "do_capture_author_info = False\n",
    "processing_counter = -1\n",
    "processing_id_list = []\n",
    "processing_section_list = []\n",
    "\n",
    "# declare variables - size of random sample we want\n",
    "#random_count = 60\n",
    "\n",
    "# declare variables - also, apply tag?\n",
    "do_apply_tag = False\n",
    "tags_to_apply_list = []\n",
    "\n",
    "# declare variables - details on author string anomalies\n",
    "anomaly_detail = {}\n",
    "author_anomaly_article_id = -1\n",
    "author_anomaly_author_string = \"\"\n",
    "author_anomaly_graf_1 = \"\"\n",
    "author_anomaly_graf_2 = \"\"\n",
    "anomaly_detail_string = \"\"\n",
    "\n",
    "#==============================================================================#\n",
    "# ! configure filters\n",
    "#==============================================================================#\n",
    "\n",
    "# ==> Article.filter_articles()\n",
    "# date range, newspaper, section list, and custom Q().\n",
    "start_date = \"\"\n",
    "end_date = \"\"\n",
    "selected_newspaper = None\n",
    "section_name_in_list = None\n",
    "custom_article_q = None\n",
    "\n",
    "# month of local news from Detroit News from 2009-12-01 to 2009-12-31\n",
    "#start_date = \"2009-12-01\"\n",
    "#end_date = \"2009-12-31\"\n",
    "selected_newspaper = Newspaper.objects.get( id = 2 ) # Detroit News\n",
    "\n",
    "# limit to \"local, regional and state news\" sections.\n",
    "section_name_in_list = DTNB.NEWS_SECTION_NAME_LIST\n",
    "\n",
    "# limit to staff reporters.\n",
    "custom_article_q = DTNB.Q_IN_HOUSE_AUTHOR\n",
    "\n",
    "# ==> article IDs - include\n",
    "#article_id_in_list = None\n",
    "\n",
    "# ==> tags - exclude\n",
    "#tags_not_in_list = [ \"prelim_reliability\", \"prelim_network\" ]\n",
    "tags_not_in_list = None\n",
    "\n",
    "# ==> tags - include only those with certain tags.\n",
    "#tags_in_list = [ \"prelim_reliability\", \"prelim_network\" ]\n",
    "#tags_in_list = [ \"prelim_reliability\", ]\n",
    "tags_in_list = None\n",
    "\n",
    "# ==> filter out \"*prelim*\" tags?\n",
    "filter_out_prelim_tags = False\n",
    "\n",
    "# ==> ORDER BY - do we want a random sample?\n",
    "#random_count = 10\n",
    "random_count = -1\n",
    "\n",
    "#==============================================================================#\n",
    "# ! configure processing\n",
    "#==============================================================================#\n",
    "\n",
    "do_capture_author_info = False\n",
    "do_apply_tag = False\n",
    "tags_to_apply_list = []\n",
    "#tags_to_apply_list = [ \"locally_implemented_hard_news\" ]\n",
    "\n",
    "#==============================================================================#\n",
    "# ! filtering\n",
    "#==============================================================================#\n",
    "\n",
    "# start with all articles\n",
    "article_qs = Article.objects.all()\n",
    "\n",
    "# ! ==> call Article.filter_articles()\n",
    "article_qs = Article.filter_articles( qs_IN = article_qs,\n",
    "                                      start_date = start_date,\n",
    "                                      end_date = end_date,\n",
    "                                      newspaper = selected_newspaper,\n",
    "                                      section_name_list = section_name_in_list,\n",
    "                                      custom_article_q = custom_article_q )\n",
    "\n",
    "# how many is that?\n",
    "article_count = article_qs.count()\n",
    "print( \"Article count before filtering on Article IDs: \" + str( article_count ) )\n",
    "\n",
    "# ! ==> article IDs in list\n",
    "if ( ( article_id_in_list is not None ) and ( len( article_id_in_list ) > 0 ) ):\n",
    "\n",
    "    # include those in a list\n",
    "    print( \"filtering articles to those with IDs: \" + str( article_id_in_list ) )\n",
    "    article_qs = article_qs.filter( id__in = article_id_in_list )\n",
    "\n",
    "#-- END check to see if we have a specific list of tags we want to exclude --#\n",
    "\n",
    "# how many is that?\n",
    "article_count = article_qs.count()\n",
    "print( \"Article count before filtering on tags: \" + str( article_count ) )\n",
    "\n",
    "# ! ==> tags - exclude\n",
    "\n",
    "# tags to exclude\n",
    "if ( ( tags_not_in_list is not None ) and ( len( tags_not_in_list ) > 0 ) ):\n",
    "\n",
    "    # exclude those in a list\n",
    "    print( \"exclude-ing articles with tags: \" + str( tags_not_in_list ) )\n",
    "    article_qs = article_qs.exclude( tags__name__in = tags_not_in_list )\n",
    "\n",
    "#-- END check to see if we have a specific list of tags we want to exclude --#\n",
    "\n",
    "# ! ==> tags - include only those with certain tags.\n",
    "if ( ( tags_in_list is not None ) and ( len( tags_in_list ) > 0 ) ):\n",
    "\n",
    "    # filter\n",
    "    print( \"filtering to just articles with tags: \" + str( tags_in_list ) )\n",
    "    article_qs = article_qs.filter( tags__name__in = tags_in_list )\n",
    "    \n",
    "#-- END check to see if we have a specific list of tags we want to include --#\n",
    "\n",
    "# ! ==> filter out \"*prelim*\" tags?\n",
    "if ( filter_out_prelim_tags == True ):\n",
    "\n",
    "    # ifilter out all articles with any tag whose name contains \"prelim\".\n",
    "    print( \"filtering out articles with tags that contain \\\"prelim\\\"\" )\n",
    "    article_qs = article_qs.exclude( tags__name__icontains = \"prelim\" )\n",
    "    \n",
    "#-- END check to see if we filter out \"prelim_*\" tags --#\n",
    "\n",
    "# how many is that?\n",
    "article_count = article_qs.count()\n",
    "\n",
    "print( \"Article count after tag filtering: \" + str( article_count ) )\n",
    "\n",
    "# just want un-cleaned-up:\n",
    "article_qs = article_qs.filter( Q( cleanup_status = Article.CLEANUP_STATUS_NEW ) | Q( cleanup_status__isnull = True ) )\n",
    "article_count = article_qs.count()\n",
    "\n",
    "print( \"Article count after filtering on cleanup_status - filter out any that have already been cleaned up: \" + str( article_count ) )\n",
    "\n",
    "# ! ==> ORDER BY - do we want a random sample?\n",
    "#random_count = 10\n",
    "if ( random_count > 0 ):\n",
    "\n",
    "    # to get random, order them by \"?\", then use slicing to retrieve requested\n",
    "    #     number.\n",
    "    article_qs = article_qs.order_by( \"?\" )[ : random_count ]\n",
    "\n",
    "else:\n",
    "\n",
    "    # order by ID (can't re-order once a slice is taken, so can't re-order if\n",
    "    #     random sample).\n",
    "    article_qs = article_qs.order_by( \"id\" )\n",
    "\n",
    "#-- END check to see if we want random sample --#\n",
    "\n",
    "# this is a nice algorithm, also:\n",
    "# - http://www.titov.net/2005/09/21/do-not-use-order-by-rand-or-how-to-get-random-rows-from-table/\n",
    "\n",
    "# how many is that?\n",
    "article_count = article_qs.count()\n",
    "print( \"Article count after ORDER-ing: \" + str( article_count ) )\n",
    "\n",
    "# ! ==> LIMIT\n",
    "# limit_count = 1\n",
    "if ( limit_count > 0 ):\n",
    "\n",
    "    article_qs = article_qs[ : limit_count ]\n",
    "    \n",
    "#-- END check to see if we limit. --#\n",
    "\n",
    "# how many is that?\n",
    "article_count = article_qs.count()\n",
    "print( \"Article count after LIMIT-ing: \" + str( article_count ) )\n",
    "\n",
    "#==============================================================================#\n",
    "# ! analyze_author_info()\n",
    "#==============================================================================#\n",
    "\n",
    "# create instance of DTNB.\n",
    "tdn = DTNB()\n",
    "\n",
    "# run analysis.\n",
    "tdn.analyze_author_info( article_qs )\n",
    "\n",
    "# output details.\n",
    "tdn.output_debug_message( \"========================================\" )\n",
    "tdn.output_debug_message( \"Found \" + str( tdn.article_counter ) + \" articles ( \" + str( tdn.article_count ) + \" ).\" )\n",
    "\n",
    "# name in 1st paragraph?\n",
    "tdn.output_debug_message( \"\\n\" )\n",
    "tdn.output_debug_message( \"Found \" + str( len( tdn.graf_1_has_name_id_list ) ) + \" ( \" + str( tdn.graf_1_has_name_count ) + \" ) articles WITH name in 1st graf.\" )\n",
    "#tdn.output_debug_message( \"----> Sections: \" + str( sorted( tdn.graf_1_has_name_section_list ) ) )\n",
    "#tdn.output_debug_message( \"----> IDs: \" + str( sorted( tdn.graf_1_has_name_id_list ) ) )\n",
    "tdn.output_debug_message( \"\" )\n",
    "tdn.output_debug_message( \"Found \" + str( len( tdn.graf_1_no_name_id_list ) ) + \" articles WITHOUT name in 1st graf.\" )\n",
    "tdn.output_debug_message( \"----> Sections: \" + str( sorted( tdn.graf_1_no_name_section_list ) ) )\n",
    "tdn.output_debug_message( \"----> IDs (sorted): \" + str( sorted( tdn.graf_1_no_name_id_list ) ) )\n",
    "tdn.output_debug_message( \"----> IDs: \" + str( tdn.graf_1_no_name_id_list ) )\n",
    "tdn.output_debug_message( \"----> graf text: \" )\n",
    "tdn.output_debug_message( \"----> NO NAME 1st GRAF anomaly details: \" )\n",
    "\n",
    "# output author name anomaly details.\n",
    "for anomaly_detail in tdn.graf_1_no_name_detail_list:\n",
    "\n",
    "    # get anomaly details\n",
    "    author_anomaly_article_id = anomaly_detail.get( DTNB.AUTHOR_ANOMALY_DETAIL_ARTICLE_ID, -1 )\n",
    "    author_anomaly_author_string = anomaly_detail.get( DTNB.AUTHOR_ANOMALY_DETAIL_AUTHOR_STRING, \"\" )\n",
    "    author_anomaly_graf_1 = anomaly_detail.get( DTNB.AUTHOR_ANOMALY_DETAIL_GRAF_1, \"\" )\n",
    "    author_anomaly_graf_2 = anomaly_detail.get( DTNB.AUTHOR_ANOMALY_DETAIL_GRAF_2, \"\" )\n",
    "    \n",
    "    # output them.\n",
    "    anomaly_detail_string = \"--------> article ID: \" + str( author_anomaly_article_id )\n",
    "    anomaly_detail_string += \"\\n- author_string: \" + str( author_anomaly_author_string )\n",
    "    anomaly_detail_string += \"\\n- graf 1: \" + author_anomaly_graf_1\n",
    "    anomaly_detail_string += \"\\n- graf 2: \" + author_anomaly_graf_2\n",
    "    anomaly_detail_string += \"\\n\"\n",
    "    tdn.output_debug_message( anomaly_detail_string )\n",
    "\n",
    "#-- END loop over author anomaly details --#\n",
    "\n",
    "tdn.output_debug_message( \"----> got name?: \" + str( tdn.graf_1_no_name_yes_author_count ) )\n",
    "\n",
    "# \"by\" in 1st paragraph?\n",
    "tdn.output_debug_message( \"\\n\" )\n",
    "tdn.output_debug_message( \"Found \" + str( len( tdn.graf_1_has_by_id_list ) ) + \" ( \" + str( tdn.graf_1_has_by_count ) + \" ) articles WITH \\\"by\\\" in 1st graf.\" )\n",
    "#tdn.output_debug_message( \"----> Sections: \" + str( sorted( tdn.graf_1_has_by_section_list ) ) )\n",
    "#tdn.output_debug_message( \"----> IDs: \" + str( sorted( tdn.graf_1_has_by_id_list ) ) )\n",
    "tdn.output_debug_message( \"\" )\n",
    "tdn.output_debug_message( \"Found \" + str( len( tdn.graf_1_no_by_id_list ) ) + \" articles WITHOUT \\\"by\\\" in 1st graf.\" )\n",
    "tdn.output_debug_message( \"----> Sections: \" + str( sorted( tdn.graf_1_no_by_section_list ) ) )\n",
    "tdn.output_debug_message( \"----> IDs (sorted): \" + str( sorted( tdn.graf_1_no_by_id_list ) ) )\n",
    "tdn.output_debug_message( \"----> IDs: \" + str( tdn.graf_1_no_by_id_list ) )\n",
    "tdn.output_debug_message( \"----> graf text: \" )\n",
    "tdn.output_debug_message( \"----> NO BY 1st GRAF anomaly details: \" )\n",
    "\n",
    "# output author name anomaly details.\n",
    "for anomaly_detail in tdn.graf_1_no_by_detail_list:\n",
    "\n",
    "    # get anomaly details\n",
    "    author_anomaly_article_id = anomaly_detail.get( DTNB.AUTHOR_ANOMALY_DETAIL_ARTICLE_ID, -1 )\n",
    "    author_anomaly_author_string = anomaly_detail.get( DTNB.AUTHOR_ANOMALY_DETAIL_AUTHOR_STRING, \"\" )\n",
    "    author_anomaly_graf_1 = anomaly_detail.get( DTNB.AUTHOR_ANOMALY_DETAIL_GRAF_1, \"\" )\n",
    "    author_anomaly_graf_2 = anomaly_detail.get( DTNB.AUTHOR_ANOMALY_DETAIL_GRAF_2, \"\" )\n",
    "    \n",
    "    # output them.\n",
    "    anomaly_detail_string = \"--------> article ID: \" + str( author_anomaly_article_id )\n",
    "    anomaly_detail_string += \"\\n- author_string: \" + str( author_anomaly_author_string )\n",
    "    anomaly_detail_string += \"\\n- graf 1: \" + author_anomaly_graf_1\n",
    "    anomaly_detail_string += \"\\n- graf 2: \" + author_anomaly_graf_2\n",
    "    anomaly_detail_string += \"\\n\"\n",
    "    tdn.output_debug_message( anomaly_detail_string )\n",
    "\n",
    "#-- END loop over author anomaly details --#\n",
    "\n",
    "tdn.output_debug_message( \"----> got name?: \" + str( tdn.graf_1_no_by_yes_author_count ) )\n",
    "\n",
    "# \"detroit news\" in 2nd paragraph?\n",
    "tdn.output_debug_message( \"\\n\" )\n",
    "tdn.output_debug_message( \"Found \" + str( len( tdn.graf_2_has_DN_id_list ) ) + \" ( \" + str( tdn.graf_2_has_DN_count ) + \" ) articles WITH \\\"detroit news\\\" in 2nd graf.\" )\n",
    "#tdn.output_debug_message( \"----> Sections: \" + str( sorted( tdn.graf_2_has_DN_section_list ) ) )\n",
    "#tdn.output_debug_message( \"----> IDs: \" + str( sorted( tdn.graf_2_has_DN_id_list ) ) )\n",
    "tdn.output_debug_message( \"\" )\n",
    "tdn.output_debug_message( \"Found \" + str( len( tdn.graf_2_no_DN_id_list ) ) + \" articles WITHOUT \\\"detroit news\\\" in 2nd graf.\" )\n",
    "tdn.output_debug_message( \"----> Sections: \" + str( sorted( tdn.graf_2_no_DN_section_list ) ) )\n",
    "tdn.output_debug_message( \"----> IDs: \" + str( sorted( tdn.graf_2_no_DN_id_list ) ) )\n",
    "tdn.output_debug_message( \"----> graf text: \" )\n",
    "tdn.output_debug_message( \"----> NO \\\"detroit news\\\" 2nd GRAF anomaly details: \" )\n",
    "\n",
    "# output author name anomaly details.\n",
    "for anomaly_detail in tdn.graf_2_no_DN_detail_list:\n",
    "\n",
    "    # get anomaly details\n",
    "    author_anomaly_article_id = anomaly_detail.get( DTNB.AUTHOR_ANOMALY_DETAIL_ARTICLE_ID, -1 )\n",
    "    author_anomaly_author_string = anomaly_detail.get( DTNB.AUTHOR_ANOMALY_DETAIL_AUTHOR_STRING, \"\" )\n",
    "    author_anomaly_graf_1 = anomaly_detail.get( DTNB.AUTHOR_ANOMALY_DETAIL_GRAF_1, \"\" )\n",
    "    author_anomaly_graf_2 = anomaly_detail.get( DTNB.AUTHOR_ANOMALY_DETAIL_GRAF_2, \"\" )\n",
    "    \n",
    "    # output them.\n",
    "    anomaly_detail_string = \"--------> article ID: \" + str( author_anomaly_article_id )\n",
    "    anomaly_detail_string += \"\\n- author_string: \" + str( author_anomaly_author_string )\n",
    "    anomaly_detail_string += \"\\n- graf 1: \" + author_anomaly_graf_1\n",
    "    anomaly_detail_string += \"\\n- graf 2: \" + author_anomaly_graf_2\n",
    "    anomaly_detail_string += \"\\n\"\n",
    "    tdn.output_debug_message( anomaly_detail_string )\n",
    "\n",
    "#-- END loop over author anomaly details --#\n",
    "\n",
    "# all article IDs in set.\n",
    "#tdn.output_debug_message( \"\\n\" )\n",
    "#tdn.output_debug_message( \"List of \" + str( len( tdn.article_id_list ) ) + \" filtered article IDs: \" + str( sorted( tdn.article_id_list ) ) )\n",
    "\n",
    "#==============================================================================#\n",
    "# ! processing - apply tags, capture author info\n",
    "#==============================================================================#\n",
    "\n",
    "# loop over articles?\n",
    "if ( ( do_apply_tag == True ) or ( do_capture_author_info == True ) ):\n",
    "\n",
    "    # capture author information\n",
    "    processing_counter = 0\n",
    "    processing_id_list = []\n",
    "    processing_section_list = []\n",
    "    for current_article in article_qs:\n",
    "    \n",
    "        # increment counter\n",
    "        processing_counter += 1\n",
    "        \n",
    "        # update auditing information\n",
    "        processing_id_list.append( current_article.id )\n",
    "        if ( current_article.section not in processing_section_list ):\n",
    "\n",
    "            # add hitherto unseen section to list.\n",
    "            processing_section_list.append( current_article.section )\n",
    "            \n",
    "        #-- END check to see if we've already captured this section. --#\n",
    "        \n",
    "        print( \"\\nArticle \" + str( processing_counter ) + \" of \" + str( article_count ) + \": \" + str( current_article ) )\n",
    "\n",
    "        # ! ==> capture_author_info()\n",
    "        \n",
    "        # are we capturing author info?\n",
    "        if ( do_capture_author_info ):\n",
    "    \n",
    "            print( \"- Attempting to capture author information from body of article.\")\n",
    "    \n",
    "            # call capture_author_info()\n",
    "            capture_status = tdn.capture_author_info( current_article )\n",
    "            capture_status_list = capture_status.get_message_list()\n",
    "            \n",
    "            # output status list\n",
    "            print( \"====> \" + str( processing_counter ) + \" - Article ID: \" + str( current_article.id ) + \"; capture_status = \" + str( capture_status ) )\n",
    "            \n",
    "        #-- END check to see if we try to capture author info --#\n",
    "        \n",
    "        # ! ==> apply tags\n",
    "        \n",
    "        # apply tag(s) while we are at it?\n",
    "        if ( ( do_apply_tag == True ) and ( tags_to_apply_list is not None ) and ( len( tags_to_apply_list ) > 0 ) ):\n",
    "        \n",
    "            print( \"- Applying tags \" + str( tags_to_apply_list ) + \" to article.\")\n",
    "\n",
    "            # yes, please.  Loop over tags list.\n",
    "            for tag_to_apply in tags_to_apply_list:\n",
    "            \n",
    "                # tag the article with each tag in the list.\n",
    "                current_article.tags.add( tag_to_apply )\n",
    "                \n",
    "                print( \"====> Applied tag \\\"\" + tag_to_apply + \"\\\".\" )\n",
    "                \n",
    "            #-- END loop over tag list. --#\n",
    "            \n",
    "            print( \"- Tags for article \" + str( current_article.id ) + \" : \" + str( current_article.tags.all() ) )\n",
    "            \n",
    "        #-- END check to see if we apply tag. --#\n",
    "        \n",
    "    #-- END loop over articles to capture author info. --#\n",
    "    \n",
    "    print( \"\\n\" )\n",
    "    print( \"Processed \" + str( processing_counter ) + \" filtered article IDs: \" + str( sorted( processing_id_list ) ) + \" in the following sections of the paper: \" + str( processing_section_list ) )\n",
    "\n",
    "#-- END check to see if there is work to do. --#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_virtualenv",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "689px",
    "left": "0px",
    "right": "1118px",
    "top": "111px",
    "width": "322px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
