{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a62fac68-0a57-47c6-b6cc-e62a02385a47",
   "metadata": {},
   "source": [
    "**analysis-network_data_output-GRP.ipynb - Programmatic network data output**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4ccabf-42d0-4217-8baf-87bd790d8478",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260fc288-1cd1-4af0-84f6-1e97011defdc",
   "metadata": {},
   "source": [
    "## Setup - Debug\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6a3ed9-96c2-441d-a443-371200c275f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T15:43:45.678275Z",
     "start_time": "2019-09-17T15:43:45.673730Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "debug_flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089876e6-2d2f-4fd0-96f6-730520fb0bab",
   "metadata": {},
   "source": [
    "## Setup - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c3f417-8fcb-49c1-85f3-44c070e980fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python base imports\n",
    "import copy\n",
    "import datetime\n",
    "import hashlib\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# import six\n",
    "import six\n",
    "\n",
    "print( \"packages imported at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105b958b-0102-4978-9132-ab0af2cd81c2",
   "metadata": {},
   "source": [
    "## Setup - working folder paths\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47541bda-424d-4bf7-8897-3e2cc19acefc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T15:43:47.305614Z",
     "start_time": "2019-09-17T15:43:47.286949Z"
    }
   },
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324f5746-3fe3-49bc-ba43-f38602b06bba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T15:43:48.159415Z",
     "start_time": "2019-09-17T15:43:48.153181Z"
    }
   },
   "outputs": [],
   "source": [
    "# current working folder\n",
    "project_name = \"research\"\n",
    "project_base_folder = \"/home/jonathanmorgan/work/django/{project_name}\".format( project_name = project_name )\n",
    "django_project_folder = \"{base_folder}/{project_name}\".format(\n",
    "    base_folder = project_base_folder,\n",
    "    project_name = project_name\n",
    ")\n",
    "current_working_folder = \"{django_project_folder}/work/phd_work/analysis/network_data\".format(\n",
    "    django_project_folder = django_project_folder\n",
    ")\n",
    "current_datetime = datetime.datetime.now()\n",
    "current_date_string = current_datetime.strftime( \"%Y-%m-%d-%H-%M-%S\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206e3216-5791-4be6-aa90-ff0917a1b486",
   "metadata": {},
   "source": [
    "## Setup - logging\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "configure logging for this notebook's kernel (If you do not run this cell, you'll get the django application's logging configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c7beff-b869-464c-9f82-66666ac46c69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T15:43:49.038050Z",
     "start_time": "2019-09-17T15:43:49.031535Z"
    }
   },
   "outputs": [],
   "source": [
    "# build file name\n",
    "project_log_folder = \"{base_folder}/logs\".format( base_folder = project_base_folder )\n",
    "logging_file_name = \"{}/network_data_output-GRP-{}.log.txt\".format( project_log_folder, current_date_string )\n",
    "\n",
    "# set up logging.\n",
    "logging.basicConfig(\n",
    "    level = logging.DEBUG,\n",
    "    format = '%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
    "    filename = logging_file_name,\n",
    "    filemode = 'w' # set to 'a' if you want to append, rather than overwrite each time.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17939321-ff9b-4230-84ef-5165d0d8820a",
   "metadata": {},
   "source": [
    "## Setup - Initialize Django\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "First, initialize my dev django project, so I can run code in this notebook that references my django models and can talk to the database using my project's settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daabb30f-9129-4d0a-85a2-f1b32a522275",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T15:43:52.077172Z",
     "start_time": "2019-09-17T15:43:52.071107Z"
    }
   },
   "outputs": [],
   "source": [
    "# init django\n",
    "django_init_folder = \"{django_project_folder}/work/phd_work\".format(\n",
    "    django_project_folder = django_project_folder\n",
    ")\n",
    "django_init_path = \"django_init.py\"\n",
    "if( ( django_init_folder is not None ) and ( django_init_folder != \"\" ) ):\n",
    "    \n",
    "    # add folder to front of path.\n",
    "    django_init_path = \"{}/{}\".format( django_init_folder, django_init_path )\n",
    "    \n",
    "#-- END check to see if django_init folder. --#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9e1ebf-ca96-45ed-8a3f-bfd418516e41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T15:43:54.453200Z",
     "start_time": "2019-09-17T15:43:52.833671Z"
    }
   },
   "outputs": [],
   "source": [
    "%run $django_init_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09170da9-c45c-4a93-8b0a-765ce4d9a790",
   "metadata": {},
   "source": [
    "### Setup - django-related imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4c9544-0d64-4cf1-baca-f1226617dec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python utilities\n",
    "from python_utilities.strings.string_helper import StringHelper\n",
    "\n",
    "# import class that actually processes requests for outputting networks.\n",
    "from context_text.export.network_output import NetworkOutput\n",
    "\n",
    "print( \"django model packages imported at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858984de-3b03-4475-9fbd-ee10f9c193e3",
   "metadata": {},
   "source": [
    "## Setup - functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b94cfc-259a-4ffd-84e8-0848379f1e84",
   "metadata": {},
   "source": [
    "### Setup - function `make_string_hash()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008b7d86-675e-497e-ac35-8b2349f67d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_string_hash( value_IN, hash_function_IN = hashlib.sha256 ):\n",
    "\n",
    "    # return reference\n",
    "    value_OUT = None\n",
    "\n",
    "    # declare variables\n",
    "    me = \"make_string_hash\"\n",
    "\n",
    "    # call StringHelper method.\n",
    "    value_OUT = StringHelper.make_string_hash( value_IN, hash_function_IN = hash_function_IN )\n",
    "\n",
    "    return value_OUT\n",
    "\n",
    "#-- END function make_string_hash() --#\n",
    "\n",
    "print( \"function make_string_hash() defined at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c03dbe0-2629-4761-907d-abc2af709dca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup - base data spec\n",
    "\n",
    "Network data spec that includes:\n",
    "\n",
    "- `Article_Data` and `Person` queries the same...:\n",
    "\n",
    "    - _`coders` (`person_coders`)_: 2 (automated coder, id = 2)\n",
    "    - coder type \"OpenCalais_REST_API_v2\"\n",
    "    \n",
    "        - _`coder_type_filter_type` (`person_coder_type_filter_type`)_: \"automated\"\n",
    "        - _`coder_types_list` (`person_coder_types_list`)_: \"OpenCalais_REST_API_v2\"\n",
    "    \n",
    "    - _`publications` (`person_publications`)_: 1 (Grand Rapids Press)\n",
    "    - all dates in database (from 2005-01-01 to 2010-11-30)\n",
    "    \n",
    "        - _`start_date` (`person_start_date`)_: \"2005-01-01\"\n",
    "        - _`end_date` (`person_end_date`)_: \"2010-11-30\"\n",
    "    \n",
    "    - only articles tagged with `local_hard_news` and `coded-OpenCalaisV2ArticleCoder`.\n",
    "\n",
    "        - _`tags_list` (`person_tags_list`)_: \"local_hard_news,coded-OpenCalaisV2ArticleCoder\"\n",
    "\n",
    "- ...EXCEPT allowing duplicate articles for person so you get absolutely all persons, but not for `Article_Data` query.\n",
    "\n",
    "    - _`person_allow_duplicate_articles`_: \"yes\"\n",
    "\n",
    "- Network data creation options:\n",
    "\n",
    "    - excludes persons with single word (no spaces) `verbatim_name`.\n",
    "    \n",
    "        - _`include_persons_with_single_word_name`_: \"no\"\n",
    "    \n",
    "    - exclude render details\n",
    "        \n",
    "        - _`network_include_render_details`_: \"no\"\n",
    "        \n",
    "    - ouput as tab-delimited matrix, with node attributes as additional columns on the far right of the square network part of the matrix.\n",
    "\n",
    "        - _`output_type`_: \"tab_delimited_matrix\"\n",
    "        - _`network_data_output_type`_: \"net_and_attr_cols\"\n",
    "\n",
    "    - label - _`network_label`_: \"all_grp_hard_news\"\n",
    "    - include header row in the matrix output file.\n",
    "    \n",
    "        - _`network_include_headers`_: \"yes\"\n",
    "\n",
    "    - output spec plus the resulting network data to the database, with lable set to `network_label` plus a date-time string.\n",
    "    \n",
    "        - _`database_output`_: \"yes\",\n",
    "        - _`db_add_timestamp_to_label`_: \"yes\"\n",
    "\n",
    "_NOTE: only pass True to `network_outputter.process_network_output_request( debug_flag_IN )` if you really need to debug - it adds garbage data at the end of the output, even if you ask for no render details._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ef24eb-3a73-4fc7-8b67-2979753889ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data_spec_json_string = \"\"\"{\n",
    "    \"start_date\": \"2005-01-01\",\n",
    "    \"end_date\": \"2005-12-31\",\n",
    "    \"date_range\": \"\",\n",
    "    \"publications\": \"1\",\n",
    "    \"coders\": \"2\",\n",
    "    \"coder_id_priority_list\": \"\",\n",
    "    \"coder_type_filter_type\": \"automated\",\n",
    "    \"coder_types_list\": \"OpenCalais_REST_API_v2\",\n",
    "    \"tags_list\": \"local_hard_news\",\n",
    "    \"unique_identifiers\": \"\",\n",
    "    \"allow_duplicate_articles\": \"no\",\n",
    "    \"person_query_type\": \"custom\",\n",
    "    \"person_start_date\": \"2005-01-01\",\n",
    "    \"person_end_date\": \"2010-11-30\",\n",
    "    \"person_date_range\": \"\",\n",
    "    \"person_publications\": \"1\",\n",
    "    \"person_coders\": \"2\",\n",
    "    \"person_coder_id_priority_list\": \"\",\n",
    "    \"person_coder_type_filter_type\": \"automated\",\n",
    "    \"person_coder_types_list\": \"OpenCalais_REST_API_v2\",\n",
    "    \"person_tags_list\": \"local_hard_news\",\n",
    "    \"person_unique_identifiers\": \"\",\n",
    "    \"person_allow_duplicate_articles\": \"yes\",\n",
    "    \"include_source_contact_types\": [\n",
    "        \"direct\",\n",
    "        \"event\",\n",
    "        \"past_quotes\",\n",
    "        \"document\",\n",
    "        \"other\"\n",
    "    ],\n",
    "    \"exclude_persons_with_tags_in_list\": \"\",\n",
    "    \"include_persons_with_single_word_name\": \"no\",\n",
    "    \"network_download_as_file\": \"no\",\n",
    "    \"network_include_render_details\": \"yes\",\n",
    "    \"output_type\": \"tab_delimited_matrix\",\n",
    "    \"network_data_output_type\": \"net_and_attr_cols\",\n",
    "    \"network_label\": \"all_grp_hard_news\",\n",
    "    \"network_include_headers\": \"yes\",\n",
    "    \"database_output\": \"yes\",\n",
    "    \"db_add_timestamp_to_label\": \"yes\"\n",
    "}\"\"\"\n",
    "\n",
    "base_data_spec_json = json.loads( base_data_spec_json_string )\n",
    "print( base_data_spec_json ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045a0216-61d3-450e-b73a-9daf681b5407",
   "metadata": {},
   "source": [
    "### Setup - update base data spec for different time slices\n",
    "\n",
    "To update this for different time slices:\n",
    "\n",
    "- make a copy of `base_data_spec_json`:\n",
    "\n",
    "    - not threadsafe:\n",
    "    \n",
    "            my_timeslice_spec = copy.deepcopy( base_data_spec_json )\n",
    "    \n",
    "    - threadsafe (but doesn't handle complex data types - ours is just JSON, though, so fine here):\n",
    "    \n",
    "            my_timeslice_spec = json.loads( json.dumps( base_data_spec_json ) )\n",
    "\n",
    "- update the `start_date` and `end_date` to the period you want for your time slice.\n",
    "\n",
    "        my_timeslice_spec[ NetworkOutput.PARAM_START_DATE ] = \"2009-12-01\"\n",
    "        my_timeslice_spec[ NetworkOutput.PARAM_END_DATE ] = \"2009-12-31\"\n",
    "\n",
    "- update the `network_label` value so that it captures what time slice you are making.\n",
    "\n",
    "        my_timeslice_spec[ NetworkOutput.PARAM_NETWORK_LABEL ] = \"month-grp-automated-20091201-20091231\"\n",
    "\n",
    "    - example pattern: <type>-<paper>-<coder>-<start_date>-<end_date>\n",
    "    - examples:\n",
    "        \n",
    "            week-grp-automated-20050501-20050507\n",
    "            7day-grp-automated-20050502-20050508\n",
    "\n",
    "    - type would be either:\n",
    "\n",
    "        - actual time period:\n",
    "\n",
    "            - week\n",
    "            - month\n",
    "            - quarter\n",
    "            - half-year\n",
    "            - year\n",
    "\n",
    "        - conceptual time period:\n",
    "\n",
    "            - sliding week = \"7day\"\n",
    "            - sliding month = \"31day\"\n",
    "            - sliding quarter = \"92day\"\n",
    "            - sliding half-year = \"183day\"\n",
    "            - sliding year = \"365day\"\n",
    "\n",
    "_NOTE: leave person query parameters the same for all networks if you want all your network matrices to have same set of people (same count and position of rows and columns) so each network can be compared to all others, regardless of time period of a given network slice._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20460e6-825e-4fb4-a403-eb320537bedb",
   "metadata": {},
   "source": [
    "# network data output example - base data spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d270743-ddb6-40b9-b77b-83f4e21fbb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try creating network data.\n",
    "network_outputter = NetworkOutput()\n",
    "network_data = network_outputter.process_network_output_request(\n",
    "    params_IN = base_data_spec_json,\n",
    "    debug_flag_IN = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7e6a5d-221b-459e-bf26-2dc96afdc494",
   "metadata": {},
   "source": [
    "- if include_persons_with_single_word_name = \"yes\": 2427606\n",
    "- if include_persons_with_single_word_name = \"no\": 2344545"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a765cbff-c2e9-4075-b0ee-7f9d351e0d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a hash of the data, for comparison\n",
    "network_data_hash = make_string_hash( network_data )\n",
    "print( \"Network data hash: {}\".format( network_data_hash ) )\n",
    "\n",
    "# match?\n",
    "should_be = \"0f8a530f18a724b3d724d7fe9caa3082954c049abdc02b77bc480fc432d0a770\"\n",
    "if ( network_data_hash != should_be ):\n",
    "    \n",
    "    # not right hash. Error.\n",
    "    print( \"ERROR! network data hash is {}, should be {}\".format( network_data_hash, should_be ) )\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # a match\n",
    "    print( \"MATCH - network data hash {} matches expected. hooray!\".format( network_data_hash ) )\n",
    "    \n",
    "#-- END debug/test --#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35b214c-d25d-4278-a645-bacec4eed51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_data_length = len( network_data )\n",
    "should_be = 11534\n",
    "print( \"Network data length: {}\".format( network_data_length ) )\n",
    "if ( network_data_length != should_be ):\n",
    "    \n",
    "    # not right length. Error.\n",
    "    print( \"ERROR! network data length is {}, should be {}\".format( network_data_length, should_be ) )\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # a match\n",
    "    print( \"MATCH - string len()gth of {} matches expected. hooray!\".format( network_data_length ) )\n",
    "    \n",
    "#-- END debug/test --#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793e0488-d275-4469-867f-f24a1c61b1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at master person dict\n",
    "master_person_dict = network_outputter.create_person_dict( load_person_IN = True )\n",
    "\n",
    "# how many entries?\n",
    "person_count = len( master_person_dict )\n",
    "print( \"- person count: {person_count}\".format( person_count = person_count ) )\n",
    "\n",
    "# right number?\n",
    "should_be = 66\n",
    "if ( person_count != should_be ):\n",
    "    \n",
    "    # not right length. Error.\n",
    "    print( \"ERROR! person count is {}, should be {}\".format( person_count, should_be ) )\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # a match\n",
    "    print( \"MATCH - person count of {} matches expected. hooray!\".format( person_count ) )\n",
    "    \n",
    "#-- END debug/test --#\n",
    "\n",
    "# the following persons should not be present\n",
    "find_person_list = list()\n",
    "\n",
    "# 1049, 752 (single names)\n",
    "find_person_list.append( 1049 )\n",
    "find_person_list.append( 752 )\n",
    "\n",
    "# 102, 224, 261 (tag `from_press_release`)\n",
    "find_person_list.append( 102 )\n",
    "find_person_list.append( 224 )\n",
    "find_person_list.append( 261 )\n",
    "\n",
    "# 187, 188, 189 (tag `godwin_heights`)\n",
    "find_person_list.append( 187 )\n",
    "find_person_list.append( 188 )\n",
    "find_person_list.append( 189 )\n",
    "\n",
    "# check for people who should have been removed.\n",
    "for find_person_id in find_person_list:\n",
    "\n",
    "    if ( find_person_id in master_person_dict ):\n",
    "    \n",
    "        print( \"ERROR - single-name person {} is in dictionary\".format( find_person_id ) )\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        print( \"SUCCESS - single-name person {} not in dictionary\".format( find_person_id ) )\n",
    "    \n",
    "    #-- END check for person --#\n",
    "\n",
    "#-- END loop over persons to find. --#\n",
    "\n",
    "# output all persons.\n",
    "for person_id, person_instance in master_person_dict.items():\n",
    "    \n",
    "    print( \"\\n==> Person {person_id}: {person_instance}\".format( person_id = person_id, person_instance = person_instance ) )\n",
    "    \n",
    "#-- END loop over persons --#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cc27cf-4318-4042-8932-3e24915392bf",
   "metadata": {},
   "source": [
    "# write network data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aada51-899c-476b-b564-4fd5ef4a7889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the output to a file\n",
    "current_date_time = None\n",
    "my_file_extension = None\n",
    "network_data_file_path = None\n",
    "network_data_file = None\n",
    "\n",
    "# time stamp and file extension to append to file name\n",
    "current_date_time = datetime.datetime.now().strftime( '%Y%m%d-%H%M%S' )\n",
    "my_file_extension = \"txt\"\n",
    "\n",
    "# make file path.\n",
    "network_data_file_path = \"context_text_data-{timestamp}.{file_extension}\".format(\n",
    "    timestamp = current_date_time,\n",
    "    file_extension = my_file_extension\n",
    ")\n",
    "\n",
    "# write to file.\n",
    "with open( network_data_file_path, 'w' ) as network_data_file:\n",
    "\n",
    "    # output all the data to file.\n",
    "    network_data_file.write( network_data )\n",
    "    \n",
    "#-- END with open( network_data_file_path, 'w' ) as network_data_file --#\n",
    "\n",
    "print( \"network data written to file {} at {}\".format( network_data_file_path, datetime.datetime.now() ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_virtualenv",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
