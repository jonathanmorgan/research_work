{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**analysis-todo.ipynb - context-based analysis TODO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#TODO\" data-toc-modified-id=\"TODO-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>TODO</a></span></li><li><span><a href=\"#Step-1---sourcenet-to-context\" data-toc-modified-id=\"Step-1---sourcenet-to-context-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Step 1 - sourcenet-to-context</a></span><ul class=\"toc-item\"><li><span><a href=\"#Step-1---TODO\" data-toc-modified-id=\"Step-1---TODO-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Step 1 - TODO</a></span><ul class=\"toc-item\"><li><span><a href=\"#Step-1---TODO---General\" data-toc-modified-id=\"Step-1---TODO---General-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Step 1 - TODO - General</a></span></li><li><span><a href=\"#Step-1---TODO---sourcenet-to-context\" data-toc-modified-id=\"Step-1---TODO---sourcenet-to-context-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Step 1 - TODO - sourcenet-to-context</a></span><ul class=\"toc-item\"><li><span><a href=\"#Step-1---TODO---Relation-Creation\" data-toc-modified-id=\"Step-1---TODO---Relation-Creation-2.1.2.1\"><span class=\"toc-item-num\">2.1.2.1&nbsp;&nbsp;</span>Step 1 - TODO - Relation Creation</a></span></li></ul></li></ul></li><li><span><a href=\"#Step-1---DONE\" data-toc-modified-id=\"Step-1---DONE-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Step 1 - DONE</a></span><ul class=\"toc-item\"><li><span><a href=\"#Step-1---DONE---General\" data-toc-modified-id=\"Step-1---DONE---General-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Step 1 - DONE - General</a></span></li><li><span><a href=\"#Step-1---DONE---sourcenet-to-context\" data-toc-modified-id=\"Step-1---DONE---sourcenet-to-context-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Step 1 - DONE - sourcenet-to-context</a></span><ul class=\"toc-item\"><li><span><a href=\"#Step-1---DONE---Entity-Creation\" data-toc-modified-id=\"Step-1---DONE---Entity-Creation-2.2.2.1\"><span class=\"toc-item-num\">2.2.2.1&nbsp;&nbsp;</span>Step 1 - DONE - Entity Creation</a></span></li><li><span><a href=\"#Step-1---DONE---Relation-Creation\" data-toc-modified-id=\"Step-1---DONE---Relation-Creation-2.2.2.2\"><span class=\"toc-item-num\">2.2.2.2&nbsp;&nbsp;</span>Step 1 - DONE - Relation Creation</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Step-2---filter-network-relations\" data-toc-modified-id=\"Step-2---filter-network-relations-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Step 2 - filter network relations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Step-2---TODO\" data-toc-modified-id=\"Step-2---TODO-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Step 2 - TODO</a></span><ul class=\"toc-item\"><li><span><a href=\"#Step-2---TODO---general\" data-toc-modified-id=\"Step-2---TODO---general-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Step 2 - TODO - general</a></span></li><li><span><a href=\"#Step-2---TODO---Network-data-filtering\" data-toc-modified-id=\"Step-2---TODO---Network-data-filtering-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Step 2 - TODO - Network data filtering</a></span></li></ul></li><li><span><a href=\"#Step-2---DONE\" data-toc-modified-id=\"Step-2---DONE-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Step 2 - DONE</a></span><ul class=\"toc-item\"><li><span><a href=\"#Step-2---DONE---general\" data-toc-modified-id=\"Step-2---DONE---general-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Step 2 - DONE - general</a></span></li><li><span><a href=\"#Step-2---DONE---Network-data-filtering\" data-toc-modified-id=\"Step-2---DONE---Network-data-filtering-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Step 2 - DONE - Network data filtering</a></span><ul class=\"toc-item\"><li><span><a href=\"#2019.12.10\" data-toc-modified-id=\"2019.12.10-3.2.2.1\"><span class=\"toc-item-num\">3.2.2.1&nbsp;&nbsp;</span>2019.12.10</a></span></li><li><span><a href=\"#2019.12.13\" data-toc-modified-id=\"2019.12.13-3.2.2.2\"><span class=\"toc-item-num\">3.2.2.2&nbsp;&nbsp;</span>2019.12.13</a></span></li><li><span><a href=\"#2019.12.19\" data-toc-modified-id=\"2019.12.19-3.2.2.3\"><span class=\"toc-item-num\">3.2.2.3&nbsp;&nbsp;</span>2019.12.19</a></span></li><li><span><a href=\"#2019.12.20\" data-toc-modified-id=\"2019.12.20-3.2.2.4\"><span class=\"toc-item-num\">3.2.2.4&nbsp;&nbsp;</span>2019.12.20</a></span></li><li><span><a href=\"#2020.01.06\" data-toc-modified-id=\"2020.01.06-3.2.2.5\"><span class=\"toc-item-num\">3.2.2.5&nbsp;&nbsp;</span>2020.01.06</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Step-3---render-context-networks\" data-toc-modified-id=\"Step-3---render-context-networks-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Step 3 - render context networks</a></span><ul class=\"toc-item\"><li><span><a href=\"#Step-3---TODO\" data-toc-modified-id=\"Step-3---TODO-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Step 3 - TODO</a></span><ul class=\"toc-item\"><li><span><a href=\"#Step-3---TODO---general\" data-toc-modified-id=\"Step-3---TODO---general-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Step 3 - TODO - general</a></span></li><li><span><a href=\"#Step-3---TODO---Network-data-creation---framework\" data-toc-modified-id=\"Step-3---TODO---Network-data-creation---framework-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Step 3 - TODO - Network data creation - framework</a></span></li><li><span><a href=\"#Step-3---TODO---Network-data-creation---performance\" data-toc-modified-id=\"Step-3---TODO---Network-data-creation---performance-4.1.3\"><span class=\"toc-item-num\">4.1.3&nbsp;&nbsp;</span>Step 3 - TODO - Network data creation - performance</a></span></li><li><span><a href=\"#Step-3---TODO---Network-data-creation---testing\" data-toc-modified-id=\"Step-3---TODO---Network-data-creation---testing-4.1.4\"><span class=\"toc-item-num\">4.1.4&nbsp;&nbsp;</span>Step 3 - TODO - Network data creation - testing</a></span></li></ul></li><li><span><a href=\"#Step-3---DONE\" data-toc-modified-id=\"Step-3---DONE-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Step 3 - DONE</a></span><ul class=\"toc-item\"><li><span><a href=\"#Step-3---DONE---general\" data-toc-modified-id=\"Step-3---DONE---general-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Step 3 - DONE - general</a></span></li><li><span><a href=\"#Step-3---DONE---Network-data-creation---framework\" data-toc-modified-id=\"Step-3---DONE---Network-data-creation---framework-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Step 3 - DONE - Network data creation - framework</a></span><ul class=\"toc-item\"><li><span><a href=\"#2020.01.06\" data-toc-modified-id=\"2020.01.06-4.2.2.1\"><span class=\"toc-item-num\">4.2.2.1&nbsp;&nbsp;</span>2020.01.06</a></span></li><li><span><a href=\"#2020.01.08\" data-toc-modified-id=\"2020.01.08-4.2.2.2\"><span class=\"toc-item-num\">4.2.2.2&nbsp;&nbsp;</span>2020.01.08</a></span></li><li><span><a href=\"#2020.01.23\" data-toc-modified-id=\"2020.01.23-4.2.2.3\"><span class=\"toc-item-num\">4.2.2.3&nbsp;&nbsp;</span>2020.01.23</a></span></li></ul></li><li><span><a href=\"#Step-3---DONE---Network-data-creation---testing\" data-toc-modified-id=\"Step-3---DONE---Network-data-creation---testing-4.2.3\"><span class=\"toc-item-num\">4.2.3&nbsp;&nbsp;</span>Step 3 - DONE - Network data creation - testing</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "TODO:\n",
    "\n",
    "- // Step 1 - sourcenet-to-context:\n",
    "\n",
    "    - specify what we need to do to get network data loaded into context store.\n",
    "    - write program to load data into context store ( [sourcenet-to-context.ipynb](sourcenet-to-context.ipynb) ).\n",
    "    - take the code in this notebook and move it to context_text, and then make a class out of it so it is easier to re-use.\n",
    "    - load all current data into context.\n",
    "    - go back and make better rules to pull all local hard news (misspelled reporter affiliation strings, etc).\n",
    "    \n",
    "- Step 2 - filter network relations\n",
    "- Step 3 - render context networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - sourcenet-to-context\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Related notebooks:\n",
    "\n",
    "- [step-1-sourcenet-to-context.ipynb](step-1-sourcenet-to-context.ipynb) - actual code to export articles and their data from sourcenet (`context_text`) into context.\n",
    "- [step-1-sourcenet-to-context-dev.ipynb](step-1-sourcenet-to-context-dev.ipynb) - includes code to export articles to context, plus testing code and was the original source of the following TODO items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - TODO\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-contents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - TODO - General\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-contents)\n",
    "\n",
    "**general TODO:**\n",
    "\n",
    "- methods to find relations, similar to `filter_entities()` and `lookup_entities()` in `Entity` model class.  Include:\n",
    "\n",
    "    - // Entity_Relation_Type by either slug or instance\n",
    "    - // from = \n",
    "    - from_in\n",
    "    - from_type_in\n",
    "    - from_identifiers_in\n",
    "    - from_entity_traits\n",
    "\n",
    "        - AND dictionary\n",
    "        - OR dictionary\n",
    "        - fancy\n",
    "    \n",
    "    - // to = \n",
    "    - to_in\n",
    "    - to_type_in\n",
    "    - to_identifiers_in\n",
    "    - to_entity_traits\n",
    "\n",
    "        - AND dictionary\n",
    "        - OR dictionary\n",
    "        - fancy\n",
    "    \n",
    "    - // through =\n",
    "    - through_in\n",
    "    - through_identifiers_in\n",
    "    - through_entity_traits\n",
    "\n",
    "        - AND dictionary\n",
    "        - OR dictionary\n",
    "        - fancy\n",
    "    \n",
    "    - either FROM or TO (so undirected search - \"I don't care which side\")\n",
    "    \n",
    "        - IDs\n",
    "        - identifiers\n",
    "        - traits\n",
    "    \n",
    "    - any of FROM, TO, THROUGH\n",
    "    \n",
    "        - IDs\n",
    "        - identifiers\n",
    "        - traits\n",
    "    \n",
    "    - relation_traits\n",
    "    \n",
    "        - // AND dictionary\n",
    "        - OR dictionary\n",
    "        - fancy\n",
    "    \n",
    "    - _NOTE_ for trait matching types (and probably entity identifiers, also):\n",
    "\n",
    "        - \"AND dictionary\" - to start, accept a dictionary of trait names and values that all must match (AND match).\n",
    "        - \"OR dictionary\" - could add an \"OR\" trait match dictionary as well.\n",
    "        - \"fancy\" - Eventually, could add ability to spec trait name (or unsaved model instance?), then specify test for value (equals, contains, etc.) and test value.  This would likely be a new little object.\n",
    "        \n",
    "    - Tags on Entity and/or Entity_Relation.\n",
    "\n",
    "- make small dummy person and organization classes in context, so I can use them to test Abstract_Entity_Container without needing context_text.\n",
    "- come up with better way to seed entities and relations for sourcenet - store spec in context_text base, then method to create or update all.\n",
    "\n",
    "    - store the JSON from the context fixture in Context_Text_Base?  Or in a sourcenet class somewhere?\n",
    "    - make a class in context/shared that contains variables and methods to loops over the items in context fixture JSON and update the database based on what is inside.  For each item in the fixture JSON, looks each up based on unique idnetifying information (name, slug, label, etc.). If it finds it, moves on.  If not, creates it.  \n",
    "    - This will need to build up a basic object mapping based on foriegn keys before it creates anything, then create things in the right order (Entity_Types and related first, then Entity_Identifier_Types, then Relation_Types).  Order:\n",
    "    \n",
    "        - context.Trait_Type \\\n",
    "        - context.Entity_Type \\\n",
    "        - context.Entity_Type_Trait \\\n",
    "        - context.Entity_Identifier_Type\n",
    "        - context.Entity_Relation_Type \\\n",
    "        - context.Entity_Relation_Type_Trait \\\n",
    "        - context.Term_Relation_Type \\\n",
    "        - context.Vocabulary \\\n",
    "        - context.Term \\\n",
    "        - context.Term_Relation \\\n",
    "        \n",
    "    - for each type:\n",
    "    \n",
    "        - make a map of id to fields for each item of that type.\n",
    "        - make a method for creating an instance of that type from fields.\n",
    "        - to associate related, retrieve instance from in-memory map based on ID, then if db_id present, use it to look up, else look up in database based on name.  If not found, error, but could create.\n",
    "\n",
    "    - To actually load, go in order of types outlined above, creating as you go.\n",
    "    - When one of the items is added to the database, add a db_id field to their \"fields\".\n",
    "    \n",
    "- abstraction:\n",
    "\n",
    "    - make an abstract parent for a type that has associated trait specs (parent to `Entity_Type` and `Entity_Relation_Type`).\n",
    "    \n",
    "        - share method `get_trait_spec()`.\n",
    "    \n",
    "    - make an abstract parent for trait containers that have associated types with associated trait specs (parent to `Entity` and `Entity_Relation`).\n",
    "    \n",
    "        - share method `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - TODO - sourcenet-to-context\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 - TODO - Relation Creation\n",
    "\n",
    "- FUTURE - abstract out the tests for an EntityContainer into their own parent test class that AbstractEntityContainers can use to re-use testing methods.  Will need a way to abstract out traits, identifiers, etc.  Not for now.\n",
    "- ? - make an \"Abstract_Relation_Container\" abstract method for code related to an instance of a given model resulting in a relation (Article_Data)?\n",
    "\n",
    "    - Might need ManyToMany back links, will have to see how we do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - DONE\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - DONE - General\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "**general TODO DONE:**\n",
    "\n",
    "- // take the \"`create_article_entity()`\" function and put it in a class for loading sourcenet articles into  context\n",
    "\n",
    "    - `context_text/export/to_context_base/export_to_context.py` - class `ExportToContext`\n",
    "\n",
    "- // build unit test class for this loading class, and add one for creating a fake article, then making an entity out of it. Check entity, traits, and identifiers.\n",
    "- // Add Entity ID foreign key to Article, Person, Newspaper, Organization models.  Perhaps add it to a shared parent class? - context/shared/entity_models.py --> class Abstract_Entity_Container\n",
    "- add a unique_identifier_type column to Article model.  To set for NewsBank:\n",
    "\n",
    "        --SELECT COUNT( * ) FROM context_text_article;\n",
    "        --SELECT COUNT( * ) FROM context_text_article WHERE archive_source = 'NewsBank';\n",
    "        --SELECT * FROM context_text_article WHERE archive_source != 'NewsBank';\n",
    "        --UPDATE context_text_article SET unique_identifier_type = 'article_newsbank_id' WHERE archive_source = 'NewsBank';\n",
    "        --SELECT COUNT( * ) FROM context_text_article WHERE unique_identifier_type = 'permalink';\n",
    "        --SELECT COUNT( * ) FROM context_text_article WHERE unique_identifier_type = 'article_newsbank_id';\n",
    "\n",
    "    - need to update the code that loaded the NewsBank Articles so it sets this value.\n",
    "    - also, need to make \"Article\" unit tests for entity creation, rather than just having it in the export unit tests?\n",
    "\n",
    "- 2019.11.07 - // method to find entity - based on type and identifier (accept all the fields that make sense, including optional identifier type instance).\n",
    "\n",
    "    - // lookup_entities() - implemented, still need to write unit test.\n",
    "    - // implement unit test test_lookup_entities() in test_entity_model, pattern off of the Entity_Identifier unit test test_filter_identifiers().\n",
    "    - // update unit test test_get_entity_for_identifier() in test_entity_model to use all possible arguments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - DONE - sourcenet-to-context\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 - DONE - Entity Creation\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Entity Creation TODO - DONE:\n",
    "\n",
    "- // Build and test basic article entity creation\n",
    "\n",
    "    - // includes building out entity helper methods and testing context entity code.\n",
    "    - // include adding reverse reference to Article's Entity to Article model.\n",
    "    - // include creating Newspaper entity for related newspaper?\n",
    "\n",
    "- // Build and test basic newspaper entity creation\n",
    "\n",
    "    - // ID type \"newspaper_sourcenet_id\" - add to both test and normal\n",
    "    - // ID type \"newspaper_newsbank_code\" - add to both test and normal\n",
    "    - // export new metadata fixture\n",
    "    - // integrate into article creation.\n",
    "\n",
    "- // Build and test basic person entity creation\n",
    "\n",
    "    - include adding reverse reference to Person's Entity to Person model.\n",
    "\n",
    "- // Build and test basic organization entity creation\n",
    "\n",
    "    - include adding reverse reference to Organization's Entity to Organization model.\n",
    "    - update newspaper entity creation to also create organization entity if newspaper.organization.has_entity() is False.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 - DONE - Relation Creation\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Relation Creation (start in `export_to_context.py`) TODO - DONE (All added 2019.11.25 unless noted otherwise):\n",
    "\n",
    "- // review the trait code and tests for entity (get, set, etc.), modify it and add it to relation, as well.  It will work exactly the same (see if we can abstract somehow).\n",
    "- // make methods `filter_relations` and `lookup_relations` with subset of above to serve Entity_Relation creation.\n",
    "- create unit test class for `Entity_Relation` based on Entity that tests:\n",
    "\n",
    "    - // trait methods\n",
    "    - instance methods:\n",
    "\n",
    "        - // `set_basic_traits_from_dict()`\n",
    "\n",
    "    - class methods:\n",
    "\n",
    "         - // `Entity_Relation.create_entity_relation()`\n",
    "\n",
    "             - test 1 - make one with type of \"quoted\", set FROM, TO, THROUGH and traits.\n",
    "             - test 2 - make one with same info, different traits, make sure it doesn't make a duplicate relation, and that trait values are updated.\n",
    "             - try other permutations?  No type, no through, no traits...\n",
    "\n",
    "         - // `filter_relations()`\n",
    "         - // `lookup_relations()`\n",
    "\n",
    "- Entity_Type and Entity_Relation_Type tests:\n",
    "\n",
    "    - method `get_type_for_slug()`\n",
    "\n",
    "- // work through entity creation first in `export_to_context.py`:\n",
    "\n",
    "    - // `create_entities()`\n",
    "    - // `create_newspaper_entities()`\n",
    "    - // `create_article_entities()`\n",
    "    - // add coder ID, coder username, and coder type to all relations based on the Article_Data from which they are derived.\n",
    "    - // create methods for getting lists of author, subject (including sources flag), and create test cases.\n",
    "    - // create method to generate relaton trait dictionary from article and article_Data passed in.\n",
    "    - // test cases for each of these in `test_export_to_context`.\n",
    "\n",
    "        - // `create_entity_container_entity()`\n",
    "        - // `create_article_entity()`\n",
    "        - // `create_person_entity()`\n",
    "        - // `@classmethod make_author_entity_list()`\n",
    "        - // `@classmethod make_relation_trait_dict()`\n",
    "        - // `@classmethod make_subject_entity_list()` (including only sources, and don't include sources in subjects).\n",
    "        - // `create_newspaper_relations()`\n",
    "        - // `create_article_relations()`\n",
    "        - // `create_relations()`\n",
    "        - // `process_articles()`\n",
    "\n",
    "    - // hook these in to `process_articles()`\n",
    "\n",
    "- // add traits to some of the relations created in `TestHelper.create_test_relations`.\n",
    "- // need to test what happens when you call the `update_entity()` method on each entity a second time.  Should not result in two separate entities.\n",
    "- 2019.12.04 - // add to unit test for `process_articles()` tests to make sure that tags are getting added to each article as they are processed.\n",
    "- 2019.12.04 - // create data from automated coding (just articles with coding by OpenCalais V.2) in actual database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - filter network relations\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Related Notebooks:\n",
    "\n",
    "- [step-2-filter-network-relations-dev.ipynb](step-2-filter-network-relations-dev.ipynb) - all work on filtering network relations to get to susbset to be included in network output is here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - TODO\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - TODO - general\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "**general TODO:**\n",
    "\n",
    "- methods to find relations, similar to `filter_entities()` and `lookup_entities()` in `Entity` model class.  Include:\n",
    "\n",
    "    - // Entity_Relation_Type by either slug or instance\n",
    "    - // from = \n",
    "    - from_in\n",
    "    - from_type_in\n",
    "    - from_identifiers_in\n",
    "    - from_entity_traits\n",
    "\n",
    "        - AND dictionary\n",
    "        - OR dictionary\n",
    "        - fancy\n",
    "    \n",
    "    - // to = \n",
    "    - to_in\n",
    "    - to_type_in\n",
    "    - to_identifiers_in\n",
    "    - to_entity_traits\n",
    "\n",
    "        - AND dictionary\n",
    "        - OR dictionary\n",
    "        - fancy\n",
    "    \n",
    "    - // through =\n",
    "    - through_in\n",
    "    - through_identifiers_in\n",
    "    - through_entity_traits\n",
    "\n",
    "        - AND dictionary\n",
    "        - OR dictionary\n",
    "        - fancy\n",
    "    \n",
    "    - either FROM or TO (so undirected search - \"I don't care which side\")\n",
    "    \n",
    "        - IDs\n",
    "        - identifiers\n",
    "        - traits\n",
    "    \n",
    "    - any of FROM, TO, THROUGH\n",
    "    \n",
    "        - IDs\n",
    "        - identifiers\n",
    "        - traits\n",
    "    \n",
    "    - relation_traits\n",
    "    \n",
    "        - // AND dictionary\n",
    "        - OR dictionary\n",
    "        - fancy\n",
    "    \n",
    "    - _NOTE_ for trait matching types (and probably entity identifiers, also):\n",
    "\n",
    "        - \"AND dictionary\" - to start, accept a dictionary of trait names and values that all must match (AND match).\n",
    "        - \"OR dictionary\" - could add an \"OR\" trait match dictionary as well.\n",
    "        - \"fancy\" - Eventually, could add ability to spec trait name (or unsaved model instance?), then specify test for value (equals, contains, etc.) and test value.  This would likely be a new little object.\n",
    "        \n",
    "    - Tags on Entity and/or Entity_Relation.\n",
    "\n",
    "- make small dummy person and organization classes in context, so I can use them to test Abstract_Entity_Container without needing context_text.\n",
    "- come up with better way to seed entities and relations for sourcenet - store spec in context_text base, then method to create or update all.\n",
    "\n",
    "    - store the JSON from the context fixture in Context_Text_Base?  Or in a sourcenet class somewhere?\n",
    "    - make a class in context/shared that contains variables and methods to loops over the items in context fixture JSON and update the database based on what is inside.  For each item in the fixture JSON, looks each up based on unique idnetifying information (name, slug, label, etc.). If it finds it, moves on.  If not, creates it.  \n",
    "    - This will need to build up a basic object mapping based on foriegn keys before it creates anything, then create things in the right order (Entity_Types and related first, then Entity_Identifier_Types, then Relation_Types).  Order:\n",
    "    \n",
    "        - context.Trait_Type \\\n",
    "        - context.Entity_Type \\\n",
    "        - context.Entity_Type_Trait \\\n",
    "        - context.Entity_Identifier_Type\n",
    "        - context.Entity_Relation_Type \\\n",
    "        - context.Entity_Relation_Type_Trait \\\n",
    "        - context.Term_Relation_Type \\\n",
    "        - context.Vocabulary \\\n",
    "        - context.Term \\\n",
    "        - context.Term_Relation \\\n",
    "        \n",
    "    - for each type:\n",
    "    \n",
    "        - make a map of id to fields for each item of that type.\n",
    "        - make a method for creating an instance of that type from fields.\n",
    "        - to associate related, retrieve instance from in-memory map based on ID, then if db_id present, use it to look up, else look up in database based on name.  If not found, error, but could create.\n",
    "\n",
    "    - To actually load, go in order of types outlined above, creating as you go.\n",
    "    - When one of the items is added to the database, add a db_id field to their \"fields\".\n",
    "    \n",
    "- abstraction:\n",
    "\n",
    "    - make an abstract parent for a type that has associated trait specs (parent to `Entity_Type` and `Entity_Relation_Type`).\n",
    "    \n",
    "        - share method `get_trait_spec()`.\n",
    "    \n",
    "    - make an abstract parent for trait containers that have associated types with associated trait specs (parent to `Entity` and `Entity_Relation`).\n",
    "    \n",
    "        - share method `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - TODO - Network data filtering\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Network data filtering TODO:\n",
    "\n",
    "- design JSON based on https://research.local/research/context/text/output/network: generalized, but not perfectly so.  Remaining tasks (can be deferred for now):\n",
    "\n",
    "    - filter, same for entities and relations:\n",
    "\n",
    "        - topics (terms, in the context) - terms to include, terms to exclude.\n",
    "\n",
    "    - specify the output:\n",
    "\n",
    "        - if file:\n",
    "\n",
    "            - mime type?  Set in child class based on the format the class implements, for now.\n",
    "            - file extension?  Set in child class based on the format the class implements, for now.\n",
    "\n",
    "- build logic to use contents of JSON to filter QuerySets of Entities and Relations, then will need to make lots more tests.\n",
    "\n",
    "    - testing:\n",
    "    \n",
    "        - FilterSpec\n",
    "        \n",
    "            - ?\n",
    "            - output_as_json_string()?\n",
    "        \n",
    "        - NetworkDataRequest - start with low-level filter-type-specific methods and work your way up.\n",
    "        \n",
    "            - \"`compact_entity_relation_queryset()`\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - DONE\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - DONE - general\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Nothing to report thus far. See Step 3, where this was all worked on more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - DONE - Network data filtering\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Network data filtering TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2019.12.10\n",
    "\n",
    "- in test data base, make fixture of entities, relations, traits, etc., post-data load, for testing.  No need to include any Article_Data or anything, but need to specify exactly which tables are needed, and export all needed tables to a fixture.\n",
    "- // create test JSON file that matches the criteria for methods paper month.\n",
    "- // build out class to parse and hold the above JSON.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2019.12.13\n",
    "\n",
    "- 2019.12.13 - design JSON based on https://research.local/research/context/text/output/network: generalized, but not perfectly so:\n",
    "\n",
    "    - filter, same for entities and relations:\n",
    "\n",
    "        - // list of entity type slugs to include\n",
    "        - // list of entity type slugs to exclude\n",
    "        - // list of relation type slugs to include\n",
    "        - // list of relation type slugs to exclude\n",
    "        - // trait-based filters (allow for \n",
    "\n",
    "            - // in general - per trait:\n",
    "\n",
    "                - trait name\n",
    "                - optional trait type (ID, or slug)\n",
    "                - data type (int, string, datetime - so you can cast in query for ranges - datetimes, for example)\n",
    "                - type of comparison (equals, includes, excludes, list of ranges of include - from, to)\n",
    "                - trait values (set appropriate depending on type of comparison):\n",
    "\n",
    "                    - trait_value\n",
    "                    - trait_value_from\n",
    "                    - trait_value_to\n",
    "                    - trait_value_list\n",
    "                    \n",
    "            - // pub_date ranges - list of one or more pairs of pub-date start and end date ranges.\n",
    "            - // newspaper IDs - include and exclude lists.\n",
    "            - // coders to include or exclude.\n",
    "            - // coder_types to include or exclude.\n",
    "            \n",
    "                - Do we include the \"only check type for automated user\" thing?  Can use AND and OR to do this.\n",
    "\n",
    "        - // identifier-based filters...\n",
    "\n",
    "    - specify the output:\n",
    "\n",
    "        - // download as file?\n",
    "        - if file:\n",
    "\n",
    "            - // file path\n",
    "            - mime type? - for now, let the output code choose.\n",
    "            - file extension? - for now, let the output code choose.\n",
    "\n",
    "        - // data format - choose from:\n",
    "\n",
    "            - simple matrix\n",
    "            - CSV matrix\n",
    "            - tab-delimited matrix\n",
    "            - edge list?\n",
    "\n",
    "        - // output types:\n",
    "\n",
    "            - just network\n",
    "            - just attributes (one row per node, column per attribute).\n",
    "            - network with attributes as columns, so values stored per row.\n",
    "            - network with attributes as rows, so values stored per column.\n",
    "\n",
    "        - // include headers?\n",
    "        - ? - Network label...?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2019.12.19\n",
    "\n",
    "- 2019.12.19 - add \"`filter_type`\" as a property in filter criteria, make \"AND\" and \"OR\" filter types, and then just have a filter specification, don't have the 5 separate lists.\n",
    "- build logic to use contents of JSON to filter QuerySets of Entities and Relations, then will need to make lots more tests.\n",
    "\n",
    "    - testing:\n",
    "    \n",
    "        - // FilterSpec\n",
    "        \n",
    "            - child q and child filter spec\n",
    "        \n",
    "        - NetworkDataRequest - start with low-level filter-type-specific methods and work your way up.\n",
    "        \n",
    "            - low-level methods for actually filtering on each type of filter, based on a single filter spec:\n",
    "                \n",
    "                - // build_filter_spec_entity_id_q\n",
    "                - // build_filter_spec_entity_trait_q\n",
    "                - // build_filter_spec_entity_type_slug_q\n",
    "                - // build_filter_spec_relation_trait_q\n",
    "                - // build_filter_spec_relation_type_slug_q\n",
    "                - // build_filter_spec_entity_q_target_roles - take test code for entity identifiers or entity traits and turn it directly into test - make entity QS, then pass it to the method, count the output, and check if correct, for all permutations of combinations of FROM, TO, and THROUGH."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2019.12.20\n",
    "\n",
    "- 2019.12.20 - methods for tying the different filter specs and filter types together:\n",
    "                \n",
    "    - // build_filter_spec_aggregate_q (just handles comparison types AND and OR)\n",
    "                \n",
    "        - handles AND and OR by looping over the FilterSpecs in a list, calling build_filter_spec_q on each, and then AND-ing or OR-ing the results together into a combined Q.\n",
    "        - // build_filter_spec_q\n",
    "                \n",
    "            - // calls build_filter_spec_aggregate_q() for comparison types AND and OR\n",
    "            - // calls the filter-type-specific method for EQUALS, INCLUDES, EXCLUDES, RANGE - single method per filter type, each of the types are handled inside."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2020.01.06\n",
    "\n",
    "- design JSON based on https://research.local/research/context/text/output/network: generalized, but not perfectly so.  Remaining tasks (can be deferred for now):\n",
    "\n",
    "    - specify the output:\n",
    "\n",
    "        - // Network label - was just a header line - omit it.\n",
    "\n",
    "- build logic to use contents of JSON to filter QuerySets of Entities and Relations, then will need to make lots more tests.\n",
    "\n",
    "    - testing:\n",
    "    \n",
    "        - NetworkDataRequest - start with low-level filter-type-specific methods and work your way up.\n",
    "        \n",
    "            - // methods for coordinating the overall filter plan stored in the request.\n",
    "                \n",
    "                - // filter_relation_query_set()\n",
    "                \n",
    "                    - // get_selection_filters()\n",
    "                    - // filter_relations()\n",
    "                    \n",
    "                        - calls // build_filter_spec_q()\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - render context networks\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Related notebooks:\n",
    "\n",
    "- [step-3-render-context-networks-dev.ipynb](step-3-render-context-networks-dev.ipynb) - network output implementation in context, then comparison to previous sourcenet method. Includes unit test and testing code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - TODO\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - TODO - general\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "**general TODO:**\n",
    "\n",
    "- _based on Step 2 general TODO._\n",
    "- methods to find relations, similar to `filter_entities()` and `lookup_entities()` in `Entity` model class.  Include:\n",
    "\n",
    "    - // Entity_Relation_Type by either slug or instance\n",
    "    - // from = \n",
    "    - from_in\n",
    "    - from_type_in\n",
    "    - from_identifiers_in\n",
    "    - from_entity_traits\n",
    "\n",
    "        - AND dictionary\n",
    "        - OR dictionary\n",
    "        - fancy\n",
    "    \n",
    "    - // to = \n",
    "    - to_in\n",
    "    - to_type_in\n",
    "    - to_identifiers_in\n",
    "    - to_entity_traits\n",
    "\n",
    "        - AND dictionary\n",
    "        - OR dictionary\n",
    "        - fancy\n",
    "    \n",
    "    - // through =\n",
    "    - through_in\n",
    "    - through_identifiers_in\n",
    "    - through_entity_traits\n",
    "\n",
    "        - AND dictionary\n",
    "        - OR dictionary\n",
    "        - fancy\n",
    "    \n",
    "    - either FROM or TO (so undirected search - \"I don't care which side\")\n",
    "    \n",
    "        - IDs\n",
    "        - identifiers\n",
    "        - traits\n",
    "    \n",
    "    - any of FROM, TO, THROUGH\n",
    "    \n",
    "        - IDs\n",
    "        - identifiers\n",
    "        - traits\n",
    "    \n",
    "    - relation_traits\n",
    "    \n",
    "        - // AND dictionary\n",
    "        - OR dictionary\n",
    "        - fancy\n",
    "    \n",
    "    - _NOTE_ for trait matching types (and probably entity identifiers, also):\n",
    "\n",
    "        - \"AND dictionary\" - to start, accept a dictionary of trait names and values that all must match (AND match).\n",
    "        - \"OR dictionary\" - could add an \"OR\" trait match dictionary as well.\n",
    "        - \"fancy\" - Eventually, could add ability to spec trait name (or unsaved model instance?), then specify test for value (equals, contains, etc.) and test value.  This would likely be a new little object.\n",
    "        \n",
    "    - Tags on Entity and/or Entity_Relation.\n",
    "\n",
    "- make small dummy person and organization classes in context, so I can use them to test Abstract_Entity_Container without needing context_text.\n",
    "- come up with better way to seed entities and relations for sourcenet - store spec in context_text base, then method to create or update all.\n",
    "\n",
    "    - store the JSON from the context fixture in Context_Text_Base?  Or in a sourcenet class somewhere?\n",
    "    - make a class in context/shared that contains variables and methods to loops over the items in context fixture JSON and update the database based on what is inside.  For each item in the fixture JSON, looks each up based on unique idnetifying information (name, slug, label, etc.). If it finds it, moves on.  If not, creates it.  \n",
    "    - This will need to build up a basic object mapping based on foriegn keys before it creates anything, then create things in the right order (Entity_Types and related first, then Entity_Identifier_Types, then Relation_Types).  Order:\n",
    "    \n",
    "        - context.Trait_Type \\\n",
    "        - context.Entity_Type \\\n",
    "        - context.Entity_Type_Trait \\\n",
    "        - context.Entity_Identifier_Type\n",
    "        - context.Entity_Relation_Type \\\n",
    "        - context.Entity_Relation_Type_Trait \\\n",
    "        - context.Term_Relation_Type \\\n",
    "        - context.Vocabulary \\\n",
    "        - context.Term \\\n",
    "        - context.Term_Relation \\\n",
    "        \n",
    "    - for each type:\n",
    "    \n",
    "        - make a map of id to fields for each item of that type.\n",
    "        - make a method for creating an instance of that type from fields.\n",
    "        - to associate related, retrieve instance from in-memory map based on ID, then if db_id present, use it to look up, else look up in database based on name.  If not found, error, but could create.\n",
    "\n",
    "    - To actually load, go in order of types outlined above, creating as you go.\n",
    "    - When one of the items is added to the database, add a db_id field to their \"fields\".\n",
    "    \n",
    "- abstraction:\n",
    "\n",
    "    - make an abstract parent for a type that has associated trait specs (parent to `Entity_Type` and `Entity_Relation_Type`).\n",
    "    \n",
    "        - share method `get_trait_spec()`.\n",
    "    \n",
    "    - make an abstract parent for trait containers that have associated types with associated trait specs (parent to `Entity` and `Entity_Relation`).\n",
    "    \n",
    "        - share method `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - TODO - Network data creation - framework\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Framework todos:\n",
    "\n",
    "- add in a little more detailed updates on rendering network data (every X relations, output timestamp).\n",
    "- build basic framework where each output type accepts these two QuerySets, renders and returns desired output format.\n",
    "\n",
    "    - have child NDO classes implement \"`initialize_from_request`\" if needed, call parent, then init format-specific stuff.\n",
    "    - update to use StatusContainer instead of status strings.\n",
    "\n",
    "- add type checking to setters of dictionaries and lists, to make sure either None or correct type passed in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - TODO - Network data creation - performance\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Performance todos:\n",
    "\n",
    "- look at queries being run to generate network data, look for columns in context that are not indexed, to speed network output. Should be able to speed things considerably.\n",
    "- perhaps look into adding and removing indexes depending on state of application - remove indexes when loading data, add them when rendering networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - TODO - Network data creation - testing\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Testing todos:\n",
    "\n",
    "- // first, get it running, then unit tests.\n",
    "- // make plan for unit testing for all export instances, fill in outline below.\n",
    "- find a way to put method `validate_string_against_file_contents()` into python_utilities - new unittest_helper class, and call the stock unittest asserts instead of those on the instance?\n",
    "\n",
    "    - make a parent class that extends the base unittest class? (`unittest.TestCase`)\n",
    "    - // make a parent class that extends Django's unit test class (`django.test.TestCase`).\n",
    "\n",
    "- unit testing:\n",
    "\n",
    "    - NetworkDataRequest\n",
    "    \n",
    "        - // `do_output_entity_traits_or_ids`\n",
    "        - // class method `create_entity_id_header_label`\n",
    "        - // class method `create_entity_trait_header_label`\n",
    "        - // `create_entity_ids_and_traits_header_list`\n",
    "        - // `get/set_entity_ids_and_traits_header_list`\n",
    "        - // `get/set_entity_id_to_instance_map`\n",
    "        - // `get/set_entity_id_to_traits_map`\n",
    "        - // `process_entities` - add to test to include entity traits and IDs\n",
    "\n",
    "            - // make sure structure and count are right\n",
    "            - add test for entity ID list?\n",
    "            - // spot-check a few individuals for values\n",
    "            \n",
    "                - 8 - 161; None; Nardy; Baeza; Bickel\n",
    "                - 27 - 877; http://d.opencalais.com/pershash-1/15e6a7c0-40fa-3235-bbec-f46f2d362782; Kaidon; None; None\n",
    "                - 57 - 933; http://d.opencalais.com/pershash-1/5de8e1c8-9f6b-32de-b77b-29dab0a9c3c2; Douglas; Vander; Hart\n",
    "                - 66 - 274; http://d.opencalais.com/pershash-1/18bc2abb-9540-300a-b6e1-2f75366848bd; Stacie; None; Behler\n",
    "                - 85 - 84; None; John; None; Tunison\n",
    "            \n",
    "            - build tests for the following:\n",
    "\n",
    "                - // `load_entities_ids_and_traits`\n",
    "                - // `load_entity_identifiers`\n",
    "                - // `load_entity_traits`\n",
    "\n",
    "        - **NOTE: Add `process_entities` as precondition for the following:**    \n",
    "        - // `create_ids_and_traits_values_for_entity`\n",
    "\n",
    "            - // `get_ids_and_traits_for_entity`\n",
    "\n",
    "        - // `get/set_entity_id_list`\n",
    "        - // `generate_entity_id_list`\n",
    "        - `create_entity_ids_and_traits_value_dict( entity_id_list_IN )`\n",
    "\n",
    "            - loop over labels, calling the validate method for `create_entity_ids_and_traits_value_list` for each.\n",
    "            - `create_entity_ids_and_traits_value_list( self, header_label_IN, entity_id_list_IN = None ):` - make a \"validate\" method that accepts...? and:\n",
    "            \n",
    "                - check default list\n",
    "                - check a smaller list\n",
    "                - check a smaller list that includes entities who were not loaded\n",
    "            \n",
    "        - `load_ids_and_traits_for_entities( self, entity_id_list_IN, dictionary_IN )`\n",
    "        - `process_entities_from_id_list`\n",
    "\n",
    "    - NetworkDataOutput\n",
    "    \n",
    "        - dependencies for child classes:\n",
    "\n",
    "            - `create_header_list()`\n",
    "            - `create_label_list()`\n",
    "            - `create_relation_type_roles_for_entity()`\n",
    "            - `create_relation_type_roles_header_list()`\n",
    "            - `do_output_attribute_columns()`\n",
    "            - `do_output_attribute_rows()`\n",
    "            - `do_output_network()`\n",
    "            - `get_entity_label()`\n",
    "            - `get_relation_roles_for_entity()`\n",
    "            - `get_relations_for_entity()`\n",
    "\n",
    "        - notes\n",
    "\n",
    "            - `register_relation_type()`, and the places that call it: `render()`, optionally also `update_entity_relation_details()`\n",
    "\n",
    "    - NDO children\n",
    "\n",
    "        - NDO_SimpleMatrix\n",
    "\n",
    "            - `render_network_data()` - at a high level, render the basic, compare to a pre-rendered file.\n",
    "\n",
    "                - `create_label_string()`\n",
    "\n",
    "            - `create_network_string()` - the worker method, effectively, testing `render_network_data()` tests this.\n",
    "\n",
    "                - `create_entity_row_string()` - per row method.\n",
    "\n",
    "            - `create_entity_relation_types_attribute_string()`\n",
    "\n",
    "        - NDO_CSVMatrix\n",
    "\n",
    "            - `append_entity_ids_and_traits_rows`\n",
    "            - `render_network_data()` - at a high level, render the basic, compare to a pre-rendered file.\n",
    "\n",
    "                - `create_csv_string()`\n",
    "\n",
    "                    - `init_csv_output()`\n",
    "                    - `create_csv_document()`\n",
    "\n",
    "                        - `create_header_list()`\n",
    "                        - `append_row_to_csv()`\n",
    "                        - `append_entity_row()`\n",
    "\n",
    "                            - `create_relation_type_roles_for_entity()`\n",
    "                            - (duplicate) `append_row_to_csv()`\n",
    "\n",
    "                        - `append_entity_id_row()`\n",
    "\n",
    "                            - (duplicate) `append_row_to_csv()`\n",
    "\n",
    "                        - `append_entity_relation_type_rows()`\n",
    "\n",
    "                            - (duplicate) `append_row_to_csv()`\n",
    "\n",
    "                    - `cleanup()`\n",
    "\n",
    "        - NDO_TabDelimitedMatrix\n",
    "\n",
    "            - nothing but an init - maybe just run the basic config through, make sure it comes out as we expect.\n",
    "\n",
    "- // look at relation filtering/tie creation/rendering - Entity 10 (person 872) has two ties in test output for \"basic\" (to entities 8 and 9), should only have 1.  Article (21409) had two authors, so single article resulted in two ties to the subject, one from each author.\n",
    "- test by comparing to output from the original tool, including derived statistics.\n",
    "\n",
    "    - Jupyter notebooks:\n",
    "    \n",
    "        - overview of network data creation and analysis: [phd_work/methods/methods_paper_planning.ipynb#Network-Analysis](../methods/methods_paper_planning.ipynb#Network-Analysis)\n",
    "        \n",
    "            - old version of this information: [phd_work/methods/network_analysis/methods-network_analysis-create_network_data.ipynb](../methods/network_analysis/methods-network_analysis-create_network_data.ipynb)\n",
    "        \n",
    "        - R code for analysis comparing human and automated networks from original output: [phd_work/methods/network_analysis/statnet/R-statnet-grp_month-full_month.ipynb](../methods/network_analysis/statnet/R-statnet-grp_month-full_month.ipynb)\n",
    "        - R notebook for new analysis: [phd_work/methods/network_analysis/statnet/R-statnet-grp_month-full_month-context_test.ipynb](../methods/network_analysis/statnet/R-statnet-grp_month-full_month-context_test.ipynb)\n",
    "    \n",
    "    - row counts are not the same, so need to look into what is going on.\n",
    "    - spec for just automated: `./grp_month_from_context.json`\n",
    "    \n",
    "        - output file: `./grp_month_from_context.tsv`\n",
    "        - attempt to just get automated coding from previous tool: `context_text_data-20200205-023708-just_automated.txt`\n",
    "        - to start, probably should create a program to compare the two:\n",
    "        \n",
    "            - for each relation in one, then the other:\n",
    "            \n",
    "                - look up the article in question.\n",
    "                - pull in data on it in context_text, and in context.\n",
    "                - compare - how many relations in context, compared to Article_Data for that article in context_text for just the automated coder.\n",
    "                - looking for two classes of problem: 1) where data was moved over incorrectly; and 2) where the filter criteria failed to pull in something in either system that should have been pulled in.\n",
    "                - need to see why \"just automated, just GRP, between 2009-12-01 and 2009-12-31\" gives different results in the two systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - DONE\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - DONE - general\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Nothing yet..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - DONE - Network data creation - framework\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Framework todos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2020.01.06\n",
    "\n",
    "- then, build basic framework where each output type accepts these two QuerySets, renders and returns desired output format.\n",
    "\n",
    "    - refactoring from old NetworkOutput, NetworkDataOutput, and NDO objects:\n",
    "\n",
    "        - // change so they refer to entities, not persons.\n",
    "        - // pull out all of the Article_Data stuff.\n",
    "        - // maintain the data structures used when actually rendering, just build from Entity_Relation, not Article_Data.  Might be able to get rid of some stuff, too.\n",
    "        - // terms to search for and consider replacing \"person\" with \"entity\" (if they aren't in sections that will just be ripped out because they are no longer needed):\n",
    "        \n",
    "            - // person_dictionary\n",
    "            - // person_dict\n",
    "            - // article_data_query_set\n",
    "            - // generate_master_person_list\n",
    "            - // person_ids_list\n",
    "            - // current_person_id \n",
    "            - // current_article_data\n",
    "            - // article_data_counter\n",
    "            - // master_person_list\n",
    "\n",
    "        - todo:\n",
    "\n",
    "            - // remove references to \"include_render_details\"\n",
    "            - // remove \"inclusion_params\"\n",
    "            \n",
    "                - // remove references to `self.inclusion_params`\n",
    "                - // remove references to `inclusion_params`\n",
    "                - // remove references to `self.is_source_connected( current_source )`\n",
    "            \n",
    "            - // remove network_label\n",
    "            - // update `generate_master_person_list()` to reference new variables (`generate_master_entity_list`).\n",
    "            - // what to do about `get_person_label()`? - updated to `get_entity_label`, for now just uses Entity ID.  Could make it also include more IF Entity instances are cached.  We'll see if that is helpful.\n",
    "            - // remove `get_person_type` and `get_person_type_id` (functions themselves are removed, need to mop up around the other classes: `grep -r -n \"get_person_type\" .`; `grep -r -n \"get_person_type_id\" .`\n",
    "            - // rename `get_relations_for_person` to `get_relations_for_entity`\n",
    "            - // rename `get_master_person_list` to `get_master_entity_list`\n",
    "            - // rename `create_person_id_list` to `create_entity_id_list`\n",
    "            - // rename `get_person_label` to `get_entity_label` (and made it a lot simpler).\n",
    "            - // remove `PERSON_QUERY_TYPE_CHOICES_LIST` and related.\n",
    "            - // remove `CODER_TYPE_FILTER_*`\n",
    "            - // remove `PERSON_TYPE_*` variables (check in all files)\n",
    "            - // search for \"person\", \"people\" in all NDO files in context.\n",
    "            \n",
    "                - // `ndo_simple_matrix.py`\n",
    "                - // `ndo_csv_matrix.py`\n",
    "                - // `ndo_tab_delimited_matrix.py`\n",
    "            \n",
    "            - // `Article_Subject`\n",
    "            - // `append_person_row`...\n",
    "            - // get rid of fancy date range code...\n",
    "            - // remove `PARAM_*`?  Not for now - used in places, is a good signal for needing changes.\n",
    "            \n",
    "        - update person type stuff so it stores a list, rather than \"author\", \"source\", or \"both\".\n",
    "        \n",
    "            - // As you build data, keep track centrally of all relation types seen - `register_relation_type( relation_type_IN )`, called from `render()`, optionally also from `update_entity_relation_details()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2020.01.08\n",
    "\n",
    "- build basic framework where each output type accepts these two QuerySets, renders and returns desired output format.\n",
    "\n",
    "    - refactoring from old NetworkOutput, NetworkDataOutput, and NDO objects:\n",
    "\n",
    "        - // `NetworkOutput.render_network_data()`: add outputting to file if file output path specified in request.\n",
    "        - // add check to see if master list is larger after integrating items from network processing - if so, output error - for the entity filter to be effective, it must be a superset of the network set of relations.\n",
    "        - // update person type stuff so it stores a list, rather than \"author\", \"source\", or \"both\".\n",
    "        \n",
    "            - // remove `update_person_type()`\n",
    "            - // check for places that retrieve person type dictionary ( `self.person_type_dict` ) - removed all.\n",
    "            - // create a variable, getter and setter for `relation_type_slug_to_instance_map` and `relation_type_slug_list`.\n",
    "            - // removed `NDO.create_person_type_id_list` - figure out ramifications.  Might need to create a set of columns for each relation type, one for each of FROM, TO, and THROUGH, then populate appropriately from the new relation type map.    \n",
    "            - // As you build data, keep track centrally of all relation types seen - call `register_relation_type( relation_type_IN )` to update map and list created above.  Updated from `render()`, optionally also from `update_entity_relation_details()`.\n",
    "            - then, when outputting:\n",
    "                \n",
    "                - // for headers, grab this list of relation types and create FROM, TO, and THROUGH column headers for each.\n",
    "                - // for tabular (`ndo_csv_matrix` and children):\n",
    "                    \n",
    "                    - // `NetworkDataOutput.create_relation_type_roles_for_entity()`: for data rows (attribute columns at right), walk the entity's relation type data structure in the same order as the relation type list, and output FROM, TO, and THROUGH numbers for each, 0 if not found.  Will result in many attribute columns.\n",
    "                    - for data columns (attribute rows at bottom), pull in all relation types, then for each entity-->type-->role, walk all entities and output their value for that relation type in the row.  So, will result in many rows of attribute values.\n",
    "                    \n",
    "                        - // `NetworkDataOutput.create_relation_type_role_value_list()`: create method that accepts a relation type slug and a role, creates list of values for all entities in master entity list for that combination of slug and role.  If not present for a given entity, sets to 0.\n",
    "                        - // `NetworkDataOutput.create_relation_type_value_dict()`: create a method that accepts a relation type slug, loops over all roles, calls `NetworkDataOutput.create_relation_type_role_value_list()` to build the list of values for each, then makes and returns dictionary mapping roles to value lists.\n",
    "                        - // `NetworkDataOutput.create_all_relation_type_values_lists()`: create a method that loops over relation type slugs, then for each, calls `NetworkDataOutput.create_relation_type_value_dict()` to create dictionary that maps roles to values lists.  Creates a dictionary that maps relation type slugs to these dictionaries, then returns the new dictionary.\n",
    "                        - // `NDO_CSVMatrix.append_entity_relation_type_rows()`: implement logic in the ndo_csv_matrix class that retrieves the values lists and uses them appropriately.\n",
    "                    \n",
    "                - // for `ndo_simple_matrix.py` (UCINet native format), need to implement `create_entity_relation_types_attribute_string()` - it assumed a single entity type value per person - need to re-do it so it pulls in all relation types, then outputs a list per person-->type-->role.  So, will result in many lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2020.01.23\n",
    "\n",
    "- add ability in JSON to tell which entity traits we want to include in output traits, then when loading entities, look for those traits in each as it is loaded, store in a separate entity ID to trait name-value map.\n",
    "\n",
    "    - // add place in output spec for:\n",
    "    \n",
    "        - traits (`output_entity_traits_list`?) - store the list of names/slugs of traits you want included if traits are output.  Possible filter criteria:\n",
    "        \n",
    "            - name\n",
    "            - slug\n",
    "            - entity_type_trait ID\n",
    "\n",
    "        - identifiers (`output_entity_identifiers_list`) - list of identifiers you want to include - to effectively target, might need an object with more than just name.  Possible filter criteria:\n",
    "        \n",
    "            - name\n",
    "            - id_type\n",
    "            - source\n",
    "            - identifier type ID\n",
    "            \n",
    "        - includes updating NetworkDataRequest and its tests to know of and allow for easy retrieval of these lists.\n",
    "\n",
    "    - // add to processing a step in generating the master entity list where you loop over the list of traits if one present in the request and make a map of the values for those traits for each entity (map entity ID --> trait dict).\n",
    "    \n",
    "        - move the logic for processing entities to NetworkDataRequest, so it can be used to pass the entity dictionary, master entity list, and entry traits to NetworkDataOutput and children.\n",
    "        \n",
    "            - `process_entities`\n",
    "            \n",
    "                - `add_entities_to_dict`\n",
    "                - `add_entity_to_dict`\n",
    "                -  entity dictionary and trait map, and getters and setters.\n",
    "\n",
    "                        self.m_entity_id_to_instance_map = {}\n",
    "                        self.m_entity_id_to_traits_map = {}\n",
    "                    \n",
    "                - it checks if traits specified (call to `NetworkDataRequest.do_output_entity_traits_or_ids()`).\n",
    "                - if so, calls `load_entities_traits_and_ids`.  Inside:\n",
    "            \n",
    "                    - `load_entity_traits`\n",
    "                    - `load_entity_identifiers`\n",
    "                \n",
    "        - need to remove all that stuff from NetworkOutput, fix everything so it works again.\n",
    "        - move all the test cases over to NetworkDataRequest.\n",
    "    \n",
    "    - // in rendering output, if traits output, update to render:\n",
    "    \n",
    "        - 1) entity ID\n",
    "        - 2) entity relation type role information\n",
    "        - 3) any requested traits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - DONE - Network data creation - testing\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Testing todos:\n",
    "\n",
    "- unit testing:\n",
    "\n",
    "    - // NetworkOutput\n",
    "\n",
    "        - // `create_ndo_instance()`\n",
    "        - // `get_NDO_instance()`\n",
    "        - // `get_network_data_request()`\n",
    "        - // `get_relation_query_set()`\n",
    "        - // `set_NDO_instance()`\n",
    "        - // `set_network_data_request()`\n",
    "        - // `set_relation_query_set()`\n",
    "        \n",
    "    - NetworkDataOutput\n",
    "\n",
    "        - // getters and setters\n",
    "\n",
    "            - // `get_entity_dictionary()`/`set_entity_dictionary()`\n",
    "            - // `get_entity_relation_type_summary_dict()`/`set_entity_relation_type_summary_dict()`\n",
    "            - // `get_master_entity_list()`/`set_master_entity_list()`\n",
    "            - // `get_network_data_request()`/`set_network_data_request()`\n",
    "            - // `get_output_format()`/`set_output_format()`\n",
    "            - // `get_output_structure()`/`set_output_structure()`\n",
    "            - // `get_output_type()`/`set_output_type()`\n",
    "            - // `get_query_set()`/`set_query_set()`\n",
    "            - // `get_relation_map()`/`set_relation_map()`\n",
    "            - // `get_relation_type_slug_list()`/`set_relation_type_slug_list()`\n",
    "            - // `get_relation_type_slug_to_instance_map()`/`set_relation_type_slug_to_instance_map()`\n",
    "\n",
    "        - // `set_query_set()`\n",
    "        - // `set_entity_dictionary()`\n",
    "        - // `initialize_from_request()`\n",
    "        - // `render()`\n",
    "\n",
    "            - // `get_query_set()`\n",
    "            - // `get_entity_dictionary()`\n",
    "            - // `add_directed_relation()`\n",
    "\n",
    "                - // `get_relation_map()`\n",
    "\n",
    "            - // `add_reciprocal_relation()`\n",
    "\n",
    "                - // (duplicate) `add_directed_relation()`\n",
    "\n",
    "            - // `register_relation_type()`\n",
    "\n",
    "                - // `get_relation_type_slug_to_instance_map()`\n",
    "                - // `get_relation_type_slug_list()`\n",
    "\n",
    "            - // `update_entity_relations_details()`\n",
    "\n",
    "                - // (duplicate) `register_relation_type()`\n",
    "                - // (duplicate)`get_entity_relation_type_summary_dict()`\n",
    "\n",
    "            - // `generate_master_entity_list()`\n",
    "\n",
    "                - // `get_entity_dictionary()`\n",
    "                - // (duplicate) `get_entity_relation_type_summary_dict()`\n",
    "                - // (duplicate) `set_master_entity_list()`\n",
    "                - // (duplicate) `get_master_entity_list()`\n",
    "\n",
    "            - abstract `render_network_data()`\n",
    "\n",
    "        - dependencies for child classes:\n",
    "\n",
    "            - // `create_entity_id_list()`\n",
    "            - // `create_all_relation_type_values_lists()`\n",
    "\n",
    "                - // `get_relation_type_slug_list()`\n",
    "                - // `create_relation_type_value_dict()`\n",
    "\n",
    "                    - // `create_relation_type_role_value_list()`\n",
    "\n",
    "                        - // (duplicate) `get_master_entity_list()`\n",
    "                        - // `get_entity_relation_type_summary_dict()`\n",
    "                        - // create goal data:\n",
    "                        \n",
    "                            - write program to, for basic, then entity_selection:\n",
    "                            \n",
    "                                - setup and render.\n",
    "                                - retrieve relation QS.\n",
    "                                - retrieve master entity ID list.\n",
    "                                - for each relation type\n",
    "\n",
    "                                    - for each role:\n",
    "                                    \n",
    "                                        - loop over ID list, and filter to count all relations where the current ID is in the selected type and role.\n",
    "\n",
    "    - // NetworkDataRequest\n",
    "\n",
    "        - // `process_entities()`\n",
    "\n",
    "            - // `create_entity_dict()`\n",
    "\n",
    "                - // `add_entities_to_dict()`\n",
    "\n",
    "                    - // `add_entity_to_dict()`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_virtualenv",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "425.783px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
