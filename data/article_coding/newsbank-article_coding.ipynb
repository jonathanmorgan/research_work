{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Setup---Debug\" data-toc-modified-id=\"Setup---Debug-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Setup - Debug</a></span></li><li><span><a href=\"#Setup---Imports\" data-toc-modified-id=\"Setup---Imports-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Setup - Imports</a></span></li><li><span><a href=\"#Setup---working-folder-paths\" data-toc-modified-id=\"Setup---working-folder-paths-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Setup - working folder paths</a></span></li><li><span><a href=\"#Setup---logging\" data-toc-modified-id=\"Setup---logging-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Setup - logging</a></span></li><li><span><a href=\"#Setup---virtualenv-jupyter-kernel\" data-toc-modified-id=\"Setup---virtualenv-jupyter-kernel-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Setup - virtualenv jupyter kernel</a></span></li><li><span><a href=\"#Setup---Initialize-Django\" data-toc-modified-id=\"Setup---Initialize-Django-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Setup - Initialize Django</a></span></li><li><span><a href=\"#Setup---Initialize-LoggingHelper\" data-toc-modified-id=\"Setup---Initialize-LoggingHelper-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>Setup - Initialize LoggingHelper</a></span></li></ul></li><li><span><a href=\"#Find-articles-to-be-coded\" data-toc-modified-id=\"Find-articles-to-be-coded-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Find articles to be coded</a></span><ul class=\"toc-item\"><li><span><a href=\"#which-articles-have-already-been-coded?\" data-toc-modified-id=\"which-articles-have-already-been-coded?-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>which articles have already been coded?</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tag-the-coded-articles\" data-toc-modified-id=\"Tag-the-coded-articles-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Tag the coded articles</a></span></li><li><span><a href=\"#Profile-the-coded-articles\" data-toc-modified-id=\"Profile-the-coded-articles-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Profile the coded articles</a></span></li></ul></li><li><span><a href=\"#tag-all-local-news\" data-toc-modified-id=\"tag-all-local-news-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>tag all local news</a></span><ul class=\"toc-item\"><li><span><a href=\"#TODO\" data-toc-modified-id=\"TODO-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>TODO</a></span><ul class=\"toc-item\"><li><span><a href=\"#DONE\" data-toc-modified-id=\"DONE-3.2.1.1\"><span class=\"toc-item-num\">3.2.1.1&nbsp;&nbsp;</span>DONE</a></span></li></ul></li><li><span><a href=\"#Grand-Rapids-Press-local-news\" data-toc-modified-id=\"Grand-Rapids-Press-local-news-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Grand Rapids Press local news</a></span></li><li><span><a href=\"#Detroit-News-local-news\" data-toc-modified-id=\"Detroit-News-local-news-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Detroit News local news</a></span></li></ul></li></ul></li><li><span><a href=\"#Code-Articles\" data-toc-modified-id=\"Code-Articles-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Code Articles</a></span><ul class=\"toc-item\"><li><span><a href=\"#Optional-Validation\" data-toc-modified-id=\"Optional-Validation-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Optional Validation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Validate-success-publications\" data-toc-modified-id=\"Validate-success-publications-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Validate success publications</a></span></li><li><span><a href=\"#Validate-error-publications\" data-toc-modified-id=\"Validate-error-publications-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Validate error publications</a></span></li></ul></li></ul></li><li><span><a href=\"#TODO\" data-toc-modified-id=\"TODO-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>TODO</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "This is a notebook that expands on the OpenCalais code in the file `article_coding.py`, also in this folder.  It includes more sections on selecting publications you want to submit to OpenCalais as an example.  It is intended to be copied and re-used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Debug\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T14:20:58.860415Z",
     "start_time": "2019-08-11T14:20:58.849302Z"
    }
   },
   "outputs": [],
   "source": [
    "debug_flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Imports\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T14:21:00.360077Z",
     "start_time": "2019-08-11T14:21:00.183892Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from django.db.models import Avg, Max, Min\n",
    "import logging\n",
    "import six"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - working folder paths\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T14:21:01.570214Z",
     "start_time": "2019-08-11T14:21:01.545056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jonathanmorgan/work/django/research/work/phd_work/data/article_coding'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current working folder\n",
    "current_working_folder = \"/home/jonathanmorgan/work/django/research/work/phd_work/analysis\"\n",
    "current_datetime = datetime.datetime.now()\n",
    "current_date_string = current_datetime.strftime( \"%Y-%m-%d-%H-%M-%S\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - logging\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "configure logging for this notebook's kernel (If you do not run this cell, you'll get the django application's logging configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T14:21:19.306850Z",
     "start_time": "2019-08-11T14:21:19.295790Z"
    }
   },
   "outputs": [],
   "source": [
    "# build file name\n",
    "logging_file_name = \"{}/article_coding-{}.log.txt\".format( current_working_folder, current_date_string )\n",
    "\n",
    "# set up logging.\n",
    "logging.basicConfig(\n",
    "    level = logging.DEBUG,\n",
    "    format = '%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
    "    filename = logging_file_name,\n",
    "    filemode = 'w' # set to 'a' if you want to append, rather than overwrite each time.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - virtualenv jupyter kernel\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "If you are using a virtualenv, make sure that you:\n",
    "\n",
    "- have installed your virtualenv as a kernel.\n",
    "- choose the kernel for your virtualenv as the kernel for your notebook (Kernel --> Change kernel).\n",
    "\n",
    "Since I use a virtualenv, need to get that activated somehow inside this notebook.  One option is to run `../dev/wsgi.py` in this notebook, to configure the python environment manually as if you had activated the `sourcenet` virtualenv.  To do this, you'd make a code cell that contains:\n",
    "\n",
    "    %run ../dev/wsgi.py\n",
    "    \n",
    "This is sketchy, however, because of the changes it makes to your Python environment within the context of whatever your current kernel is.  I'd worry about collisions with the actual Python 3 kernel.  Better, one can install their virtualenv as a separate kernel.  Steps:\n",
    "\n",
    "- activate your virtualenv:\n",
    "\n",
    "        workon research\n",
    "\n",
    "- in your virtualenv, install the package `ipykernel`.\n",
    "\n",
    "        pip install ipykernel\n",
    "\n",
    "- use the ipykernel python program to install the current environment as a kernel:\n",
    "\n",
    "        python -m ipykernel install --user --name <env_name> --display-name \"<display_name>\"\n",
    "        \n",
    "    `sourcenet` example:\n",
    "    \n",
    "        python -m ipykernel install --user --name sourcenet --display-name \"research (Python 3)\"\n",
    "        \n",
    "More details: [http://ipython.readthedocs.io/en/stable/install/kernel_install.html](http://ipython.readthedocs.io/en/stable/install/kernel_install.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Initialize Django\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "First, initialize my dev django project, so I can run code in this notebook that references my django models and can talk to the database using my project's settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T14:21:21.579845Z",
     "start_time": "2019-08-11T14:21:21.569585Z"
    }
   },
   "outputs": [],
   "source": [
    "# init django\n",
    "django_init_folder = \"/home/jonathanmorgan/work/django/research/work/phd_work\"\n",
    "django_init_path = \"django_init.py\"\n",
    "if( ( django_init_folder is not None ) and ( django_init_folder != \"\" ) ):\n",
    "    \n",
    "    # add folder to front of path.\n",
    "    django_init_path = \"{}/{}\".format( django_init_folder, django_init_path )\n",
    "    \n",
    "#-- END check to see if django_init folder. --#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T14:21:24.194003Z",
     "start_time": "2019-08-11T14:21:22.374313Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "django initialized at 2019-08-11 14:21:24.190799\n"
     ]
    }
   ],
   "source": [
    "%run $django_init_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T14:21:24.404603Z",
     "start_time": "2019-08-11T14:21:24.200524Z"
    }
   },
   "outputs": [],
   "source": [
    "# context_text imports\n",
    "from context_text.article_coding.article_coding import ArticleCoder\n",
    "from context_text.article_coding.article_coding import ArticleCoding\n",
    "from context_text.article_coding.open_calais_v2.open_calais_v2_article_coder import OpenCalaisV2ArticleCoder\n",
    "from context_text.collectors.newsbank.newspapers.GRPB import GRPB\n",
    "from context_text.collectors.newsbank.newspapers.DTNB import DTNB\n",
    "from context_text.models import Article\n",
    "from context_text.models import Article_Subject\n",
    "from context_text.models import Newspaper\n",
    "from context_text.shared.context_text_base import ContextTextBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Initialize LoggingHelper\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Create a LoggingHelper instance to use to log debug and also print at the same time.\n",
    "\n",
    "Preconditions: Must be run after Django is initialized, since `python_utilities` is in the django path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T14:21:24.819278Z",
     "start_time": "2019-08-11T14:21:24.794914Z"
    }
   },
   "outputs": [],
   "source": [
    "# python_utilities\n",
    "from python_utilities.logging.logging_helper import LoggingHelper\n",
    "\n",
    "# init\n",
    "my_logging_helper = LoggingHelper()\n",
    "my_logging_helper.set_logger_name( \"newsbank-article_coding\" )\n",
    "log_message = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find articles to be coded\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Tag all locally implemented hard news articles in database and all that have already been coded using Open Calais V2, then work through using OpenCalais to code all local hard news that hasn't alredy been coded, starting with those proximal to the coding sample for methods paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## which articles have already been coded?\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "More precisely, find all articles that have Article_Data coded by the automated coder with type \"OpenCalais_REST_API_v2\" and tag the articles as \"coded-open_calais_v2\" or something like that.\n",
    "\n",
    "Then, for articles without that tag, use our criteria for local hard news to filter out and tag publications in the year before and after the month used to evaluate the automated coder, in both the Grand Rapids Press and the Detroit News, so I can look at longer time frames, then code all articles currently in database.\n",
    "\n",
    "Eventually, then, we'll code and examine before and after layoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T14:21:26.966947Z",
     "start_time": "2019-08-11T14:21:26.928620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-11 14:21:26.963496 - Loaded automated user: automated, id = 2\n"
     ]
    }
   ],
   "source": [
    "# look for publications that have article data:\n",
    "# - coded by automated coder\n",
    "# - with coder type of \"OpenCalais_REST_API_v2\"\n",
    "\n",
    "# get automated coder\n",
    "automated_coder_user = ArticleCoder.get_automated_coding_user()\n",
    "\n",
    "print( \"{} - Loaded automated user: {}, id = {}\".format( datetime.datetime.now(), automated_coder_user, automated_coder_user.id ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T19:39:39.564585Z",
     "start_time": "2019-07-31T19:39:39.556701Z"
    }
   },
   "outputs": [],
   "source": [
    "# try aggregates\n",
    "article_qs = Article.objects.all()\n",
    "pub_date_info = article_qs.aggregate( Max( 'pub_date' ), Min( 'pub_date' ) )\n",
    "print( pub_date_info )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T03:51:39.175858Z",
     "start_time": "2019-08-03T03:51:39.052603Z"
    }
   },
   "outputs": [],
   "source": [
    "# find articles with Article_Data created by the automated user...\n",
    "article_qs = Article.objects.filter( article_data__coder = automated_coder_user )\n",
    "\n",
    "# ...and specifically coded using OpenCalais V2...\n",
    "article_qs = article_qs.filter( article_data__coder_type = OpenCalaisV2ArticleCoder.CONFIG_APPLICATION )\n",
    "\n",
    "# ...and finally, we just want the distinct articles by ID.\n",
    "article_qs = article_qs.order_by( \"id\" ).distinct( \"id\" )\n",
    "\n",
    "# count?\n",
    "article_count = article_qs.count()\n",
    "print( \"Found {} articles\".format( article_count ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag the coded articles\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Removing duplicates present from joining with Article_Data yields 579 articles that were coded by the automated coder.\n",
    "\n",
    "Tag all the coded articles with `OpenCalaisV2ArticleCoder.TAG_CODED_BY_ME`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T19:40:04.298910Z",
     "start_time": "2019-07-31T19:40:03.244803Z"
    }
   },
   "outputs": [],
   "source": [
    "# declare variables\n",
    "current_article = None\n",
    "tag_name_list = None\n",
    "article_count = None\n",
    "untagged_count = None\n",
    "already_tagged_count = None\n",
    "newly_tagged_count = None\n",
    "count_sum = None\n",
    "do_add_tag = False\n",
    "\n",
    "# init\n",
    "do_add_tag = True\n",
    "\n",
    "# get article_count\n",
    "article_count = article_qs.count()\n",
    "\n",
    "# loop over articles.\n",
    "untagged_count = 0\n",
    "already_tagged_count = 0\n",
    "newly_tagged_count = 0\n",
    "for current_article in article_qs:\n",
    "    \n",
    "    # get list of tags for this publication\n",
    "    tag_name_list = current_article.tags.names()\n",
    "    \n",
    "    # is the coded tag in the list?\n",
    "    if ( OpenCalaisV2ArticleCoder.TAG_CODED_BY_ME not in tag_name_list ):\n",
    "        \n",
    "        # are we adding tag?\n",
    "        if ( do_add_tag == True ):\n",
    "\n",
    "            # add tag.\n",
    "            current_article.tags.add( OpenCalaisV2ArticleCoder.TAG_CODED_BY_ME )\n",
    "            newly_tagged_count += 1\n",
    "            \n",
    "        else:\n",
    "\n",
    "            # for now, increment untagged count\n",
    "            untagged_count += 1\n",
    "            \n",
    "        #-- END check to see if we are adding tag. --#\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # already tagged\n",
    "        already_tagged_count += 1\n",
    "        \n",
    "    #-- END check to see if coded tag is set --#\n",
    "    \n",
    "#-- END loop over articles. --#\n",
    "\n",
    "print( \"Article counts:\" )\n",
    "print( \"- total articles: {}\".format( article_count ) )\n",
    "print( \"- untagged articles: {}\".format( untagged_count ) )\n",
    "print( \"- already tagged: {}\".format( already_tagged_count ) )\n",
    "print( \"- newly tagged: {}\".format( newly_tagged_count ) )\n",
    "count_sum = untagged_count + already_tagged_count + newly_tagged_count\n",
    "print( \"- count sum: {}\".format( count_sum ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profile the coded articles\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Look at range of pub dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T03:52:35.494718Z",
     "start_time": "2019-08-03T03:52:35.473029Z"
    }
   },
   "outputs": [],
   "source": [
    "tags_in_list = []\n",
    "tags_in_list.append( OpenCalaisV2ArticleCoder.TAG_CODED_BY_ME )\n",
    "article_qs = Article.objects.filter( tags__name__in = tags_in_list )\n",
    "print( \"Matching article count: {}\".format( article_qs.count() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Original: 579\n",
    "- after coding 10: 589 (tag is being set correctly by Open Calais V2 coder)\n",
    "- 2019.08.02 - after 5000 (minus a few errors because 2 seconds isn't quite enough for rate limit): 5518"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T17:49:07.328924Z",
     "start_time": "2019-07-31T17:49:07.275399Z"
    }
   },
   "outputs": [],
   "source": [
    "# profile these publications\n",
    "min_pub_date = None\n",
    "max_pub_date = None\n",
    "current_pub_date = None\n",
    "pub_date_count = None\n",
    "date_to_count_map = {}\n",
    "date_to_articles_map = {}\n",
    "pub_date_article_dict = None\n",
    "\n",
    "# try aggregates\n",
    "pub_date_info = article_qs.aggregate( Max( 'pub_date' ), Min( 'pub_date' ) )\n",
    "print( pub_date_info )\n",
    "\n",
    "# counts of pubs by date\n",
    "for current_article in article_qs:\n",
    "    \n",
    "    # get pub_date\n",
    "    current_pub_date = current_article.pub_date\n",
    "    current_article_id = current_article.id\n",
    "    \n",
    "    # get count, increment, and store.\n",
    "    pub_date_count = date_to_count_map.get( current_pub_date, 0 )\n",
    "    pub_date_count += 1\n",
    "    date_to_count_map[ current_pub_date ] = pub_date_count\n",
    "    \n",
    "    # also, store up ids and instances\n",
    "    \n",
    "    # get dict of article ids to article instances for date\n",
    "    pub_date_article_dict = date_to_articles_map.get( current_pub_date, {} )\n",
    "    \n",
    "    # article already there?\n",
    "    if ( current_article_id not in pub_date_article_dict ):\n",
    "        \n",
    "        # no - add it.\n",
    "        pub_date_article_dict[ current_article_id ] = current_article\n",
    "        \n",
    "    #-- END check to see if article already there.\n",
    "    \n",
    "    # put dict back.\n",
    "    date_to_articles_map[ current_pub_date ] = pub_date_article_dict\n",
    "    \n",
    "#-- END loop over articles. --#\n",
    "\n",
    "# output dates and counts.\n",
    "\n",
    "# get list of keys from map\n",
    "keys_list = list( six.viewkeys( date_to_count_map ) )\n",
    "keys_list.sort()\n",
    "for current_pub_date in keys_list:\n",
    "    \n",
    "    # get count\n",
    "    pub_date_count = date_to_count_map.get( current_pub_date, 0 )\n",
    "    print( \"- {} ( {} ) count: {}\".format( current_pub_date, type( current_pub_date ), pub_date_count ) )\n",
    "    \n",
    "#-- END loop over dates --#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T17:49:13.567482Z",
     "start_time": "2019-07-31T17:49:13.535813Z"
    }
   },
   "outputs": [],
   "source": [
    "# look at the 2010-07-31 date\n",
    "pub_date = datetime.datetime.strptime( \"2010-07-31\", \"%Y-%m-%d\" ).date()\n",
    "articles_for_date = date_to_articles_map.get( pub_date, {} )\n",
    "print( articles_for_date )\n",
    "\n",
    "# get the article and look at its tags.\n",
    "article_instance = articles_for_date.get( 6065 )\n",
    "print( article_instance.tags.all() )\n",
    "\n",
    "# loop over associated Article_Data instances.\n",
    "for article_data in article_instance.article_data_set.all():\n",
    "    \n",
    "    print( article_data )\n",
    "    \n",
    "#-- END loop over associated Article_Data instances --#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tag all local news\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Definition of local hard news by in-house implementor for Grand Rapids Press and Detroit News follow.  For each, tag all articles in database that match as \"local_hard_news\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "TODO:\n",
    "\n",
    "- make class for GRPB at NewsBank.\n",
    "\n",
    "    - also, pull the things that are newspaper specific out of ArticleCoder.py and into the GRPB.py class.\n",
    "\n",
    "- refine \"local news\" and \"locally created\" regular expressions for Grand Rapids Press based on contents of `author_string` and `author_affiliation`.\n",
    "- do the same for TDN.\n",
    "- then, use the updated classes and definitions below to flag all local hard news in database for each publication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DONE\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "DONE:\n",
    "\n",
    "- abstract out shared stuff from GRPB.py and DTNB.py into abstract parent class context_text/collectors/newsbank/newspapers/newsbank_newspaper.py\n",
    "\n",
    "    - update DTNB.py to use the parent class.\n",
    "    \n",
    "- make class for GRPB at NewsBank.\n",
    "\n",
    "    - context_text/collectors/newsbank/newspapers/GRPB.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grand Rapids Press local news\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Grand Rapids Press local hard news:\n",
    "\n",
    "- `context_text/examples/articles/articles-GRP-local_news.py`\n",
    "- local hard news sections (stored in `Article.GRP_NEWS_SECTION_NAME_LIST`):\n",
    "\n",
    "    - \"Business\"\n",
    "    - \"City and Region\"\n",
    "    - \"Front Page\"\n",
    "    - \"Lakeshore\"\n",
    "    - \"Religion\"\n",
    "    - \"Special\"\n",
    "    - \"State\"\n",
    "\n",
    "- in-house implementor (based on byline patterns, stored in `sourcenet.models.Article.Q_GRP_IN_HOUSE_AUTHOR`):\n",
    "\n",
    "    - Byline ends in \"/ THE GRAND RAPIDS PRESS\", ignore case.\n",
    "\n",
    "        - `Q( author_varchar__iregex = r'.* */ *THE GRAND RAPIDS PRESS$'`\n",
    "\n",
    "    - Byline ends in \"/ PRESS * EDITOR\", ignore case.\n",
    "\n",
    "        - `Q( author_varchar__iregex = r'.* */ *PRESS .* EDITOR$' )`\n",
    "\n",
    "    - Byline ends in \"/ GRAND RAPIDS PRESS * BUREAU\", ignore case.\n",
    "\n",
    "        - `Q( author_varchar__iregex = r'.* */ *GRAND RAPIDS PRESS .* BUREAU$' )`\n",
    "\n",
    "    - Byline ends in \"/ SPECIAL TO THE PRESS\", ignore case.\n",
    "\n",
    "        - `Q( author_varchar__iregex = r'.* */ *SPECIAL TO THE PRESS$' )`\n",
    "        \n",
    "- can also exclude columns (I will not):\n",
    "\n",
    "        grp_article_qs = grp_article_qs.exclude( index_terms__icontains = \"Column\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to work to further refine this.\n",
    "\n",
    "Looking at affiliation strings:\n",
    "\n",
    "    SELECT author_affiliation, COUNT( author_affiliation ) as affiliation_count\n",
    "    FROM context_text_article\n",
    "    WHERE newspaper_id = 1\n",
    "    GROUP BY author_affiliation\n",
    "    ORDER BY COUNT( author_affiliation ) DESC;\n",
    "    \n",
    "And at author strings for collective bylines:\n",
    "\n",
    "    SELECT author_string, COUNT( author_string ) as author_count\n",
    "    FROM context_text_article\n",
    "    WHERE newspaper_id = 1\n",
    "    GROUP BY author_string\n",
    "    ORDER BY COUNT( author_string ) DESC\n",
    "    LIMIT 10;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T18:37:55.617849Z",
     "start_time": "2019-07-31T18:37:34.091526Z"
    }
   },
   "outputs": [],
   "source": [
    "# filter queryset to just locally created Grand Rapids Press (GRP) articles.\n",
    "# imports\n",
    "from context_text.models import Article\n",
    "from context_text.models import Newspaper\n",
    "from context_text.shared.context_text_base import ContextTextBase\n",
    "from context_text.collectors.newsbank.newspapers.GRPB import GRPB\n",
    "\n",
    "# declare variables - Grand Rapids Press\n",
    "do_apply_tag = False\n",
    "tag_to_apply = None\n",
    "grp_local_news_sections = []\n",
    "grp_newspaper = None\n",
    "grp_article_qs = None\n",
    "article_count = -1\n",
    "\n",
    "# declare variables - filtering\n",
    "include_opinion_columns = True\n",
    "tags_in_list = []\n",
    "tags_not_in_list = []\n",
    "filter_out_prelim_tags = False\n",
    "random_count = -1\n",
    "\n",
    "# declare variables - make list of article IDs from QS.\n",
    "article_id_list = []\n",
    "article_counter = -1\n",
    "current_article = None\n",
    "article_tag_name_list = None\n",
    "article_update_counter = -1\n",
    "\n",
    "# ==> configure\n",
    "\n",
    "# configure - size of random sample we want\n",
    "#random_count = 60\n",
    "\n",
    "# configure - also, apply tag?\n",
    "do_apply_tag = True\n",
    "tag_to_apply = ContextTextBase.TAG_LOCAL_HARD_NEWS\n",
    "\n",
    "# set up \"local, regional and state news\" sections\n",
    "grp_local_news_sections = GRPB.LOCAL_NEWS_SECTION_NAME_LIST\n",
    "\n",
    "# Grand Rapids Press\n",
    "# get newspaper instance for GRP.\n",
    "grp_newspaper = Newspaper.objects.get( id = GRPB.NEWSPAPER_ID )\n",
    "\n",
    "# start with all articles\n",
    "#grp_article_qs = Article.objects.all()\n",
    "\n",
    "# ==> filter to newspaper, local news section list, and in-house reporters.\n",
    "\n",
    "# ----> manually\n",
    "\n",
    "# now, need to find local news articles to test on.\n",
    "#grp_article_qs = grp_article_qs.filter( newspaper = grp_newspaper )\n",
    "\n",
    "# only the locally implemented sections\n",
    "#grp_article_qs = grp_article_qs.filter( section__in = grp_local_news_sections )\n",
    "\n",
    "# and, with an in-house author\n",
    "#grp_article_qs = grp_article_qs.filter( Article.Q_GRP_IN_HOUSE_AUTHOR )\n",
    "\n",
    "#print( \"manual filter count: {}\".format( grp_article_qs.count() ) )\n",
    "\n",
    "# ----> using Article.filter_articles()\n",
    "grp_article_qs = Article.filter_articles( qs_IN = grp_article_qs,\n",
    "                                          newspaper = grp_newspaper,\n",
    "                                          section_name_list = grp_local_news_sections,\n",
    "                                          custom_article_q = GRPB.Q_IN_HOUSE_AUTHOR )\n",
    "\n",
    "print( \"Article.filter_articles count: {}\".format( grp_article_qs.count() ) )\n",
    "\n",
    "# and include opinion columns?\n",
    "if ( include_opinion_columns == False ):\n",
    "    \n",
    "    # do not include columns\n",
    "    grp_article_qs = grp_article_qs.exclude( index_terms__icontains = \"Column\" )\n",
    "    \n",
    "#-- END check to see if we include columns. --#\n",
    "\n",
    "'''\n",
    "# filter to newspaper, section list, and in-house reporters.\n",
    "grp_article_qs = Article.filter_articles( qs_IN = grp_article_qs,\n",
    "                                          start_date = \"2009-12-01\",\n",
    "                                          end_date = \"2009-12-31\",\n",
    "                                          newspaper = grp_newspaper,\n",
    "                                          section_name_list = grp_local_news_sections,\n",
    "                                          custom_article_q = Article.Q_GRP_IN_HOUSE_AUTHOR )\n",
    "'''\n",
    "\n",
    "# how many is that?\n",
    "article_count = grp_article_qs.count()\n",
    "\n",
    "print( \"Article count before filtering on tags: \" + str( article_count ) )\n",
    "\n",
    "# ==> tags\n",
    "\n",
    "# tags to exclude\n",
    "tags_not_in_list = []\n",
    "\n",
    "# Example: prelim-related tags\n",
    "#tags_not_in_list.append( \"prelim_reliability\" )\n",
    "#tags_not_in_list.append( \"prelim_network\" ]\n",
    "#tags_not_in_list.append( \"minnesota1-20160328\" )\n",
    "#tags_not_in_list.append( \"minnesota2-20160328\" )\n",
    "\n",
    "# for later - exclude articles already coded.\n",
    "#tags_not_in_list.append( OpenCalaisV2ArticleCoder.TAG_CODED_BY_ME )\n",
    "\n",
    "# exclude any already tagged with tag_to_apply\n",
    "tags_not_in_list.append( tag_to_apply )\n",
    "\n",
    "if ( ( tags_not_in_list is not None ) and ( len( tags_not_in_list ) > 0 ) ):\n",
    "\n",
    "    # exclude those in a list\n",
    "    print( \"filtering out articles with tags: \" + str( tags_not_in_list ) )\n",
    "    grp_article_qs = grp_article_qs.exclude( tags__name__in = tags_not_in_list )\n",
    "\n",
    "#-- END check to see if we have a specific list of tags we want to exclude --#\n",
    "\n",
    "# include only those with certain tags.\n",
    "tags_in_list = []\n",
    "\n",
    "# Examples\n",
    "\n",
    "# Examples: prelim-related tags\n",
    "#tags_in_list.append( \"prelim_unit_test_001\" )\n",
    "#tags_in_list.append( \"prelim_unit_test_002\" )\n",
    "#tags_in_list.append( \"prelim_unit_test_003\" )\n",
    "#tags_in_list.append( \"prelim_unit_test_004\" )\n",
    "#tags_in_list.append( \"prelim_unit_test_005\" )\n",
    "#tags_in_list.append( \"prelim_unit_test_006\" )\n",
    "#tags_in_list.append( \"prelim_unit_test_007\" )\n",
    "\n",
    "# Example: grp_month\n",
    "#tags_in_list.append( \"grp_month\" )\n",
    "\n",
    "if ( ( tags_in_list is not None ) and ( len( tags_in_list ) > 0 ) ):\n",
    "\n",
    "    # filter\n",
    "    print( \"filtering to just articles with tags: \" + str( tags_in_list ) )\n",
    "    grp_article_qs = grp_article_qs.filter( tags__name__in = tags_in_list )\n",
    "    \n",
    "#-- END check to see if we have a specific list of tags we want to include --#\n",
    "\n",
    "# filter out \"*prelim*\" tags?\n",
    "#filter_out_prelim_tags = True\n",
    "if ( filter_out_prelim_tags == True ):\n",
    "\n",
    "    # ifilter out all articles with any tag whose name contains \"prelim\".\n",
    "    print( \"filtering out articles with tags that contain \\\"prelim\\\"\" )\n",
    "    grp_article_qs = grp_article_qs.exclude( tags__name__icontains = \"prelim\" )\n",
    "    \n",
    "#-- END check to see if we filter out \"prelim_*\" tags --#\n",
    "\n",
    "# how many is that?\n",
    "article_count = grp_article_qs.count()\n",
    "\n",
    "print( \"Article count after tag filtering: \" + str( article_count ) )\n",
    "\n",
    "# do we want a random sample?\n",
    "if ( random_count > 0 ):\n",
    "\n",
    "    # to get random, order them by \"?\", then use slicing to retrieve requested\n",
    "    #     number.\n",
    "    grp_article_qs = grp_article_qs.order_by( \"?\" )[ : random_count ]\n",
    "    \n",
    "#-- END check to see if we want random sample --#\n",
    "\n",
    "# this is a nice algorithm, also:\n",
    "# - http://www.titov.net/2005/09/21/do-not-use-order-by-rand-or-how-to-get-random-rows-from-table/\n",
    "\n",
    "# make ID list, tag articles if configured to.\n",
    "article_id_list = []\n",
    "article_counter = 0\n",
    "article_update_counter = 0\n",
    "for current_article in grp_article_qs:\n",
    "\n",
    "    # increment article_counter\n",
    "    article_counter += 1\n",
    "\n",
    "    # add IDs to article_id_list\n",
    "    article_id_list.append( str( current_article.id ) )\n",
    "    \n",
    "    # apply a tag while we are at it?\n",
    "    if ( ( do_apply_tag == True ) and ( tag_to_apply is not None ) and ( tag_to_apply != \"\" ) ):\n",
    "    \n",
    "        # yes, please.  Tag already present?\n",
    "        article_tag_name_list = current_article.tags.names()\n",
    "        if ( tag_to_apply not in article_tag_name_list ):\n",
    "\n",
    "            # Add tag.\n",
    "            current_article.tags.add( tag_to_apply )\n",
    "            \n",
    "            # increment counter\n",
    "            article_update_counter += 1\n",
    "            \n",
    "        #-- END check to see if tag already present. --#\n",
    "        \n",
    "    #-- END check to see if we apply tag. --#\n",
    "\n",
    "    # output the tags.\n",
    "    if ( debug_flag == True ):\n",
    "        print( \"- Tags for article \" + str( current_article.id ) + \" : \" + str( current_article.tags.all() ) )\n",
    "    #-- END DEBUG --#\n",
    "\n",
    "#-- END loop over articles --#\n",
    "\n",
    "# output the list.\n",
    "print( \"grp_article_qs count: {}\".format( grp_article_qs.count() ) )\n",
    "print( \"Found \" + str( article_counter ) + \" articles ( \" + str( article_count ) + \" ).\" )\n",
    "print( \"- Updated {} articles to add tag {}.\".format( article_update_counter, tag_to_apply ) )\n",
    "if ( debug_flag == True ):\n",
    "    print( \"List of \" + str( len( article_id_list ) ) + \" local GRP staff article IDs: \" + \", \".join( article_id_list ) )\n",
    "#-- END DEBUG --#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detroit News local news\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Detroit News local news:\n",
    "\n",
    "- `context_text/examples/articles/articles-TDN-local_news.py`\n",
    "- local hard news sections (stored in `from context_text.collectors.newsbank.newspapers.DTNB import DTNB` - `DTNB.NEWS_SECTION_NAME_LIST`):\n",
    "\n",
    "    - \"Business\"\n",
    "    - \"Metro\"\n",
    "    - \"Nation\" - because of auto industry stories\n",
    "\n",
    "- in-house implementor (based on byline patterns, stored in `DTNB.Q_IN_HOUSE_AUTHOR`):\n",
    "\n",
    "    - Byline ends in \"/ The Detroit News\", ignore case.\n",
    "\n",
    "        - `Q( author_varchar__iregex = r'.*\\s*/\\s*the\\s*detroit\\s*news$' )`\n",
    "\n",
    "    - Byline ends in \"Special to The Detroit News\", ignore case.\n",
    "\n",
    "        - `Q( author_varchar__iregex = r'.*\\s*/\\s*special\\s*to\\s*the\\s*detroit\\s*news$' )`\n",
    "\n",
    "    - Byline ends in \"Detroit News * Bureau\", ignore case.\n",
    "\n",
    "        - `Q( author_varchar__iregex = r'.*\\s*/\\s*detroit\\s*news\\s*.*\\s*bureau$' )`   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-04T02:42:42.445226Z",
     "start_time": "2019-07-04T02:42:39.261361Z"
    }
   },
   "outputs": [],
   "source": [
    "# filter queryset to just locally created Detroit News (TDN) articles.\n",
    "# imports\n",
    "from context_text.models import Article\n",
    "from context_text.models import Newspaper\n",
    "from context_text.shared.context_text_base import ContextTextBase\n",
    "from context_text.collectors.newsbank.newspapers.DTNB import DTNB\n",
    "\n",
    "# declare variables - Detroit News\n",
    "do_apply_tag = False\n",
    "tag_to_apply = None\n",
    "tdn_local_news_sections = []\n",
    "tdn_newspaper = None\n",
    "tdn_article_qs = None\n",
    "article_count = -1\n",
    "\n",
    "# declare variables - filtering\n",
    "include_opinion_columns = True\n",
    "tags_in_list = []\n",
    "tags_not_in_list = []\n",
    "filter_out_prelim_tags = False\n",
    "random_count = -1\n",
    "\n",
    "# declare variables - make list of article IDs from QS.\n",
    "article_id_list = []\n",
    "article_counter = -1\n",
    "current_article = None\n",
    "\n",
    "# ==> configure\n",
    "\n",
    "# configure - size of random sample we want\n",
    "#random_count = 60\n",
    "\n",
    "# configure - also, apply tag?\n",
    "do_apply_tag = False\n",
    "tag_to_apply = ContextTextBase.TAG_LOCAL_HARD_NEWS\n",
    "\n",
    "# set up \"local, regional and state news\" sections\n",
    "tdn_local_news_sections = DTNB.LOCAL_NEWS_SECTION_NAME_LIST\n",
    "\n",
    "# Detroit News\n",
    "# get newspaper instance for TDN.\n",
    "tdn_newspaper = Newspaper.objects.get( id = DTNB.NEWSPAPER_ID )\n",
    "\n",
    "# start with all articles\n",
    "#tdn_article_qs = Article.objects.all()\n",
    "\n",
    "# ==> filter to newspaper, local news section list, and in-house reporters.\n",
    "\n",
    "# ----> manually\n",
    "\n",
    "# now, need to find local news articles to test on.\n",
    "#tdn_article_qs = tdn_article_qs.filter( newspaper = tdn_newspaper )\n",
    "\n",
    "# only the locally implemented sections\n",
    "#tdn_article_qs = tdn_article_qs.filter( section__in = tdn_local_news_sections )\n",
    "\n",
    "# and, with an in-house author\n",
    "#tdn_article_qs = tdn_article_qs.filter( DTNB.Q_IN_HOUSE_AUTHOR )\n",
    "\n",
    "#print( \"manual filter count: {}\".format( tdn_article_qs.count() ) )\n",
    "\n",
    "# ----> using Article.filter_articles()\n",
    "tdn_article_qs = Article.filter_articles( qs_IN = tdn_article_qs,\n",
    "                                          newspaper = tdn_newspaper,\n",
    "                                          section_name_list = tdn_local_news_sections,\n",
    "                                          custom_article_q = DTNB.Q_IN_HOUSE_AUTHOR )\n",
    "\n",
    "print( \"Article.filter_articles count: {}\".format( tdn_article_qs.count() ) )\n",
    "\n",
    "# and include opinion columns?\n",
    "if ( include_opinion_columns == False ):\n",
    "    \n",
    "    # do not include columns\n",
    "    tdn_article_qs = tdn_article_qs.exclude( author_string__in = DTNB.COLUMNIST_NAME_LIST )\n",
    "    \n",
    "#-- END check to see if we include columns. --#\n",
    "\n",
    "'''\n",
    "# filter to newspaper, section list, and in-house reporters.\n",
    "tdn_article_qs = Article.filter_articles( qs_IN = tdn_article_qs,\n",
    "                                          start_date = \"2009-12-01\",\n",
    "                                          end_date = \"2009-12-31\",\n",
    "                                          newspaper = tdn_newspaper,\n",
    "                                          section_name_list = tdn_local_news_sections,\n",
    "                                          custom_article_q = DTNB.Q_IN_HOUSE_AUTHOR )\n",
    "'''\n",
    "\n",
    "# how many is that?\n",
    "article_count = tdn_article_qs.count()\n",
    "\n",
    "print( \"Article count before filtering on tags: \" + str( article_count ) )\n",
    "\n",
    "# ==> tags\n",
    "\n",
    "# tags to exclude\n",
    "#tags_not_in_list = [ \"prelim_reliability\", \"prelim_network\" ]\n",
    "#tags_not_in_list = [ \"minnesota1-20160328\", \"minnesota2-20160328\", ]\n",
    "\n",
    "# for later - exclude articles already coded.\n",
    "#tags_not_in_list = [ OpenCalaisV2ArticleCoder.TAG_CODED_BY_ME ]\n",
    "\n",
    "tags_not_in_list = None\n",
    "if ( ( tags_not_in_list is not None ) and ( len( tags_not_in_list ) > 0 ) ):\n",
    "\n",
    "    # exclude those in a list\n",
    "    print( \"filtering out articles with tags: \" + str( tags_not_in_list ) )\n",
    "    tdn_article_qs = tdn_article_qs.exclude( tags__name__in = tags_not_in_list )\n",
    "\n",
    "#-- END check to see if we have a specific list of tags we want to exclude --#\n",
    "\n",
    "# include only those with certain tags.\n",
    "#tags_in_list = [ \"prelim_unit_test_001\", \"prelim_unit_test_002\", \"prelim_unit_test_003\", \"prelim_unit_test_004\", \"prelim_unit_test_005\", \"prelim_unit_test_006\", \"prelim_unit_test_007\" ]\n",
    "#tags_in_list = [ \"tdn_month\", ]\n",
    "tags_in_list = None\n",
    "if ( ( tags_in_list is not None ) and ( len( tags_in_list ) > 0 ) ):\n",
    "\n",
    "    # filter\n",
    "    print( \"filtering to just articles with tags: \" + str( tags_in_list ) )\n",
    "    tdn_article_qs = tdn_article_qs.filter( tags__name__in = tags_in_list )\n",
    "    \n",
    "#-- END check to see if we have a specific list of tags we want to include --#\n",
    "\n",
    "# filter out \"*prelim*\" tags?\n",
    "#filter_out_prelim_tags = True\n",
    "if ( filter_out_prelim_tags == True ):\n",
    "\n",
    "    # ifilter out all articles with any tag whose name contains \"prelim\".\n",
    "    print( \"filtering out articles with tags that contain \\\"prelim\\\"\" )\n",
    "    tdn_article_qs = tdn_article_qs.exclude( tags__name__icontains = \"prelim\" )\n",
    "    \n",
    "#-- END check to see if we filter out \"prelim_*\" tags --#\n",
    "\n",
    "# how many is that?\n",
    "article_count = tdn_article_qs.count()\n",
    "\n",
    "print( \"Article count after tag filtering: \" + str( article_count ) )\n",
    "\n",
    "# do we want a random sample?\n",
    "if ( random_count > 0 ):\n",
    "\n",
    "    # to get random, order them by \"?\", then use slicing to retrieve requested\n",
    "    #     number.\n",
    "    tdn_article_qs = tdn_article_qs.order_by( \"?\" )[ : random_count ]\n",
    "    \n",
    "#-- END check to see if we want random sample --#\n",
    "\n",
    "# this is a nice algorithm, also:\n",
    "# - http://www.titov.net/2005/09/21/do-not-use-order-by-rand-or-how-to-get-random-rows-from-table/\n",
    "\n",
    "# make ID list, tag articles if configured to.\n",
    "article_id_list = []\n",
    "article_counter = 0\n",
    "for current_article in tdn_article_qs:\n",
    "\n",
    "    # increment article_counter\n",
    "    article_counter += 1\n",
    "\n",
    "    # add IDs to article_id_list\n",
    "    article_id_list.append( str( current_article.id ) )\n",
    "    \n",
    "    # apply a tag while we are at it?\n",
    "    if ( ( do_apply_tag == True ) and ( tag_to_apply is not None ) and ( tag_to_apply != \"\" ) ):\n",
    "    \n",
    "        # yes, please.  Add tag.\n",
    "        current_article.tags.add( tag_to_apply )\n",
    "        \n",
    "    #-- END check to see if we apply tag. --#\n",
    "\n",
    "    # output the tags.\n",
    "    if ( debug_flag == True ):\n",
    "        print( \"- Tags for article \" + str( current_article.id ) + \" : \" + str( current_article.tags.all() ) )\n",
    "    #-- END DEBUG --#\n",
    "\n",
    "#-- END loop over articles --#\n",
    "\n",
    "# output the list.\n",
    "print( \"tdn_article_qs count: {}\".format( tdn_article_qs.count() ) )\n",
    "print( \"Found \" + str( article_counter ) + \" articles ( \" + str( article_count ) + \" ).\" )\n",
    "if ( debug_flag == True ):\n",
    "    print( \"List of \" + str( len( article_id_list ) ) + \" local TDN staff article IDs: \" + \", \".join( article_id_list ) )\n",
    "#-- END DEBUG --#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Articles\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve just publications that are tagged as being local hard news and that also are not tagged as having been coded by OpenCalaisV2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T14:22:00.947669Z",
     "start_time": "2019-08-11T14:21:30.863068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Parameters: {'start_date': None, 'end_date': None, 'tags_in_list_IN': ['local_hard_news'], 'tags_not_in_list_IN': ['coded-OpenCalaisV2ArticleCoder'], 'publications': [], 'section_list': [], 'article_id_list': [], 'coder_type': 'open_calais_api_v2'}\n",
      "After my_article_coding.create_article_query_set(), count: 0\n",
      "article_qs evaluated: NO ( None )\n",
      "Matching article count: 0\n",
      "do_coding == True - it's on!\n"
     ]
    }
   ],
   "source": [
    "# declare variables\n",
    "\n",
    "# declare variables - article filter parameters\n",
    "start_pub_date = None # should be datetime instance\n",
    "end_pub_date = None # should be datetime instance\n",
    "tags_in_list = []\n",
    "tags_not_in_list = []\n",
    "paper_id_in_list = []\n",
    "section_list = []\n",
    "article_id_in_list = []\n",
    "params = {}\n",
    "\n",
    "# declare variables - processing\n",
    "do_i_print_updates = True\n",
    "my_article_coding = None\n",
    "article_qs = None\n",
    "article_count = -1\n",
    "coding_status = \"\"\n",
    "limit_to = -1\n",
    "do_coding = True\n",
    "\n",
    "# declare variables - results\n",
    "success_count = -1\n",
    "success_list = None\n",
    "got_errors = False\n",
    "error_count = -1\n",
    "error_dictionary = None\n",
    "error_article_id = -1\n",
    "error_status_list = None\n",
    "error_status = \"\"\n",
    "error_status_counter = -1\n",
    "\n",
    "# first, get a list of articles to code.\n",
    "\n",
    "# ! Set param values.\n",
    "\n",
    "# ==> start and end dates\n",
    "#start_pub_date = \"2009-12-06\"\n",
    "#end_pub_date = \"2009-12-12\"\n",
    "\n",
    "# ==> tagged articles\n",
    "\n",
    "# Examples:\n",
    "#tag_in_list = \"prelim_reliability\"\n",
    "#tag_in_list = \"prelim_network\"\n",
    "#tag_in_list = \"prelim_unit_test_007\"\n",
    "#tag_in_list = [ \"prelim_reliability\", \"prelim_network\" ]\n",
    "#tag_in_list = [ \"prelim_reliability_test\" ] # 60 articles - Grand Rapids only.\n",
    "#tag_in_list = [ \"prelim_reliability_combined\" ] # 87 articles, Grand Rapids and Detroit.\n",
    "#tag_in_list = [ \"prelim_training_001\" ]\n",
    "#tag_in_list = [ \"grp_month\" ]\n",
    "\n",
    "# ----> include articles when these tags are present.\n",
    "#tags_in_list = None\n",
    "tags_in_list = []\n",
    "tags_in_list.append( ContextTextBase.TAG_LOCAL_HARD_NEWS )\n",
    "\n",
    "# ---> exclude articles when these tags are present.\n",
    "#tags_not_in_list = None\n",
    "tags_not_in_list = []\n",
    "tags_not_in_list.append( OpenCalaisV2ArticleCoder.TAG_CODED_BY_ME )\n",
    "\n",
    "# ==> IDs of newspapers to include.\n",
    "#paper_id_in_list = \"1\"\n",
    "\n",
    "# ==> names of sections to include.\n",
    "#section_list = \"Lakeshore,Front Page,City and Region,Business\"\n",
    "\n",
    "# ==> just limit to specific articles by ID.\n",
    "article_id_in_list = []\n",
    "#article_id_in_list = [ 360962 ]\n",
    "#article_id_in_list = [ 28598 ]\n",
    "#article_id_in_list = [ 21653, 21756 ]\n",
    "#article_id_in_list = [ 90948 ]\n",
    "#article_id_in_list = [ 21627, 21609, 21579 ]\n",
    "#article_id_in_list = [ 48778 ]\n",
    "#article_id_in_list = [ 6065 ]\n",
    "#article_id_in_list = [ 221858 ]\n",
    "#article_id_in_list = [ 23804, 22630 ]\n",
    "#article_id_in_list = [ 23804 ]\n",
    "\n",
    "# debugging exception\n",
    "#article_id_in_list.append( 402670 )\n",
    "#article_id_in_list.append( 408735 )\n",
    "\n",
    "# filter parameters\n",
    "params[ ArticleCoding.PARAM_START_DATE ] = start_pub_date\n",
    "params[ ArticleCoding.PARAM_END_DATE ] = end_pub_date\n",
    "params[ ArticleCoding.PARAM_TAGS_IN_LIST ] = tags_in_list\n",
    "params[ ArticleCoding.PARAM_TAGS_NOT_IN_LIST ] = tags_not_in_list\n",
    "params[ ArticleCoding.PARAM_PUBLICATION_LIST ] = paper_id_in_list\n",
    "params[ ArticleCoding.PARAM_SECTION_LIST ] = section_list\n",
    "params[ ArticleCoding.PARAM_ARTICLE_ID_LIST ] = article_id_in_list\n",
    "\n",
    "# set coder you want to use.\n",
    "\n",
    "# OpenCalais REST API v.2\n",
    "params[ ArticleCoding.PARAM_CODER_TYPE ] = ArticleCoding.ARTICLE_CODING_IMPL_OPEN_CALAIS_API_V2\n",
    "\n",
    "# get instance of ArticleCoding\n",
    "my_article_coding = ArticleCoding()\n",
    "my_article_coding.do_print_updates = do_i_print_updates\n",
    "\n",
    "# to adjust timing, you need to update the ArticleCoder class for your\n",
    "#     coder.  That overrides the value set here (so we respect limits\n",
    "#     if they are coded into a particular coder):\n",
    "my_article_coding.rate_limit_in_seconds = 3\n",
    "\n",
    "# set params\n",
    "my_article_coding.store_parameters( params )\n",
    "\n",
    "print( \"Query Parameters: {}\".format( params ) )\n",
    "\n",
    "# create query set - ArticleCoding does the filtering for you.\n",
    "article_qs = my_article_coding.create_article_query_set()\n",
    "\n",
    "print( \"After my_article_coding.create_article_query_set(), count: {}\".format( article_qs.count() ) )\n",
    "if ( article_qs._result_cache is None ):\n",
    "    \n",
    "    print( \"article_qs evaluated: NO ( {} )\".format( article_qs._result_cache ) )\n",
    "    \n",
    "else:\n",
    "    \n",
    "    print( \"article_qs evaluated: YES\" )\n",
    "\n",
    "#-- END check to see if _result_cache --#\n",
    "\n",
    "# order by pub_date DESC, so we do most recent first.\n",
    "article_qs = article_qs.order_by( \"-pub_date\" )\n",
    "\n",
    "# limit for an initial test?\n",
    "limit_to = 5000\n",
    "# limit_to = 5\n",
    "if ( ( limit_to is not None ) and ( isinstance( limit_to, int ) == True ) and ( limit_to > 0 ) ):\n",
    "\n",
    "    # yes.\n",
    "    article_qs = article_qs[ : limit_to ]\n",
    "\n",
    "#-- END check to see if limit --#\n",
    "\n",
    "# get article count\n",
    "if ( isinstance( article_qs, list ) == True ):\n",
    "\n",
    "    # list - call len()\n",
    "    article_list = article_qs\n",
    "    article_count = len( article_list )\n",
    "    \n",
    "else:\n",
    "\n",
    "    # not a list - call count()\n",
    "    article_count = article_qs.count()\n",
    "    \n",
    "#-- END figure out how to get count --#\n",
    "\n",
    "print( \"Matching article count: \" + str( article_count ) )\n",
    "\n",
    "# Do coding?\n",
    "if ( do_coding == True ):\n",
    "\n",
    "    print( \"do_coding == True - it's on!\" )\n",
    "\n",
    "    # yes - make sure we have at least one article:\n",
    "    if ( article_count > 0 ):\n",
    "\n",
    "        # invoke the code_article_data( self, query_set_IN ) method.\n",
    "        coding_status = my_article_coding.code_article_data( article_qs )\n",
    "    \n",
    "        # output status\n",
    "        print( \"\\n\\n==============================\\n\\nCoding status: \\\"\" + coding_status + \"\\\"\" )\n",
    "        \n",
    "        # get success count\n",
    "        success_count = my_article_coding.get_success_count()\n",
    "        print( \"\\n\\n====> Count of articles successfully processed: \" + str( success_count ) )    \n",
    "        \n",
    "        # if successes, list out IDs.\n",
    "        if ( success_count > 0 ):\n",
    "        \n",
    "            # there were successes.\n",
    "            success_list = my_article_coding.get_success_list()\n",
    "            print( \"- list of successfully processed articles: \" + str( success_list ) )\n",
    "        \n",
    "        #-- END check to see if successes. --#\n",
    "        \n",
    "        # got errors?\n",
    "        got_errors = my_article_coding.has_errors()\n",
    "        if ( got_errors == True ):\n",
    "        \n",
    "            # get error dictionary\n",
    "            error_dictionary = my_article_coding.get_error_dictionary()\n",
    "            \n",
    "            # get error count\n",
    "            error_count = len( error_dictionary )\n",
    "            print( \"\\n\\n====> Count of articles with errors: \" + str( error_count ) )\n",
    "            \n",
    "            # loop...\n",
    "            for error_article_id, error_status_list in six.iteritems( error_dictionary ):\n",
    "            \n",
    "                # output errors for this article.\n",
    "                print( \"- errors for article ID \" + str( error_article_id ) + \":\" )\n",
    "                \n",
    "                # loop over status messages.\n",
    "                error_status_counter = 0\n",
    "                for error_status in error_status_list:\n",
    "                \n",
    "                    # increment status\n",
    "                    error_status_counter += 1\n",
    "\n",
    "                    # print status\n",
    "                    print( \"----> status #\" + str( error_status_counter ) + \": \" + error_status )\n",
    "                    \n",
    "                #-- END loop over status messages. --#\n",
    "            \n",
    "            #-- END loop over articles. --#\n",
    "   \n",
    "        #-- END check to see if errors --#\n",
    "    \n",
    "    #-- END check to see if article count. --#\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # output matching article count.\n",
    "    print( \"do_coding == False, so dry run\" )\n",
    "    \n",
    "#-- END check to see if we do_coding --#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2019.07.31 - 5000 - started: execution queued 22:42:01 2019-07-31 --> executed in 3h 47m 55s, finished 02:29:55 2019-08-01\n",
    "- 2019.08.03 - 4990 - started: execution queued 00:38:05 2019-08-03 --> \n",
    "- 2019.08.04 - 5000 - started: execution queued 22:28:45 2019-08-04 --> executed in 4h 45m 21s, finished 03:14:07 2019-08-05\n",
    "- 2019.08.05 - 5000 - started: execution queued 23:04:50 2019-08-05 --> \n",
    "- 2019.08.06 - 5000 - started: execution queued 22:27:34 2019-08-06 --> executed in 5h 21m 21s, finished 03:48:55 2019-08-07\n",
    "- 2019.08.07 - 5000 - started: execution queued 00:11:32 2019-08-08 --> executed in 4h 51m 22s, finished 05:02:54 2019-08-08\n",
    "- 2019.08.08 - 5000 - started: execution queued 00:00:00 2019-08-09 --> executed in 4h 54m 50s, finished 03:04:21 2019-08-10\n",
    "- 2091.08.10 - 3819 - started: execution queued 22:09:20 2019-08-10 --> finished 02:52:51.48118 2019-08-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Validation\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T14:17:18.594154Z",
     "start_time": "2019-08-11T14:17:18.584023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-11 14:17:18.589179 - Loaded automated user: automated, id = 2\n"
     ]
    }
   ],
   "source": [
    "# get automated coder\n",
    "automated_coder_user = ArticleCoder.get_automated_coding_user()\n",
    "\n",
    "print( \"{} - Loaded automated user: {}, id = {}\".format( datetime.datetime.now(), automated_coder_user, automated_coder_user.id ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate success publications\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Loop over all successful records and verify:\n",
    "\n",
    "- that they have the OpenCalais coded-by-me tag (`OpenCalaisV2ArticleCoder.TAG_CODED_BY_ME`).\n",
    "- that they have an ArticleData for automated coding user.\n",
    "- that it isn't all just 0 sources.  Perhaps, collect and average source and subject counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T14:17:21.113686Z",
     "start_time": "2019-08-11T14:17:19.613010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====> Count of articles successfully processed: 46\n",
      "- Tagged article count: 46\n",
      "- Correct ArticleData count: 46\n",
      "- Has data count: 46\n",
      "- Has people count: 45\n",
      "- Has subjects count: 30\n",
      "- Has sources count: 45\n"
     ]
    }
   ],
   "source": [
    "# declare variables\n",
    "success_count = -1\n",
    "success_list = None\n",
    "article_id = None\n",
    "has_coded_tag = None\n",
    "has_coded_tag_counter = None\n",
    "has_article_data_counter = None\n",
    "article_instance = None\n",
    "\n",
    "# declare variables - tag validation\n",
    "tag_name_list = None\n",
    "coded_by_tag_name = None\n",
    "has_coded_by_tag = None\n",
    "\n",
    "# declare variables - ArticleData validation\n",
    "article_id_to_data_map = None\n",
    "article_data_qs = None\n",
    "article_data_count = None\n",
    "article_data_instance = None\n",
    "article_data_id = None\n",
    "automated_coder_type = None\n",
    "article_data_map = None\n",
    "article_author_qs = None\n",
    "author_count = None\n",
    "article_subject_qs = None\n",
    "subject_qs = None\n",
    "subject_count = None\n",
    "source_qs = None\n",
    "source_count = None\n",
    "has_data_count = None\n",
    "has_people_count = None\n",
    "has_subjects_count = None\n",
    "has_sources_count = None\n",
    "article_counter = None\n",
    "start_time = None\n",
    "previous_time = None\n",
    "current_time = None\n",
    "time_since_start = None\n",
    "time_since_previous = None\n",
    "\n",
    "# validation\n",
    "\n",
    "# init\n",
    "coded_by_tag_name = OpenCalaisV2ArticleCoder.TAG_CODED_BY_ME\n",
    "#automated_coder_user = ArticleCoder.get_automated_coding_user()\n",
    "automated_coder_type = OpenCalaisV2ArticleCoder.CONFIG_APPLICATION\n",
    "article_id_to_data_map = {}\n",
    "\n",
    "# get success count\n",
    "success_count = my_article_coding.get_success_count()\n",
    "log_message = \"\\n\\n====> Count of articles successfully processed: {}\".format( success_count )\n",
    "my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )\n",
    "\n",
    "# if successes, list out IDs.\n",
    "if ( success_count > 0 ):\n",
    "\n",
    "    # there were successes.\n",
    "    success_list = my_article_coding.get_success_list()\n",
    "    #print( \"- list of successfully processed articles: \" + str( success_list ) )\n",
    "    \n",
    "    # loop over success articles\n",
    "    article_counter = 0\n",
    "    has_coded_tag_counter = 0\n",
    "    has_article_data_counter = 0\n",
    "    has_data_count = 0\n",
    "    has_people_count = 0\n",
    "    has_subjects_count = 0\n",
    "    has_sources_count = 0\n",
    "    start_time = datetime.datetime.now()\n",
    "    current_time = start_time\n",
    "    for article_id in success_list:\n",
    "        \n",
    "        article_counter += 1\n",
    "        \n",
    "        # load article\n",
    "        article_instance = Article.objects.get( pk = article_id )\n",
    "        \n",
    "        # get tag name list\n",
    "        tag_name_list = article_instance.tags.names()\n",
    "        \n",
    "        # is coded-by tag name present?\n",
    "        if ( coded_by_tag_name in tag_name_list ):\n",
    "            \n",
    "            # it is there, as it should be.\n",
    "            has_coded_by_tag =  True\n",
    "            has_coded_tag_counter += 1\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # not there.  Error.\n",
    "            has_coded_by_tag = False\n",
    "            log_message = \"ERROR in article {}: coded-by tag ( {} ) not in tag list: {}\".format( article_id, coded_by_tag_name, tag_name_list )\n",
    "            my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )\n",
    "        \n",
    "        #-- END check for coded-by tag name in tag list. --#\n",
    "        \n",
    "        # is there an ArticleData instance by automated coder for OpenCalais V.2?\n",
    "        article_data_qs = article_instance.article_data_set.filter( coder = automated_coder_user )\n",
    "        article_data_qs = article_data_qs.filter( coder_type = automated_coder_type )\n",
    "        article_data_count = article_data_qs.count()\n",
    "        if ( article_data_count == 1 ):\n",
    "            \n",
    "            # got one.  Increment counter.\n",
    "            has_article_data_counter += 1\n",
    "            \n",
    "            # TODO - check how many sources, subjects.\n",
    "            article_data_instance = article_data_qs.get()\n",
    "            article_data_id = article_data_instance.id\n",
    "            \n",
    "            # create article data map\n",
    "            article_data_map = {}\n",
    "            article_data_map[ \"article_id\" ] = article_id\n",
    "            article_data_map[ \"article_instance\" ] = article_instance\n",
    "            article_data_map[ \"article_data_instance\" ] = article_data_instance\n",
    "            article_data_map[ \"article_data_id\" ] = article_data_id\n",
    "            \n",
    "            # get count of authors\n",
    "            article_author_qs = article_data_instance.article_author_set.all()\n",
    "            author_count = article_author_qs.count()\n",
    "            article_data_map[ \"author_count\" ] = author_count\n",
    "            \n",
    "            # get count of subjects\n",
    "            article_subject_qs = article_data_instance.article_subject_set.all()\n",
    "            article_subject_total_count = article_subject_qs.count()\n",
    "            article_data_map[ \"article_subject_total_count\" ] = article_subject_total_count\n",
    "            if ( article_subject_total_count > 0 ):\n",
    "                \n",
    "                has_people_count += 1\n",
    "                \n",
    "            #-- END check to see if any people found at all --#\n",
    "            \n",
    "            # just subjects\n",
    "            subject_qs = article_subject_qs.filter( subject_type = Article_Subject.SUBJECT_TYPE_MENTIONED )\n",
    "            subject_count = subject_qs.count()\n",
    "            article_data_map[ \"subject_count\" ] = subject_count\n",
    "            if ( subject_count > 0 ):\n",
    "                \n",
    "                has_subjects_count += 1\n",
    "                \n",
    "            #-- END check to see if any subjects found --#\n",
    "            \n",
    "            # get count of sources\n",
    "            source_qs = article_subject_qs.filter( subject_type = Article_Subject.SUBJECT_TYPE_QUOTED )\n",
    "            source_count = source_qs.count()\n",
    "            article_data_map[ \"source_count\" ] = source_count\n",
    "            if ( source_count > 0 ):\n",
    "                \n",
    "                has_sources_count += 1\n",
    "                \n",
    "            #-- END check to see if any sources found --#\n",
    "            \n",
    "            # store information for article.\n",
    "            article_id_to_data_map[ article_id ] = article_data_map\n",
    "            \n",
    "            if ( ( author_count == 0 ) and ( article_subject_total_count == 0 ) ):\n",
    "                \n",
    "                # get current time and time elapsed since start\n",
    "                log_message = \"No authors or sources in article {}\".format( article_id )\n",
    "                my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                # increment populated data count\n",
    "                has_data_count += 1\n",
    "                \n",
    "            #-- END sanity check for empty data (won't be zero, shouldn't be many) --#\n",
    "            \n",
    "        elif ( article_data_count > 1 ):\n",
    "            \n",
    "            # more than one?\n",
    "            log_message = \"ERROR in article {}: more than one ArticleData instance ( {} ) for automated coder ( {} ), coder type: {}.\".format( article_id, article_data_count, automated_coder_user, automated_coder_type )\n",
    "            my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # error - no ArticleData.\n",
    "            log_message = \"ERROR in article {}: no ArticleData instances for automated coder ( {} ), coder type: {}.\".format( article_id, automated_coder_user, automated_coder_type )\n",
    "            my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )\n",
    "            \n",
    "        #-- END check to see if ArticleData by automated coder, Open Calais v.2 --#\n",
    "        \n",
    "        # progress output\n",
    "        if ( ( article_counter % 100 ) == 0 ):\n",
    "            \n",
    "            log_message = \"----> article counter: {}\".format( article_counter )\n",
    "            my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )\n",
    "            \n",
    "            # get current time and time elapsed since start\n",
    "            previous_time = current_time\n",
    "            current_time = datetime.datetime.now()\n",
    "            time_since_start = current_time - start_time\n",
    "            time_since_previous = current_time - previous_time\n",
    "            log_message = \"         @ {} - time since previous: {}; time since start: {}\".format( current_time, time_since_previous, time_since_start )\n",
    "            my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )\n",
    "\n",
    "        #-- END progress output. --#\n",
    "        \n",
    "    #-- END loop over IDs of sucessfully processed articles. --#\n",
    "\n",
    "#-- END check to see if successes. --#\n",
    "        \n",
    "log_message = \"- Tagged article count: {}\".format( has_coded_tag_counter )\n",
    "my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )\n",
    "log_message = \"- Correct ArticleData count: {}\".format( has_article_data_counter )\n",
    "my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )\n",
    "log_message = \"- Has data count: {}\".format( has_data_count )\n",
    "my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )\n",
    "log_message = \"- Has people count: {}\".format( has_people_count )\n",
    "my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )\n",
    "log_message = \"- Has subjects count: {}\".format( has_subjects_count )\n",
    "my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )\n",
    "log_message = \"- Has sources count: {}\".format( has_sources_count )\n",
    "my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate error publications\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Loop over all error records and verify:\n",
    "\n",
    "- that they do not have the OpenCalais coded-by-me tag (`OpenCalaisV2ArticleCoder.TAG_CODED_BY_ME`).\n",
    "- check on the status of their ArticleData.  Do they have any?  If so, what to do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T14:17:29.032548Z",
     "start_time": "2019-08-11T14:17:28.968994Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO ERRORS!  YAY!\n"
     ]
    }
   ],
   "source": [
    "# declare variables\n",
    "got_errors = None\n",
    "error_dictionary = None\n",
    "error_count = None\n",
    "error_article_id = None\n",
    "error_status_list = None\n",
    "error_status_counter = None\n",
    "article_instance = None\n",
    "tag_name_list = None\n",
    "coded_by_tag_name = None\n",
    "has_coded_by_tag = None\n",
    "\n",
    "# declare variables - ArticleData validation\n",
    "error_article_id_to_data_map = None\n",
    "article_data_qs = None\n",
    "article_data_count = None\n",
    "article_data_instance = None\n",
    "article_data_id = None\n",
    "automated_coder_type = None\n",
    "article_data_map = None\n",
    "article_author_qs = None\n",
    "author_count = None\n",
    "article_subject_qs = None\n",
    "subject_qs = None\n",
    "subject_count = None\n",
    "source_qs = None\n",
    "source_count = None\n",
    "has_data_count = None\n",
    "has_people_count = None\n",
    "has_subjects_count = None\n",
    "has_sources_count = None\n",
    "\n",
    "# init\n",
    "coded_by_tag_name = OpenCalaisV2ArticleCoder.TAG_CODED_BY_ME\n",
    "#automated_coder_user = ArticleCoder.get_automated_coding_user()\n",
    "automated_coder_type = OpenCalaisV2ArticleCoder.CONFIG_APPLICATION\n",
    "error_article_id_to_data_map = {}\n",
    "\n",
    "# got errors?\n",
    "got_errors = my_article_coding.has_errors()\n",
    "if ( got_errors == True ):\n",
    "\n",
    "    # get error dictionary\n",
    "    error_dictionary = my_article_coding.get_error_dictionary()\n",
    "\n",
    "    # get error count\n",
    "    error_count = len( error_dictionary )\n",
    "    log_message = \"\\n\\n====> Count of articles with errors: {}\".format( error_count )\n",
    "    my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )\n",
    "\n",
    "    # loop...\n",
    "    has_coded_tag_counter = 0\n",
    "    has_article_data_counter = 0\n",
    "    has_data_count = 0\n",
    "    has_people_count = 0\n",
    "    has_subjects_count = 0\n",
    "    has_sources_count = 0\n",
    "    for error_article_id, error_status_list in six.iteritems( error_dictionary ):\n",
    "\n",
    "        log_message = \"\\nError article ID: {}\".format( error_article_id )\n",
    "        my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )\n",
    "\n",
    "        # output errors for this article.\n",
    "        log_message = \"- errors for article ID {}:\".format( error_article_id )\n",
    "        my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )\n",
    "\n",
    "        # loop over status messages.\n",
    "        error_status_counter = 0\n",
    "        for error_status in error_status_list:\n",
    "\n",
    "            # increment status\n",
    "            error_status_counter += 1\n",
    "\n",
    "            # print status\n",
    "            log_message = \"----> status #{}: {}\".format( error_status_counter, error_status )\n",
    "            my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )\n",
    "            \n",
    "        #-- END loop over status messages. --#\n",
    "\n",
    "        # load article\n",
    "        article_instance = Article.objects.get( pk = error_article_id )\n",
    "        \n",
    "        # get tag name list\n",
    "        tag_name_list = article_instance.tags.names()\n",
    "        \n",
    "        # is coded-by tag name present?\n",
    "        if ( coded_by_tag_name in tag_name_list ):\n",
    "            \n",
    "            # it is there, as it should be.\n",
    "            has_coded_by_tag =  True\n",
    "            has_coded_tag_counter += 1\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # not there.  Error.\n",
    "            has_coded_by_tag = False\n",
    "            #print( \"ERROR in article {}: coded-by tag ( {} ) not in tag list: {}\".format( error_article_id, coded_by_tag_name, tag_name_list ) )\n",
    "        \n",
    "        #-- END check for coded-by tag name in tag list. --#\n",
    "        \n",
    "        # is there an ArticleData instance by automated coder for OpenCalais V.2?\n",
    "        article_data_qs = article_instance.article_data_set.filter( coder = automated_coder_user )\n",
    "        article_data_qs = article_data_qs.filter( coder_type = automated_coder_type )\n",
    "        article_data_count = article_data_qs.count()\n",
    "        if ( article_data_count == 1 ):\n",
    "            \n",
    "            # got one.  Increment counter.\n",
    "            has_article_data_counter += 1\n",
    "            \n",
    "            # TODO - check how many sources, subjects.\n",
    "            article_data_instance = article_data_qs.get()\n",
    "            article_data_id = article_data_instance.id\n",
    "            \n",
    "            # create article data map\n",
    "            article_data_map = {}\n",
    "            article_data_map[ \"article_id\" ] = error_article_id\n",
    "            article_data_map[ \"article_instance\" ] = article_instance\n",
    "            article_data_map[ \"article_data_instance\" ] = article_data_instance\n",
    "            article_data_map[ \"article_data_id\" ] = article_data_id\n",
    "            \n",
    "            # get count of authors\n",
    "            article_author_qs = article_data_instance.article_author_set.all()\n",
    "            author_count = article_author_qs.count()\n",
    "            article_data_map[ \"author_count\" ] = author_count\n",
    "            \n",
    "            # get count of subjects\n",
    "            article_subject_qs = article_data_instance.article_subject_set.all()\n",
    "            article_subject_total_count = article_subject_qs.count()\n",
    "            article_data_map[ \"article_subject_total_count\" ] = article_subject_total_count\n",
    "            if ( article_subject_total_count > 0 ):\n",
    "                \n",
    "                has_people_count += 1\n",
    "                \n",
    "            #-- END check to see if any people found at all --#\n",
    "            \n",
    "            # just subjects\n",
    "            subject_qs = article_subject_qs.filter( subject_type = Article_Subject.SUBJECT_TYPE_MENTIONED )\n",
    "            subject_count = subject_qs.count()\n",
    "            article_data_map[ \"subject_count\" ] = subject_count\n",
    "            if ( subject_count > 0 ):\n",
    "                \n",
    "                has_subjects_count += 1\n",
    "                \n",
    "            #-- END check to see if any subjects found --#\n",
    "            \n",
    "            # get count of sources\n",
    "            source_qs = article_subject_qs.filter( subject_type = Article_Subject.SUBJECT_TYPE_QUOTED )\n",
    "            source_count = source_qs.count()\n",
    "            article_data_map[ \"source_count\" ] = source_count\n",
    "            if ( source_count > 0 ):\n",
    "                \n",
    "                has_sources_count += 1\n",
    "                \n",
    "            #-- END check to see if any sources found --#\n",
    "            \n",
    "            # store information for article.\n",
    "            error_article_id_to_data_map[ error_article_id ] = article_data_map\n",
    "            \n",
    "            if ( ( author_count == 0 ) and ( article_subject_total_count == 0 ) ):\n",
    "                \n",
    "                pass\n",
    "                #print( \"- No authors or sources in article {}\".format( error_article_id ) )\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                # increment populated data count\n",
    "                has_data_count += 1\n",
    "                log_message = \"- Found data in article {}: person = {}; subject = {}; source = {}\".format( error_article_id, article_subject_total_count, subject_count, source_count )\n",
    "                my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )\n",
    "                \n",
    "            #-- END sanity check for empty data (won't be zero, shouldn't be many) --#\n",
    "            \n",
    "        elif ( article_data_count > 1 ):\n",
    "            \n",
    "            # more than one?\n",
    "            log_message = \"ERROR in article {}: more than one ArticleData instance ( {} ) for automated coder ( {} ), coder type: {}.\".format( error_article_id, article_data_count, automated_coder_user, automated_coder_type )\n",
    "            my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # no ArticleData.\n",
    "            pass\n",
    "            \n",
    "        #-- END check to see if ArticleData by automated coder, Open Calais v.2 --#\n",
    "\n",
    "    #-- END loop over articles. --#\n",
    "\n",
    "    log_message = \"- Tagged article count: {}\".format( has_coded_tag_counter )\n",
    "    my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )\n",
    "    log_message = \"- Correct ArticleData count: {}\".format( has_article_data_counter )\n",
    "    my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )\n",
    "    log_message = \"- Has data count: {}\".format( has_data_count )\n",
    "    my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )\n",
    "    log_message = \"- Has people count: {}\".format( has_people_count )\n",
    "    my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )\n",
    "    log_message = \"- Has subjects count: {}\".format( has_subjects_count )\n",
    "    my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )\n",
    "    log_message = \"- Has sources count: {}\".format( has_sources_count )\n",
    "    my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )\n",
    "    \n",
    "else:\n",
    "\n",
    "    log_message = \"NO ERRORS!  YAY!\"\n",
    "    my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )\n",
    "    \n",
    "#-- END check to see if errors --#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Looks like publications where there is an OpenCalais network error are not getting the Coded tag applied, so they will remain in the pool to be re-coded in subsequent runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T14:17:34.563937Z",
     "start_time": "2019-08-11T14:17:34.547460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STILL NO ERRORS!  YAY!\n"
     ]
    }
   ],
   "source": [
    "# get list of error IDs from map.\n",
    "if ( error_dictionary is not None ):\n",
    "\n",
    "    error_article_id_list = list( six.viewkeys( error_dictionary ) )\n",
    "    log_message = \"IDs of articles with errors: {}\".format( error_article_id_list )\n",
    "    my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )\n",
    "    \n",
    "else:\n",
    "\n",
    "    log_message = \"STILL NO ERRORS!  YAY!\"\n",
    "    my_logging_helper.output_message( log_message, do_print_IN = True, log_level_code_IN = logging.INFO )\n",
    "    \n",
    "#-- END check to see if None --#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "TODO:\n",
    "\n",
    "- make sure that I am including author-to-author based on shared byline (different tie type).\n",
    "- figure out the naive date-time error in coding.\n",
    "- test change to rate limiting values being in static variables in OpenCalaisv.2 coder.\n",
    "- start loading data from XML\n",
    "- move data from Article_Data into context.\n",
    "- make the network data creator work against context, then generalize it for tie and node types.\n",
    "- think how we specify which class to use for author strings - needs to be speced to an interface, but not just a newsbank one - so, abstraction here should be higher up - in shared?\n",
    "\n",
    "DONE:\n",
    "\n",
    "- // Save log of coding first 4990 of next round of data.\n",
    "- // for next round of coding, sort on publication date, descending, so we fill in the year before and after the layoffs first.\n",
    "- // adjust django logging to output DEBUG, then test Article.filter_articles() to see where QuerySet is evaluated (DISTINCT check?).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_virtualenv",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
