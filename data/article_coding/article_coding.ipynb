{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Setup---Debug\" data-toc-modified-id=\"Setup---Debug-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Setup - Debug</a></span></li><li><span><a href=\"#Setup---Imports\" data-toc-modified-id=\"Setup---Imports-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Setup - Imports</a></span></li><li><span><a href=\"#Setup---logging\" data-toc-modified-id=\"Setup---logging-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Setup - logging</a></span></li><li><span><a href=\"#Setup---virtualenv-jupyter-kernel\" data-toc-modified-id=\"Setup---virtualenv-jupyter-kernel-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Setup - virtualenv jupyter kernel</a></span></li><li><span><a href=\"#Setup---Initialize-Django\" data-toc-modified-id=\"Setup---Initialize-Django-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Setup - Initialize Django</a></span></li></ul></li><li><span><a href=\"#Find-articles-to-be-coded\" data-toc-modified-id=\"Find-articles-to-be-coded-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Find articles to be coded</a></span><ul class=\"toc-item\"><li><span><a href=\"#which-articles-have-already-been-coded?\" data-toc-modified-id=\"which-articles-have-already-been-coded?-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>which articles have already been coded?</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tag-the-coded-articles\" data-toc-modified-id=\"Tag-the-coded-articles-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Tag the coded articles</a></span></li><li><span><a href=\"#Profile-the-coded-articles\" data-toc-modified-id=\"Profile-the-coded-articles-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Profile the coded articles</a></span></li></ul></li><li><span><a href=\"#tag-all-local-news\" data-toc-modified-id=\"tag-all-local-news-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>tag all local news</a></span><ul class=\"toc-item\"><li><span><a href=\"#TODO\" data-toc-modified-id=\"TODO-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>TODO</a></span><ul class=\"toc-item\"><li><span><a href=\"#DONE\" data-toc-modified-id=\"DONE-3.2.1.1\"><span class=\"toc-item-num\">3.2.1.1&nbsp;&nbsp;</span>DONE</a></span></li></ul></li><li><span><a href=\"#Grand-Rapids-Press-local-news\" data-toc-modified-id=\"Grand-Rapids-Press-local-news-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Grand Rapids Press local news</a></span></li><li><span><a href=\"#Detroit-News-local-news\" data-toc-modified-id=\"Detroit-News-local-news-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Detroit News local news</a></span></li></ul></li></ul></li><li><span><a href=\"#Code-Articles\" data-toc-modified-id=\"Code-Articles-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Code Articles</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "This is a notebook that expands on the OpenCalais code in the file `article_coding.py`, also in this folder.  It includes more sections on selecting publications you want to submit to OpenCalais as an example.  It is intended to be copied and re-used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Debug\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T02:27:18.500033Z",
     "start_time": "2019-08-01T02:27:18.494807Z"
    }
   },
   "outputs": [],
   "source": [
    "debug_flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Imports\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-01T02:59:42.979Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from django.db.models import Avg, Max, Min\n",
    "import logging\n",
    "import six"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - logging\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "configure logging for this notebook's kernel (If you do not run this cell, you'll get the django application's logging configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-01T02:59:44.403Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level = logging.DEBUG,\n",
    "    format = '%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
    "    filename = '/home/jonathanmorgan/logs/django-research.log',\n",
    "    filemode = 'w' # set to 'a' if you want to append, rather than overwrite each time.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - virtualenv jupyter kernel\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "If you are using a virtualenv, make sure that you:\n",
    "\n",
    "- have installed your virtualenv as a kernel.\n",
    "- choose the kernel for your virtualenv as the kernel for your notebook (Kernel --> Change kernel).\n",
    "\n",
    "Since I use a virtualenv, need to get that activated somehow inside this notebook.  One option is to run `../dev/wsgi.py` in this notebook, to configure the python environment manually as if you had activated the `sourcenet` virtualenv.  To do this, you'd make a code cell that contains:\n",
    "\n",
    "    %run ../dev/wsgi.py\n",
    "    \n",
    "This is sketchy, however, because of the changes it makes to your Python environment within the context of whatever your current kernel is.  I'd worry about collisions with the actual Python 3 kernel.  Better, one can install their virtualenv as a separate kernel.  Steps:\n",
    "\n",
    "- activate your virtualenv:\n",
    "\n",
    "        workon research\n",
    "\n",
    "- in your virtualenv, install the package `ipykernel`.\n",
    "\n",
    "        pip install ipykernel\n",
    "\n",
    "- use the ipykernel python program to install the current environment as a kernel:\n",
    "\n",
    "        python -m ipykernel install --user --name <env_name> --display-name \"<display_name>\"\n",
    "        \n",
    "    `sourcenet` example:\n",
    "    \n",
    "        python -m ipykernel install --user --name sourcenet --display-name \"research (Python 3)\"\n",
    "        \n",
    "More details: [http://ipython.readthedocs.io/en/stable/install/kernel_install.html](http://ipython.readthedocs.io/en/stable/install/kernel_install.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Initialize Django\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "First, initialize my dev django project, so I can run code in this notebook that references my django models and can talk to the database using my project's settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T02:27:22.229445Z",
     "start_time": "2019-08-01T02:27:22.222840Z"
    }
   },
   "outputs": [],
   "source": [
    "# init django\n",
    "django_init_folder = \"/home/jonathanmorgan/work/django/research/research/work/phd_work\"\n",
    "django_init_path = \"django_init.py\"\n",
    "if( ( django_init_folder is not None ) and ( django_init_folder != \"\" ) ):\n",
    "    \n",
    "    # add folder to front of path.\n",
    "    django_init_path = \"{}/{}\".format( django_init_folder, django_init_path )\n",
    "    \n",
    "#-- END check to see if django_init folder. --#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T02:27:25.969194Z",
     "start_time": "2019-08-01T02:27:23.034994Z"
    }
   },
   "outputs": [],
   "source": [
    "%run $django_init_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T02:27:27.049878Z",
     "start_time": "2019-08-01T02:27:26.664894Z"
    }
   },
   "outputs": [],
   "source": [
    "# context_text imports\n",
    "from context_text.article_coding.article_coding import ArticleCoder\n",
    "from context_text.article_coding.article_coding import ArticleCoding\n",
    "from context_text.article_coding.open_calais_v2.open_calais_v2_article_coder import OpenCalaisV2ArticleCoder\n",
    "from context_text.collectors.newsbank.newspapers.GRPB import GRPB\n",
    "from context_text.collectors.newsbank.newspapers.DTNB import DTNB\n",
    "from context_text.models import Article\n",
    "from context_text.models import Newspaper\n",
    "from context_text.shared.context_text_base import ContextTextBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find articles to be coded\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Tag all locally implemented hard news articles in database and all that have already been coded using Open Calais V2, then work through using OpenCalais to code all local hard news that hasn't alredy been coded, starting with those proximal to the coding sample for methods paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## which articles have already been coded?\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "More precisely, find all articles that have Article_Data coded by the automated coder with type \"OpenCalais_REST_API_v2\" and tag the articles as \"coded-open_calais_v2\" or something like that.\n",
    "\n",
    "Then, for articles without that tag, use our criteria for local hard news to filter out and tag publications in the year before and after the month used to evaluate the automated coder, in both the Grand Rapids Press and the Detroit News, so I can look at longer time frames, then code all articles currently in database.\n",
    "\n",
    "Eventually, then, we'll code and examine before and after layoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T19:39:36.559547Z",
     "start_time": "2019-07-31T19:39:36.540657Z"
    }
   },
   "outputs": [],
   "source": [
    "# look for publications that have article data:\n",
    "# - coded by automated coder\n",
    "# - with coder type of \"OpenCalais_REST_API_v2\"\n",
    "\n",
    "# get automated coder\n",
    "automated_coder_user = ArticleCoder.get_automated_coding_user()\n",
    "\n",
    "print( \"{} - Loaded automated user: {}, id = {}\".format( datetime.datetime.now(), automated_coder_user, automated_coder_user.id ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T19:39:39.564585Z",
     "start_time": "2019-07-31T19:39:39.556701Z"
    }
   },
   "outputs": [],
   "source": [
    "# try aggregates\n",
    "article_qs = Article.objects.all()\n",
    "pub_date_info = article_qs.aggregate( Max( 'pub_date' ), Min( 'pub_date' ) )\n",
    "print( pub_date_info )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T19:39:44.158047Z",
     "start_time": "2019-07-31T19:39:44.139831Z"
    }
   },
   "outputs": [],
   "source": [
    "# find articles with Article_Data created by the automated user...\n",
    "article_qs = Article.objects.filter( article_data__coder = automated_coder_user )\n",
    "\n",
    "# ...and specifically coded using OpenCalais V2...\n",
    "article_qs = article_qs.filter( article_data__coder_type = OpenCalaisV2ArticleCoder.CONFIG_APPLICATION )\n",
    "\n",
    "# ...and finally, we just want the distinct articles by ID.\n",
    "article_qs = article_qs.order_by( \"id\" ).distinct( \"id\" )\n",
    "\n",
    "# count?\n",
    "article_count = article_qs.count()\n",
    "print( \"Found {} articles\".format( article_count ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag the coded articles\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Removing duplicates present from joining with Article_Data yields 579 articles that were coded by the automated coder.\n",
    "\n",
    "Tag all the coded articles with `OpenCalaisV2ArticleCoder.TAG_CODED_BY_ME`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T19:40:04.298910Z",
     "start_time": "2019-07-31T19:40:03.244803Z"
    }
   },
   "outputs": [],
   "source": [
    "# declare variables\n",
    "current_article = None\n",
    "tag_name_list = None\n",
    "article_count = None\n",
    "untagged_count = None\n",
    "already_tagged_count = None\n",
    "newly_tagged_count = None\n",
    "count_sum = None\n",
    "do_add_tag = False\n",
    "\n",
    "# init\n",
    "do_add_tag = False\n",
    "\n",
    "# get article_count\n",
    "article_count = article_qs.count()\n",
    "\n",
    "# loop over articles.\n",
    "untagged_count = 0\n",
    "already_tagged_count = 0\n",
    "newly_tagged_count = 0\n",
    "for current_article in article_qs:\n",
    "    \n",
    "    # get list of tags for this publication\n",
    "    tag_name_list = current_article.tags.names()\n",
    "    \n",
    "    # is the coded tag in the list?\n",
    "    if ( OpenCalaisV2ArticleCoder.TAG_CODED_BY_ME not in tag_name_list ):\n",
    "        \n",
    "        # are we adding tag?\n",
    "        if ( do_add_tag == True ):\n",
    "\n",
    "            # add tag.\n",
    "            current_article.tags.add( OpenCalaisV2ArticleCoder.TAG_CODED_BY_ME )\n",
    "            newly_tagged_count += 1\n",
    "            \n",
    "        else:\n",
    "\n",
    "            # for now, increment untagged count\n",
    "            untagged_count += 1\n",
    "            \n",
    "        #-- END check to see if we are adding tag. --#\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # already tagged\n",
    "        already_tagged_count += 1\n",
    "        \n",
    "    #-- END check to see if coded tag is set --#\n",
    "    \n",
    "#-- END loop over articles. --#\n",
    "\n",
    "print( \"Article counts:\" )\n",
    "print( \"- total articles: {}\".format( article_count ) )\n",
    "print( \"- untagged articles: {}\".format( untagged_count ) )\n",
    "print( \"- already tagged: {}\".format( already_tagged_count ) )\n",
    "print( \"- newly tagged: {}\".format( newly_tagged_count ) )\n",
    "count_sum = untagged_count + already_tagged_count + newly_tagged_count\n",
    "print( \"- count sum: {}\".format( count_sum ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profile the coded articles\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Look at range of pub dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T02:27:38.974747Z",
     "start_time": "2019-08-01T02:27:38.540072Z"
    }
   },
   "outputs": [],
   "source": [
    "tags_in_list = []\n",
    "tags_in_list.append( OpenCalaisV2ArticleCoder.TAG_CODED_BY_ME )\n",
    "article_qs = Article.objects.filter( tags__name__in = tags_in_list )\n",
    "print( \"Matching article count: {}\".format( article_qs.count() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Original: 579\n",
    "- after coding 10: 589 (tag is being set correctly bu Open Calais V2 coder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T17:49:07.328924Z",
     "start_time": "2019-07-31T17:49:07.275399Z"
    }
   },
   "outputs": [],
   "source": [
    "# profile these publications\n",
    "min_pub_date = None\n",
    "max_pub_date = None\n",
    "current_pub_date = None\n",
    "pub_date_count = None\n",
    "date_to_count_map = {}\n",
    "date_to_articles_map = {}\n",
    "pub_date_article_dict = None\n",
    "\n",
    "# try aggregates\n",
    "pub_date_info = article_qs.aggregate( Max( 'pub_date' ), Min( 'pub_date' ) )\n",
    "print( pub_date_info )\n",
    "\n",
    "# counts of pubs by date\n",
    "for current_article in article_qs:\n",
    "    \n",
    "    # get pub_date\n",
    "    current_pub_date = current_article.pub_date\n",
    "    current_article_id = current_article.id\n",
    "    \n",
    "    # get count, increment, and store.\n",
    "    pub_date_count = date_to_count_map.get( current_pub_date, 0 )\n",
    "    pub_date_count += 1\n",
    "    date_to_count_map[ current_pub_date ] = pub_date_count\n",
    "    \n",
    "    # also, store up ids and instances\n",
    "    \n",
    "    # get dict of article ids to article instances for date\n",
    "    pub_date_article_dict = date_to_articles_map.get( current_pub_date, {} )\n",
    "    \n",
    "    # article already there?\n",
    "    if ( current_article_id not in pub_date_article_dict ):\n",
    "        \n",
    "        # no - add it.\n",
    "        pub_date_article_dict[ current_article_id ] = current_article\n",
    "        \n",
    "    #-- END check to see if article already there.\n",
    "    \n",
    "    # put dict back.\n",
    "    date_to_articles_map[ current_pub_date ] = pub_date_article_dict\n",
    "    \n",
    "#-- END loop over articles. --#\n",
    "\n",
    "# output dates and counts.\n",
    "\n",
    "# get list of keys from map\n",
    "keys_list = list( six.viewkeys( date_to_count_map ) )\n",
    "keys_list.sort()\n",
    "for current_pub_date in keys_list:\n",
    "    \n",
    "    # get count\n",
    "    pub_date_count = date_to_count_map.get( current_pub_date, 0 )\n",
    "    print( \"- {} ( {} ) count: {}\".format( current_pub_date, type( current_pub_date ), pub_date_count ) )\n",
    "    \n",
    "#-- END loop over dates --#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T17:49:13.567482Z",
     "start_time": "2019-07-31T17:49:13.535813Z"
    }
   },
   "outputs": [],
   "source": [
    "# look at the 2010-07-31 date\n",
    "pub_date = datetime.datetime.strptime( \"2010-07-31\", \"%Y-%m-%d\" ).date()\n",
    "articles_for_date = date_to_articles_map.get( pub_date, {} )\n",
    "print( articles_for_date )\n",
    "\n",
    "# get the article and look at its tags.\n",
    "article_instance = articles_for_date.get( 6065 )\n",
    "print( article_instance.tags.all() )\n",
    "\n",
    "# loop over associated Article_Data instances.\n",
    "for article_data in article_instance.article_data_set.all():\n",
    "    \n",
    "    print( article_data )\n",
    "    \n",
    "#-- END loop over associated Article_Data instances --#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tag all local news\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Definition of local hard news by in-house implementor for Grand Rapids Press and Detroit News follow.  For each, tag all articles in database that match as \"local_hard_news\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "TODO:\n",
    "\n",
    "- make class for GRPB at NewsBank.\n",
    "\n",
    "    - also, pull the things that are newspaper specific out of ArticleCoder.py and into the GRPB.py class.\n",
    "\n",
    "- think how we specify which class to use for author strings - needs to be speced to an interface, but not just a newsbank one - so, abstraction here should be higher up - in shared?\n",
    "- refine \"local news\" and \"locally created\" regular expressions for Grand Rapids Press based on contents of `author_string` and `author_affiliation`.\n",
    "- do the same for TDN.\n",
    "- then, use the updated classes and definitions below to flag all local hard news in database for each publication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DONE\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "DONE:\n",
    "\n",
    "- abstract out shared stuff from GRPB.py and DTNB.py into abstract parent class context_text/collectors/newsbank/newspapers/newsbank_newspaper.py\n",
    "\n",
    "    - update DTNB.py to use the parent class.\n",
    "    \n",
    "- make class for GRPB at NewsBank.\n",
    "\n",
    "    - context_text/collectors/newsbank/newspapers/GRPB.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grand Rapids Press local news\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Grand Rapids Press local hard news:\n",
    "\n",
    "- `context_text/examples/articles/articles-GRP-local_news.py`\n",
    "- local hard news sections (stored in `Article.GRP_NEWS_SECTION_NAME_LIST`):\n",
    "\n",
    "    - \"Business\"\n",
    "    - \"City and Region\"\n",
    "    - \"Front Page\"\n",
    "    - \"Lakeshore\"\n",
    "    - \"Religion\"\n",
    "    - \"Special\"\n",
    "    - \"State\"\n",
    "\n",
    "- in-house implementor (based on byline patterns, stored in `sourcenet.models.Article.Q_GRP_IN_HOUSE_AUTHOR`):\n",
    "\n",
    "    - Byline ends in \"/ THE GRAND RAPIDS PRESS\", ignore case.\n",
    "\n",
    "        - `Q( author_varchar__iregex = r'.* */ *THE GRAND RAPIDS PRESS$'`\n",
    "\n",
    "    - Byline ends in \"/ PRESS * EDITOR\", ignore case.\n",
    "\n",
    "        - `Q( author_varchar__iregex = r'.* */ *PRESS .* EDITOR$' )`\n",
    "\n",
    "    - Byline ends in \"/ GRAND RAPIDS PRESS * BUREAU\", ignore case.\n",
    "\n",
    "        - `Q( author_varchar__iregex = r'.* */ *GRAND RAPIDS PRESS .* BUREAU$' )`\n",
    "\n",
    "    - Byline ends in \"/ SPECIAL TO THE PRESS\", ignore case.\n",
    "\n",
    "        - `Q( author_varchar__iregex = r'.* */ *SPECIAL TO THE PRESS$' )`\n",
    "        \n",
    "- can also exclude columns (I will not):\n",
    "\n",
    "        grp_article_qs = grp_article_qs.exclude( index_terms__icontains = \"Column\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to work to further refine this.\n",
    "\n",
    "Looking at affiliation strings:\n",
    "\n",
    "    SELECT author_affiliation, COUNT( author_affiliation ) as affiliation_count\n",
    "    FROM context_text_article\n",
    "    WHERE newspaper_id = 1\n",
    "    GROUP BY author_affiliation\n",
    "    ORDER BY COUNT( author_affiliation ) DESC;\n",
    "    \n",
    "And at author strings for collective bylines:\n",
    "\n",
    "    SELECT author_string, COUNT( author_string ) as author_count\n",
    "    FROM context_text_article\n",
    "    WHERE newspaper_id = 1\n",
    "    GROUP BY author_string\n",
    "    ORDER BY COUNT( author_string ) DESC\n",
    "    LIMIT 10;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T18:37:55.617849Z",
     "start_time": "2019-07-31T18:37:34.091526Z"
    }
   },
   "outputs": [],
   "source": [
    "# filter queryset to just locally created Grand Rapids Press (GRP) articles.\n",
    "# imports\n",
    "from context_text.models import Article\n",
    "from context_text.models import Newspaper\n",
    "from context_text.shared.context_text_base import ContextTextBase\n",
    "from context_text.collectors.newsbank.newspapers.GRPB import GRPB\n",
    "\n",
    "# declare variables - Grand Rapids Press\n",
    "do_apply_tag = False\n",
    "tag_to_apply = None\n",
    "grp_local_news_sections = []\n",
    "grp_newspaper = None\n",
    "grp_article_qs = None\n",
    "article_count = -1\n",
    "\n",
    "# declare variables - filtering\n",
    "include_opinion_columns = True\n",
    "tags_in_list = []\n",
    "tags_not_in_list = []\n",
    "filter_out_prelim_tags = False\n",
    "random_count = -1\n",
    "\n",
    "# declare variables - make list of article IDs from QS.\n",
    "article_id_list = []\n",
    "article_counter = -1\n",
    "current_article = None\n",
    "article_tag_name_list = None\n",
    "article_update_counter = -1\n",
    "\n",
    "# ==> configure\n",
    "\n",
    "# configure - size of random sample we want\n",
    "#random_count = 60\n",
    "\n",
    "# configure - also, apply tag?\n",
    "do_apply_tag = True\n",
    "tag_to_apply = ContextTextBase.TAG_LOCAL_HARD_NEWS\n",
    "\n",
    "# set up \"local, regional and state news\" sections\n",
    "grp_local_news_sections = GRPB.LOCAL_NEWS_SECTION_NAME_LIST\n",
    "\n",
    "# Grand Rapids Press\n",
    "# get newspaper instance for GRP.\n",
    "grp_newspaper = Newspaper.objects.get( id = GRPB.NEWSPAPER_ID )\n",
    "\n",
    "# start with all articles\n",
    "#grp_article_qs = Article.objects.all()\n",
    "\n",
    "# ==> filter to newspaper, local news section list, and in-house reporters.\n",
    "\n",
    "# ----> manually\n",
    "\n",
    "# now, need to find local news articles to test on.\n",
    "#grp_article_qs = grp_article_qs.filter( newspaper = grp_newspaper )\n",
    "\n",
    "# only the locally implemented sections\n",
    "#grp_article_qs = grp_article_qs.filter( section__in = grp_local_news_sections )\n",
    "\n",
    "# and, with an in-house author\n",
    "#grp_article_qs = grp_article_qs.filter( Article.Q_GRP_IN_HOUSE_AUTHOR )\n",
    "\n",
    "#print( \"manual filter count: {}\".format( grp_article_qs.count() ) )\n",
    "\n",
    "# ----> using Article.filter_articles()\n",
    "grp_article_qs = Article.filter_articles( qs_IN = grp_article_qs,\n",
    "                                          newspaper = grp_newspaper,\n",
    "                                          section_name_list = grp_local_news_sections,\n",
    "                                          custom_article_q = GRPB.Q_IN_HOUSE_AUTHOR )\n",
    "\n",
    "print( \"Article.filter_articles count: {}\".format( grp_article_qs.count() ) )\n",
    "\n",
    "# and include opinion columns?\n",
    "if ( include_opinion_columns == False ):\n",
    "    \n",
    "    # do not include columns\n",
    "    grp_article_qs = grp_article_qs.exclude( index_terms__icontains = \"Column\" )\n",
    "    \n",
    "#-- END check to see if we include columns. --#\n",
    "\n",
    "'''\n",
    "# filter to newspaper, section list, and in-house reporters.\n",
    "grp_article_qs = Article.filter_articles( qs_IN = grp_article_qs,\n",
    "                                          start_date = \"2009-12-01\",\n",
    "                                          end_date = \"2009-12-31\",\n",
    "                                          newspaper = grp_newspaper,\n",
    "                                          section_name_list = grp_local_news_sections,\n",
    "                                          custom_article_q = Article.Q_GRP_IN_HOUSE_AUTHOR )\n",
    "'''\n",
    "\n",
    "# how many is that?\n",
    "article_count = grp_article_qs.count()\n",
    "\n",
    "print( \"Article count before filtering on tags: \" + str( article_count ) )\n",
    "\n",
    "# ==> tags\n",
    "\n",
    "# tags to exclude\n",
    "tags_not_in_list = []\n",
    "\n",
    "# Example: prelim-related tags\n",
    "#tags_not_in_list.append( \"prelim_reliability\" )\n",
    "#tags_not_in_list.append( \"prelim_network\" ]\n",
    "#tags_not_in_list.append( \"minnesota1-20160328\" )\n",
    "#tags_not_in_list.append( \"minnesota2-20160328\" )\n",
    "\n",
    "# for later - exclude articles already coded.\n",
    "tags_not_in_list.append( OpenCalaisV2ArticleCoder.TAG_CODED_BY_ME )\n",
    "\n",
    "# exclude any already tagged with tag_to_apply\n",
    "tags_not_in_list.append( tag_to_apply )\n",
    "\n",
    "if ( ( tags_not_in_list is not None ) and ( len( tags_not_in_list ) > 0 ) ):\n",
    "\n",
    "    # exclude those in a list\n",
    "    print( \"filtering out articles with tags: \" + str( tags_not_in_list ) )\n",
    "    grp_article_qs = grp_article_qs.exclude( tags__name__in = tags_not_in_list )\n",
    "\n",
    "#-- END check to see if we have a specific list of tags we want to exclude --#\n",
    "\n",
    "# include only those with certain tags.\n",
    "tags_in_list = []\n",
    "\n",
    "# Examples\n",
    "\n",
    "# Examples: prelim-related tags\n",
    "#tags_in_list.append( \"prelim_unit_test_001\" )\n",
    "#tags_in_list.append( \"prelim_unit_test_002\" )\n",
    "#tags_in_list.append( \"prelim_unit_test_003\" )\n",
    "#tags_in_list.append( \"prelim_unit_test_004\" )\n",
    "#tags_in_list.append( \"prelim_unit_test_005\" )\n",
    "#tags_in_list.append( \"prelim_unit_test_006\" )\n",
    "#tags_in_list.append( \"prelim_unit_test_007\" )\n",
    "\n",
    "# Example: grp_month\n",
    "#tags_in_list.append( \"grp_month\" )\n",
    "\n",
    "if ( ( tags_in_list is not None ) and ( len( tags_in_list ) > 0 ) ):\n",
    "\n",
    "    # filter\n",
    "    print( \"filtering to just articles with tags: \" + str( tags_in_list ) )\n",
    "    grp_article_qs = grp_article_qs.filter( tags__name__in = tags_in_list )\n",
    "    \n",
    "#-- END check to see if we have a specific list of tags we want to include --#\n",
    "\n",
    "# filter out \"*prelim*\" tags?\n",
    "#filter_out_prelim_tags = True\n",
    "if ( filter_out_prelim_tags == True ):\n",
    "\n",
    "    # ifilter out all articles with any tag whose name contains \"prelim\".\n",
    "    print( \"filtering out articles with tags that contain \\\"prelim\\\"\" )\n",
    "    grp_article_qs = grp_article_qs.exclude( tags__name__icontains = \"prelim\" )\n",
    "    \n",
    "#-- END check to see if we filter out \"prelim_*\" tags --#\n",
    "\n",
    "# how many is that?\n",
    "article_count = grp_article_qs.count()\n",
    "\n",
    "print( \"Article count after tag filtering: \" + str( article_count ) )\n",
    "\n",
    "# do we want a random sample?\n",
    "if ( random_count > 0 ):\n",
    "\n",
    "    # to get random, order them by \"?\", then use slicing to retrieve requested\n",
    "    #     number.\n",
    "    grp_article_qs = grp_article_qs.order_by( \"?\" )[ : random_count ]\n",
    "    \n",
    "#-- END check to see if we want random sample --#\n",
    "\n",
    "# this is a nice algorithm, also:\n",
    "# - http://www.titov.net/2005/09/21/do-not-use-order-by-rand-or-how-to-get-random-rows-from-table/\n",
    "\n",
    "# make ID list, tag articles if configured to.\n",
    "article_id_list = []\n",
    "article_counter = 0\n",
    "article_update_counter = 0\n",
    "for current_article in grp_article_qs:\n",
    "\n",
    "    # increment article_counter\n",
    "    article_counter += 1\n",
    "\n",
    "    # add IDs to article_id_list\n",
    "    article_id_list.append( str( current_article.id ) )\n",
    "    \n",
    "    # apply a tag while we are at it?\n",
    "    if ( ( do_apply_tag == True ) and ( tag_to_apply is not None ) and ( tag_to_apply != \"\" ) ):\n",
    "    \n",
    "        # yes, please.  Tag already present?\n",
    "        article_tag_name_list = current_article.tags.names()\n",
    "        if ( tag_to_apply not in article_tag_name_list ):\n",
    "\n",
    "            # Add tag.\n",
    "            current_article.tags.add( tag_to_apply )\n",
    "            \n",
    "            # increment counter\n",
    "            article_update_counter += 1\n",
    "            \n",
    "        #-- END check to see if tag already present. --#\n",
    "        \n",
    "    #-- END check to see if we apply tag. --#\n",
    "\n",
    "    # output the tags.\n",
    "    if ( debug_flag == True ):\n",
    "        print( \"- Tags for article \" + str( current_article.id ) + \" : \" + str( current_article.tags.all() ) )\n",
    "    #-- END DEBUG --#\n",
    "\n",
    "#-- END loop over articles --#\n",
    "\n",
    "# output the list.\n",
    "print( \"grp_article_qs count: {}\".format( grp_article_qs.count() ) )\n",
    "print( \"Found \" + str( article_counter ) + \" articles ( \" + str( article_count ) + \" ).\" )\n",
    "print( \"- Updated {} articles to add tag {}.\".format( article_update_counter, tag_to_apply ) )\n",
    "if ( debug_flag == True ):\n",
    "    print( \"List of \" + str( len( article_id_list ) ) + \" local GRP staff article IDs: \" + \", \".join( article_id_list ) )\n",
    "#-- END DEBUG --#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detroit News local news\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Detroit News local news:\n",
    "\n",
    "- `context_text/examples/articles/articles-TDN-local_news.py`\n",
    "- local hard news sections (stored in `from context_text.collectors.newsbank.newspapers.DTNB import DTNB` - `DTNB.NEWS_SECTION_NAME_LIST`):\n",
    "\n",
    "    - \"Business\"\n",
    "    - \"Metro\"\n",
    "    - \"Nation\" - because of auto industry stories\n",
    "\n",
    "- in-house implementor (based on byline patterns, stored in `DTNB.Q_IN_HOUSE_AUTHOR`):\n",
    "\n",
    "    - Byline ends in \"/ The Detroit News\", ignore case.\n",
    "\n",
    "        - `Q( author_varchar__iregex = r'.*\\s*/\\s*the\\s*detroit\\s*news$' )`\n",
    "\n",
    "    - Byline ends in \"Special to The Detroit News\", ignore case.\n",
    "\n",
    "        - `Q( author_varchar__iregex = r'.*\\s*/\\s*special\\s*to\\s*the\\s*detroit\\s*news$' )`\n",
    "\n",
    "    - Byline ends in \"Detroit News * Bureau\", ignore case.\n",
    "\n",
    "        - `Q( author_varchar__iregex = r'.*\\s*/\\s*detroit\\s*news\\s*.*\\s*bureau$' )`   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-04T02:42:42.445226Z",
     "start_time": "2019-07-04T02:42:39.261361Z"
    }
   },
   "outputs": [],
   "source": [
    "# filter queryset to just locally created Detroit News (TDN) articles.\n",
    "# imports\n",
    "from context_text.models import Article\n",
    "from context_text.models import Newspaper\n",
    "from context_text.shared.context_text_base import ContextTextBase\n",
    "from context_text.collectors.newsbank.newspapers.DTNB import DTNB\n",
    "\n",
    "# declare variables - Detroit News\n",
    "do_apply_tag = False\n",
    "tag_to_apply = None\n",
    "tdn_local_news_sections = []\n",
    "tdn_newspaper = None\n",
    "tdn_article_qs = None\n",
    "article_count = -1\n",
    "\n",
    "# declare variables - filtering\n",
    "include_opinion_columns = True\n",
    "tags_in_list = []\n",
    "tags_not_in_list = []\n",
    "filter_out_prelim_tags = False\n",
    "random_count = -1\n",
    "\n",
    "# declare variables - make list of article IDs from QS.\n",
    "article_id_list = []\n",
    "article_counter = -1\n",
    "current_article = None\n",
    "\n",
    "# ==> configure\n",
    "\n",
    "# configure - size of random sample we want\n",
    "#random_count = 60\n",
    "\n",
    "# configure - also, apply tag?\n",
    "do_apply_tag = False\n",
    "tag_to_apply = ContextTextBase.TAG_LOCAL_HARD_NEWS\n",
    "\n",
    "# set up \"local, regional and state news\" sections\n",
    "tdn_local_news_sections = DTNB.LOCAL_NEWS_SECTION_NAME_LIST\n",
    "\n",
    "# Detroit News\n",
    "# get newspaper instance for TDN.\n",
    "tdn_newspaper = Newspaper.objects.get( id = DTNB.NEWSPAPER_ID )\n",
    "\n",
    "# start with all articles\n",
    "#tdn_article_qs = Article.objects.all()\n",
    "\n",
    "# ==> filter to newspaper, local news section list, and in-house reporters.\n",
    "\n",
    "# ----> manually\n",
    "\n",
    "# now, need to find local news articles to test on.\n",
    "#tdn_article_qs = tdn_article_qs.filter( newspaper = tdn_newspaper )\n",
    "\n",
    "# only the locally implemented sections\n",
    "#tdn_article_qs = tdn_article_qs.filter( section__in = tdn_local_news_sections )\n",
    "\n",
    "# and, with an in-house author\n",
    "#tdn_article_qs = tdn_article_qs.filter( DTNB.Q_IN_HOUSE_AUTHOR )\n",
    "\n",
    "#print( \"manual filter count: {}\".format( tdn_article_qs.count() ) )\n",
    "\n",
    "# ----> using Article.filter_articles()\n",
    "tdn_article_qs = Article.filter_articles( qs_IN = tdn_article_qs,\n",
    "                                          newspaper = tdn_newspaper,\n",
    "                                          section_name_list = tdn_local_news_sections,\n",
    "                                          custom_article_q = DTNB.Q_IN_HOUSE_AUTHOR )\n",
    "\n",
    "print( \"Article.filter_articles count: {}\".format( tdn_article_qs.count() ) )\n",
    "\n",
    "# and include opinion columns?\n",
    "if ( include_opinion_columns == False ):\n",
    "    \n",
    "    # do not include columns\n",
    "    tdn_article_qs = tdn_article_qs.exclude( author_string__in = DTNB.COLUMNIST_NAME_LIST )\n",
    "    \n",
    "#-- END check to see if we include columns. --#\n",
    "\n",
    "'''\n",
    "# filter to newspaper, section list, and in-house reporters.\n",
    "tdn_article_qs = Article.filter_articles( qs_IN = tdn_article_qs,\n",
    "                                          start_date = \"2009-12-01\",\n",
    "                                          end_date = \"2009-12-31\",\n",
    "                                          newspaper = tdn_newspaper,\n",
    "                                          section_name_list = tdn_local_news_sections,\n",
    "                                          custom_article_q = DTNB.Q_IN_HOUSE_AUTHOR )\n",
    "'''\n",
    "\n",
    "# how many is that?\n",
    "article_count = tdn_article_qs.count()\n",
    "\n",
    "print( \"Article count before filtering on tags: \" + str( article_count ) )\n",
    "\n",
    "# ==> tags\n",
    "\n",
    "# tags to exclude\n",
    "#tags_not_in_list = [ \"prelim_reliability\", \"prelim_network\" ]\n",
    "#tags_not_in_list = [ \"minnesota1-20160328\", \"minnesota2-20160328\", ]\n",
    "\n",
    "# for later - exclude articles already coded.\n",
    "#tags_not_in_list = [ OpenCalaisV2ArticleCoder.TAG_CODED_BY_ME ]\n",
    "\n",
    "tags_not_in_list = None\n",
    "if ( ( tags_not_in_list is not None ) and ( len( tags_not_in_list ) > 0 ) ):\n",
    "\n",
    "    # exclude those in a list\n",
    "    print( \"filtering out articles with tags: \" + str( tags_not_in_list ) )\n",
    "    tdn_article_qs = tdn_article_qs.exclude( tags__name__in = tags_not_in_list )\n",
    "\n",
    "#-- END check to see if we have a specific list of tags we want to exclude --#\n",
    "\n",
    "# include only those with certain tags.\n",
    "#tags_in_list = [ \"prelim_unit_test_001\", \"prelim_unit_test_002\", \"prelim_unit_test_003\", \"prelim_unit_test_004\", \"prelim_unit_test_005\", \"prelim_unit_test_006\", \"prelim_unit_test_007\" ]\n",
    "#tags_in_list = [ \"tdn_month\", ]\n",
    "tags_in_list = None\n",
    "if ( ( tags_in_list is not None ) and ( len( tags_in_list ) > 0 ) ):\n",
    "\n",
    "    # filter\n",
    "    print( \"filtering to just articles with tags: \" + str( tags_in_list ) )\n",
    "    tdn_article_qs = tdn_article_qs.filter( tags__name__in = tags_in_list )\n",
    "    \n",
    "#-- END check to see if we have a specific list of tags we want to include --#\n",
    "\n",
    "# filter out \"*prelim*\" tags?\n",
    "#filter_out_prelim_tags = True\n",
    "if ( filter_out_prelim_tags == True ):\n",
    "\n",
    "    # ifilter out all articles with any tag whose name contains \"prelim\".\n",
    "    print( \"filtering out articles with tags that contain \\\"prelim\\\"\" )\n",
    "    tdn_article_qs = tdn_article_qs.exclude( tags__name__icontains = \"prelim\" )\n",
    "    \n",
    "#-- END check to see if we filter out \"prelim_*\" tags --#\n",
    "\n",
    "# how many is that?\n",
    "article_count = tdn_article_qs.count()\n",
    "\n",
    "print( \"Article count after tag filtering: \" + str( article_count ) )\n",
    "\n",
    "# do we want a random sample?\n",
    "if ( random_count > 0 ):\n",
    "\n",
    "    # to get random, order them by \"?\", then use slicing to retrieve requested\n",
    "    #     number.\n",
    "    tdn_article_qs = tdn_article_qs.order_by( \"?\" )[ : random_count ]\n",
    "    \n",
    "#-- END check to see if we want random sample --#\n",
    "\n",
    "# this is a nice algorithm, also:\n",
    "# - http://www.titov.net/2005/09/21/do-not-use-order-by-rand-or-how-to-get-random-rows-from-table/\n",
    "\n",
    "# make ID list, tag articles if configured to.\n",
    "article_id_list = []\n",
    "article_counter = 0\n",
    "for current_article in tdn_article_qs:\n",
    "\n",
    "    # increment article_counter\n",
    "    article_counter += 1\n",
    "\n",
    "    # add IDs to article_id_list\n",
    "    article_id_list.append( str( current_article.id ) )\n",
    "    \n",
    "    # apply a tag while we are at it?\n",
    "    if ( ( do_apply_tag == True ) and ( tag_to_apply is not None ) and ( tag_to_apply != \"\" ) ):\n",
    "    \n",
    "        # yes, please.  Add tag.\n",
    "        current_article.tags.add( tag_to_apply )\n",
    "        \n",
    "    #-- END check to see if we apply tag. --#\n",
    "\n",
    "    # output the tags.\n",
    "    if ( debug_flag == True ):\n",
    "        print( \"- Tags for article \" + str( current_article.id ) + \" : \" + str( current_article.tags.all() ) )\n",
    "    #-- END DEBUG --#\n",
    "\n",
    "#-- END loop over articles --#\n",
    "\n",
    "# output the list.\n",
    "print( \"tdn_article_qs count: {}\".format( tdn_article_qs.count() ) )\n",
    "print( \"Found \" + str( article_counter ) + \" articles ( \" + str( article_count ) + \" ).\" )\n",
    "if ( debug_flag == True ):\n",
    "    print( \"List of \" + str( len( article_id_list ) ) + \" local TDN staff article IDs: \" + \", \".join( article_id_list ) )\n",
    "#-- END DEBUG --#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Articles\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve just publications that are tagged as being local hard news and that also are not tagged as having been coded by OpenCalaisV2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-01T02:42:01.151Z"
    }
   },
   "outputs": [],
   "source": [
    "# declare variables\n",
    "\n",
    "# declare variables - article filter parameters\n",
    "start_pub_date = None # should be datetime instance\n",
    "end_pub_date = None # should be datetime instance\n",
    "tags_in_list = []\n",
    "tags_not_in_list = []\n",
    "paper_id_in_list = []\n",
    "section_list = []\n",
    "article_id_in_list = []\n",
    "params = {}\n",
    "\n",
    "# declare variables - processing\n",
    "do_i_print_updates = True\n",
    "my_article_coding = None\n",
    "article_qs = None\n",
    "article_count = -1\n",
    "coding_status = \"\"\n",
    "limit_to = -1\n",
    "do_coding = True\n",
    "\n",
    "# declare variables - results\n",
    "success_count = -1\n",
    "success_list = None\n",
    "got_errors = False\n",
    "error_count = -1\n",
    "error_dictionary = None\n",
    "error_article_id = -1\n",
    "error_status_list = None\n",
    "error_status = \"\"\n",
    "error_status_counter = -1\n",
    "\n",
    "# first, get a list of articles to code.\n",
    "\n",
    "# ! Set param values.\n",
    "\n",
    "# ==> start and end dates\n",
    "#start_pub_date = \"2009-12-06\"\n",
    "#end_pub_date = \"2009-12-12\"\n",
    "\n",
    "# ==> tagged articles\n",
    "\n",
    "# Examples:\n",
    "#tag_in_list = \"prelim_reliability\"\n",
    "#tag_in_list = \"prelim_network\"\n",
    "#tag_in_list = \"prelim_unit_test_007\"\n",
    "#tag_in_list = [ \"prelim_reliability\", \"prelim_network\" ]\n",
    "#tag_in_list = [ \"prelim_reliability_test\" ] # 60 articles - Grand Rapids only.\n",
    "#tag_in_list = [ \"prelim_reliability_combined\" ] # 87 articles, Grand Rapids and Detroit.\n",
    "#tag_in_list = [ \"prelim_training_001\" ]\n",
    "#tag_in_list = [ \"grp_month\" ]\n",
    "\n",
    "# ----> include articles when these tags are present.\n",
    "#tags_in_list = None\n",
    "tags_in_list = []\n",
    "tags_in_list.append( ContextTextBase.TAG_LOCAL_HARD_NEWS )\n",
    "\n",
    "# ---> exclude articles when these tags are present.\n",
    "#tags_not_in_list = None\n",
    "tags_not_in_list = []\n",
    "tags_not_in_list.append( OpenCalaisV2ArticleCoder.TAG_CODED_BY_ME )\n",
    "\n",
    "# ==> IDs of newspapers to include.\n",
    "#paper_id_in_list = \"1\"\n",
    "\n",
    "# ==> names of sections to include.\n",
    "#section_list = \"Lakeshore,Front Page,City and Region,Business\"\n",
    "\n",
    "# ==> just limit to specific articles by ID.\n",
    "article_id_in_list = []\n",
    "#article_id_in_list = [ 360962 ]\n",
    "#article_id_in_list = [ 28598 ]\n",
    "#article_id_in_list = [ 21653, 21756 ]\n",
    "#article_id_in_list = [ 90948 ]\n",
    "#article_id_in_list = [ 21627, 21609, 21579 ]\n",
    "#article_id_in_list = [ 48778 ]\n",
    "#article_id_in_list = [ 6065 ]\n",
    "#article_id_in_list = [ 221858 ]\n",
    "#article_id_in_list = [ 23804, 22630 ]\n",
    "#article_id_in_list = [ 23804 ]\n",
    "\n",
    "# filter parameters\n",
    "params[ ArticleCoding.PARAM_START_DATE ] = start_pub_date\n",
    "params[ ArticleCoding.PARAM_END_DATE ] = end_pub_date\n",
    "params[ ArticleCoding.PARAM_TAGS_IN_LIST ] = tags_in_list\n",
    "params[ ArticleCoding.PARAM_TAGS_NOT_IN_LIST ] = tags_not_in_list\n",
    "params[ ArticleCoding.PARAM_PUBLICATION_LIST ] = paper_id_in_list\n",
    "params[ ArticleCoding.PARAM_SECTION_LIST ] = section_list\n",
    "params[ ArticleCoding.PARAM_ARTICLE_ID_LIST ] = article_id_in_list\n",
    "\n",
    "# set coder you want to use.\n",
    "\n",
    "# OpenCalais REST API v.2\n",
    "params[ ArticleCoding.PARAM_CODER_TYPE ] = ArticleCoding.ARTICLE_CODING_IMPL_OPEN_CALAIS_API_V2\n",
    "\n",
    "# get instance of ArticleCoding\n",
    "my_article_coding = ArticleCoding()\n",
    "my_article_coding.do_print_updates = do_i_print_updates\n",
    "\n",
    "# set params\n",
    "my_article_coding.store_parameters( params )\n",
    "\n",
    "print( \"Query Parameters: {}\".format( params ) )\n",
    "\n",
    "# create query set - ArticleCoding does the filtering for you.\n",
    "article_qs = my_article_coding.create_article_query_set()\n",
    "\n",
    "print( \"After my_article_coding.create_article_query_set(), count: {}\".format( article_qs.count() ) )\n",
    "if ( article_qs._result_cache is None ):\n",
    "    \n",
    "    print( \"article_qs evaluated: NO ( {} )\".format( article_qs._result_cache ) )\n",
    "    \n",
    "else:\n",
    "    \n",
    "    print( \"article_qs evaluated: YES\" )\n",
    "\n",
    "#-- END check to see if _result_cache --#\n",
    "\n",
    "# limit for an initial test?\n",
    "limit_to = 4990\n",
    "if ( ( limit_to is not None ) and ( isinstance( limit_to, int ) == True ) and ( limit_to > 0 ) ):\n",
    "\n",
    "    # yes.\n",
    "    article_qs = article_qs[ : limit_to ]\n",
    "\n",
    "#-- END check to see if limit --#\n",
    "\n",
    "# get article count\n",
    "if ( isinstance( article_qs, list ) == True ):\n",
    "\n",
    "    # list - call len()\n",
    "    article_list = article_qs\n",
    "    article_count = len( article_list )\n",
    "    \n",
    "else:\n",
    "\n",
    "    # not a list - call count()\n",
    "    article_count = article_qs.count()\n",
    "    \n",
    "#-- END figure out how to get count --#\n",
    "\n",
    "print( \"Matching article count: \" + str( article_count ) )\n",
    "\n",
    "# Do coding?\n",
    "if ( do_coding == True ):\n",
    "\n",
    "    print( \"do_coding == True - it's on!\" )\n",
    "\n",
    "    # yes - make sure we have at least one article:\n",
    "    if ( article_count > 0 ):\n",
    "\n",
    "        # invoke the code_article_data( self, query_set_IN ) method.\n",
    "        coding_status = my_article_coding.code_article_data( article_qs )\n",
    "    \n",
    "        # output status\n",
    "        print( \"\\n\\n==============================\\n\\nCoding status: \\\"\" + coding_status + \"\\\"\" )\n",
    "        \n",
    "        # get success count\n",
    "        success_count = my_article_coding.get_success_count()\n",
    "        print( \"\\n\\n====> Count of articles successfully processed: \" + str( success_count ) )    \n",
    "        \n",
    "        # if successes, list out IDs.\n",
    "        if ( success_count > 0 ):\n",
    "        \n",
    "            # there were successes.\n",
    "            success_list = my_article_coding.get_success_list()\n",
    "            print( \"- list of successfully processed articles: \" + str( success_list ) )\n",
    "        \n",
    "        #-- END check to see if successes. --#\n",
    "        \n",
    "        # got errors?\n",
    "        got_errors = my_article_coding.has_errors()\n",
    "        if ( got_errors == True ):\n",
    "        \n",
    "            # get error dictionary\n",
    "            error_dictionary = my_article_coding.get_error_dictionary()\n",
    "            \n",
    "            # get error count\n",
    "            error_count = len( error_dictionary )\n",
    "            print( \"\\n\\n====> Count of articles with errors: \" + str( error_count ) )\n",
    "            \n",
    "            # loop...\n",
    "            for error_article_id, error_status_list in six.iteritems( error_dictionary ):\n",
    "            \n",
    "                # output errors for this article.\n",
    "                print( \"- errors for article ID \" + str( error_article_id ) + \":\" )\n",
    "                \n",
    "                # loop over status messages.\n",
    "                error_status_counter = 0\n",
    "                for error_status in error_status_list:\n",
    "                \n",
    "                    # increment status\n",
    "                    error_status_counter += 1\n",
    "\n",
    "                    # print status\n",
    "                    print( \"----> status #\" + str( error_status_counter ) + \": \" + error_status )\n",
    "                    \n",
    "                #-- END loop over status messages. --#\n",
    "            \n",
    "            #-- END loop over articles. --#\n",
    "   \n",
    "        #-- END check to see if errors --#\n",
    "    \n",
    "    #-- END check to see if article count. --#\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # output matching article count.\n",
    "    print( \"do_coding == False, so dry run\" )\n",
    "    \n",
    "#-- END check to see if we do_coding --#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- started: execution queued 22:42:01 2019-07-31\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_virtualenv",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
